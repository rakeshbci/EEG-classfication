{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import resnet\n",
    "import numpy as np\n",
    "import pytest\n",
    "from keras import backend as K\n",
    "import keras_resnet\n",
    "import matplotlib.pyplot as plt\n",
    "data = h5py.File(\"project_datasets/A01T_slice.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"left\",\"right\",\"feet\",\"tongue\"]\n",
    "A01T = h5py.File(\"project_datasets/A01T_slice.mat\", 'r')\n",
    "A02T = h5py.File(\"project_datasets/A02T_slice.mat\", 'r')\n",
    "A03T = h5py.File(\"project_datasets/A03T_slice.mat\", 'r')\n",
    "A04T = h5py.File(\"project_datasets/A04T_slice.mat\", 'r')\n",
    "A05T = h5py.File(\"project_datasets/A05T_slice.mat\", 'r')\n",
    "A06T = h5py.File(\"project_datasets/A06T_slice.mat\", 'r')\n",
    "A07T = h5py.File(\"project_datasets/A07T_slice.mat\", 'r')\n",
    "A08T = h5py.File(\"project_datasets/A08T_slice.mat\", 'r')\n",
    "A09T = h5py.File(\"project_datasets/A09T_slice.mat\", 'r')\n",
    "x1 = np.copy(A01T['image'])\n",
    "y1 = np.copy(A01T['type'])\n",
    "x2 = np.copy(A02T['image'])\n",
    "y2 = np.copy(A02T['type'])\n",
    "x3 = np.copy(A03T['image'])\n",
    "y3 = np.copy(A03T['type'])\n",
    "x4 = np.copy(A04T['image'])\n",
    "y4 = np.copy(A04T['type'])\n",
    "x5 = np.copy(A05T['image'])\n",
    "y5 = np.copy(A05T['type'])\n",
    "x6 = np.copy(A06T['image'])\n",
    "y6 = np.copy(A06T['type'])\n",
    "x7 = np.copy(A07T['image'])\n",
    "y7 = np.copy(A07T['type'])\n",
    "x8= np.copy(A08T['image'])\n",
    "y8= np.copy(A08T['type'])\n",
    "x9= np.copy(A09T['image'])\n",
    "y9= np.copy(A09T['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape data and get train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(x,y):\n",
    "    x_reshape = x[:,:22,:]\n",
    "    y_reshape = y[0, 0:x1.shape[0]:1]\n",
    "    return x_reshape, y_reshape\n",
    "def get_train_test(X, y, num_test = 50, num_train = 238, num_val = 50, \n",
    "                   subtract_mean=True):\n",
    "    mask = list(range(num_train))\n",
    "    X_train = X[mask]\n",
    "    y_train = y[mask]\n",
    "    mask = list(range(num_val))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_train,num_train+num_test))\n",
    "    X_test = X[mask]\n",
    "    y_test = y[mask]\n",
    "    return  X_train, y_train, X_test, y_test\n",
    "def one_hot(y):\n",
    "    y=y-769\n",
    "    y = y.reshape(len(y))\n",
    "    n_values = int(np.max(y)) + 1\n",
    "    return np.eye(n_values)[np.array(y, dtype=np.int32)] \n",
    "def elm_non(x):\n",
    "    where_are_NaNs = np.isnan(x)\n",
    "    x[where_are_NaNs] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 22, 1000)\n",
      "(288,)\n",
      "(238, 22, 1000)\n",
      "(238,)\n",
      "(50, 22, 1000)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "x1_reshape,y1_reshape = reshape(x1,y1)\n",
    "x2_reshape,y2_reshape = reshape(x2,y2)\n",
    "x3_reshape,y3_reshape = reshape(x3,y3)\n",
    "x4_reshape,y4_reshape = reshape(x4,y4)\n",
    "x5_reshape,y5_reshape = reshape(x5,y5)\n",
    "x6_reshape,y6_reshape = reshape(x6,y6)\n",
    "x7_reshape,y7_reshape = reshape(x7,y7)\n",
    "x8_reshape,y8_reshape = reshape(x8,y8)\n",
    "x9_reshape,y9_reshape = reshape(x9,y9)\n",
    "x1_reshape==elm_non(x1_reshape)\n",
    "x2_reshape=elm_non(x2_reshape)\n",
    "x3_reshape=elm_non(x3_reshape)\n",
    "x4_reshape=elm_non(x4_reshape)\n",
    "x5_reshape=elm_non(x5_reshape)\n",
    "x6_reshape=elm_non(x6_reshape)\n",
    "x7_reshape=elm_non(x7_reshape)\n",
    "x8_reshape=elm_non(x8_reshape)\n",
    "x9_reshape=elm_non(x9_reshape)\n",
    "x1_train, y1_train, x1_test, y1_test = get_train_test(x1_reshape,y1_reshape)\n",
    "x2_train, y2_train, x2_test, y2_test = get_train_test(x2_reshape,y2_reshape)\n",
    "x3_train, y3_train, x3_test, y3_test = get_train_test(x3_reshape,y3_reshape)\n",
    "x4_train, y4_train, x4_test, y4_test = get_train_test(x4_reshape,y4_reshape)\n",
    "x5_train, y5_train, x5_test, y5_test = get_train_test(x5_reshape,y5_reshape )\n",
    "x6_train, y6_train, x6_test, y6_test = get_train_test(x6_reshape,y6_reshape)\n",
    "x7_train, y7_train, x7_test, y7_test = get_train_test(x7_reshape,y7_reshape)\n",
    "x8_train, y8_train, x8_test, y8_test = get_train_test(x8_reshape,y8_reshape)\n",
    "x9_train, y9_train, x9_test, y9_test = get_train_test(x9_reshape,y9_reshape)\n",
    "elm_non(x1_train)\n",
    "print(x1_reshape.shape)\n",
    "print(y1_reshape.shape)\n",
    "print(x1_train.shape)\n",
    "print(y1_train.shape)\n",
    "print(x1_test.shape)\n",
    "print(y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2142, 22, 1000)\n",
      "(2142,)\n"
     ]
    }
   ],
   "source": [
    "x_train=np.concatenate((x1_train,x2_train,x3_train,x4_train,x5_train,x6_train,x7_train,x8_train,x9_train), axis=0)\n",
    "y_train=np.concatenate((y1_train,y2_train,y3_train,y4_train,y5_train,y6_train,y7_train,y8_train,y9_train), axis=0)\n",
    "x_test=np.concatenate((x1_test,x2_train,x3_test,x4_test,x5_test,x6_test,x7_test,x8_test,x9_test), axis=0)\n",
    "y_test=np.concatenate((y1_test,y2_train,y3_test,y4_test,y5_test,y6_test,y7_test,y8_test,y9_test), axis=0)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238, 1, 22, 1000)\n",
      "(2142, 1, 22, 1000)\n",
      "(238, 4)\n",
      "(2142, 4)\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x_train_add = np.expand_dims(x_train, axis=0).transpose(1,0,2,3)\n",
    "x1_train_add = np.expand_dims(x1_train, axis=0).transpose(1,0,2,3)\n",
    "x2_train_add = np.expand_dims(x2_train, axis=0).transpose(1,0,2,3)\n",
    "x3_train_add = np.expand_dims(x3_train, axis=0).transpose(1,0,2,3)\n",
    "x4_train_add = np.expand_dims(x4_train, axis=0).transpose(1,0,2,3)\n",
    "x5_train_add = np.expand_dims(x5_train, axis=0).transpose(1,0,2,3)\n",
    "x6_train_add = np.expand_dims(x6_train, axis=0).transpose(1,0,2,3)\n",
    "x7_train_add = np.expand_dims(x7_train, axis=0).transpose(1,0,2,3)\n",
    "x8_train_add = np.expand_dims(x8_train, axis=0).transpose(1,0,2,3)\n",
    "x9_train_add = np.expand_dims(x9_train, axis=0).transpose(1,0,2,3)\n",
    "\n",
    "x_test_add = np.expand_dims(x_test, axis=0).transpose(1,0,2,3)\n",
    "x1_test_add = np.expand_dims(x1_test, axis=0).transpose(1,0,2,3)\n",
    "x2_test_add = np.expand_dims(x2_test, axis=0).transpose(1,0,2,3)\n",
    "x3_test_add = np.expand_dims(x3_test, axis=0).transpose(1,0,2,3)\n",
    "x4_test_add = np.expand_dims(x4_test, axis=0).transpose(1,0,2,3)\n",
    "x5_test_add = np.expand_dims(x5_test, axis=0).transpose(1,0,2,3)\n",
    "x6_test_add = np.expand_dims(x6_test, axis=0).transpose(1,0,2,3)\n",
    "x7_test_add = np.expand_dims(x7_test, axis=0).transpose(1,0,2,3)\n",
    "x8_test_add = np.expand_dims(x8_test, axis=0).transpose(1,0,2,3)\n",
    "x9_test_add = np.expand_dims(x9_test, axis=0).transpose(1,0,2,3)\n",
    "\n",
    "y_train_onehot=one_hot(y_train)\n",
    "y1_train_onehot=one_hot(y1_train)\n",
    "y2_train_onehot=one_hot(y2_train)\n",
    "y3_train_onehot=one_hot(y3_train)\n",
    "y4_train_onehot=one_hot(y4_train)\n",
    "y5_train_onehot=one_hot(y5_train)\n",
    "y6_train_onehot=one_hot(y6_train)\n",
    "y7_train_onehot=one_hot(y7_train)\n",
    "y8_train_onehot=one_hot(y8_train)\n",
    "y9_train_onehot=one_hot(y9_train)\n",
    "\n",
    "y_test_onehot=one_hot(y_test)\n",
    "y1_test_onehot=one_hot(y1_test)\n",
    "y2_test_onehot=one_hot(y2_test)\n",
    "y3_test_onehot=one_hot(y3_test)\n",
    "y4_test_onehot=one_hot(y4_test)\n",
    "y5_test_onehot=one_hot(y5_test)\n",
    "y6_test_onehot=one_hot(y6_test)\n",
    "y7_test_onehot=one_hot(y7_test)\n",
    "y8_test_onehot=one_hot(y8_test)\n",
    "y9_test_onehot=one_hot(y9_test)\n",
    "print(x1_train_add.shape)\n",
    "print(x_train_add.shape)\n",
    "print(y1_train_onehot.shape)\n",
    "print(y_train_onehot.shape)\n",
    "print(y_train_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet model build(code from online model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import six\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten\n",
    ")\n",
    "from keras.layers.convolutional import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D\n",
    ")\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                          kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                              strides=init_strides,\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
    "                                     strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
    "                      activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model build and train subject1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import keras\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = [0]\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(self.times[-1]+time.time() - self.epoch_time_start)\n",
    "        \n",
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.testaccuracy = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.testaccuracy.append(logs.get('val_acc'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 50 samples\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - 30s 126ms/step - loss: 2.3690 - acc: 0.3403 - val_loss: 4.2989 - val_acc: 0.2400\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 1.5787 - acc: 0.6008 - val_loss: 2.9544 - val_acc: 0.3400\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.9005 - acc: 0.8151 - val_loss: 2.9053 - val_acc: 0.2600\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.5776 - acc: 0.9622 - val_loss: 3.0045 - val_acc: 0.2200\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.4230 - acc: 0.9958 - val_loss: 3.1557 - val_acc: 0.2400\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3750 - acc: 0.9832 - val_loss: 3.3456 - val_acc: 0.2600\n",
      "Epoch 00006: early stopping\n",
      "50/50 [==============================] - 0s 4ms/step\n",
      "\n",
      "Testing loss: 3.345631971359253, acc: 0.26000000059604644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "#from sklearn import preprocessing \n",
    "tb = callbacks.TensorBoard(log_dir='/.logs', histogram_freq=10, batch_size=32,\n",
    "                           write_graph=True, write_grads=True, write_images=False,\n",
    "                           embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#x1_train_scaler = scaler.fit_transform(x1_train_add)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "\n",
    "model = ResnetBuilder.build_resnet_18((1000,1,22), 4)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "time_callback = TimeHistory()\n",
    "acc_callback = AccuracyHistory()\n",
    "model.fit(x1_train_add, y1_train_onehot,\n",
    "              batch_size=32,\n",
    "              epochs=100,shuffle=True,\n",
    "          callbacks=[ early_stop],\n",
    "         validation_data=(x1_test_add, y1_test_onehot),verbose=1)\n",
    "#times = time_callback.times\n",
    "loss,acc=model.evaluate(x1_test_add, y1_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetBuilder.build_resnet_18((1000,1,22), 4)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "time_callback = TimeHistory()\n",
    "acc_callback = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 50 samples\n",
      "Epoch 1/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2849 - acc: 1.0000 - val_loss: 4.6101 - val_acc: 0.2400\n",
      "Epoch 2/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2794 - acc: 1.0000 - val_loss: 4.6229 - val_acc: 0.2600\n",
      "Epoch 3/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2766 - acc: 1.0000 - val_loss: 4.6301 - val_acc: 0.2600\n",
      "Epoch 4/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2794 - acc: 0.9958 - val_loss: 4.6060 - val_acc: 0.2600\n",
      "Epoch 5/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2750 - acc: 1.0000 - val_loss: 4.6261 - val_acc: 0.2600\n",
      "Epoch 6/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2720 - acc: 1.0000 - val_loss: 4.5779 - val_acc: 0.2800\n",
      "Epoch 7/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2686 - acc: 1.0000 - val_loss: 4.4609 - val_acc: 0.2800\n",
      "Epoch 8/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2703 - acc: 1.0000 - val_loss: 4.4566 - val_acc: 0.2800\n",
      "Epoch 9/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2663 - acc: 1.0000 - val_loss: 4.5088 - val_acc: 0.2800\n",
      "Epoch 10/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2681 - acc: 1.0000 - val_loss: 4.4992 - val_acc: 0.3000\n",
      "Epoch 11/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2761 - acc: 0.9958 - val_loss: 4.4301 - val_acc: 0.2800\n",
      "Epoch 12/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3037 - acc: 0.9916 - val_loss: 4.3656 - val_acc: 0.2600\n",
      "Epoch 13/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2972 - acc: 0.9916 - val_loss: 4.0496 - val_acc: 0.3000\n",
      "Epoch 14/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3136 - acc: 0.9832 - val_loss: 4.2136 - val_acc: 0.3000\n",
      "Epoch 15/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2934 - acc: 0.9874 - val_loss: 4.1985 - val_acc: 0.3000\n",
      "Epoch 16/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3099 - acc: 0.9916 - val_loss: 4.0667 - val_acc: 0.2600\n",
      "Epoch 17/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2856 - acc: 0.9958 - val_loss: 3.5154 - val_acc: 0.2800\n",
      "Epoch 18/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3114 - acc: 0.9832 - val_loss: 3.3626 - val_acc: 0.2400\n",
      "Epoch 19/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2951 - acc: 0.9874 - val_loss: 3.7109 - val_acc: 0.3200\n",
      "Epoch 20/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3039 - acc: 0.9832 - val_loss: 3.7599 - val_acc: 0.2800\n",
      "Epoch 21/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3106 - acc: 0.9832 - val_loss: 4.1151 - val_acc: 0.2400\n",
      "Epoch 22/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3008 - acc: 0.9874 - val_loss: 4.4881 - val_acc: 0.2400\n",
      "Epoch 23/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2815 - acc: 0.9916 - val_loss: 4.7199 - val_acc: 0.2600\n",
      "Epoch 24/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2726 - acc: 0.9958 - val_loss: 4.8751 - val_acc: 0.2800\n",
      "Epoch 25/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.3170 - acc: 0.9748 - val_loss: 4.6161 - val_acc: 0.2800\n",
      "Epoch 26/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2964 - acc: 0.9790 - val_loss: 4.5733 - val_acc: 0.3600\n",
      "Epoch 27/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.4396 - acc: 0.9370 - val_loss: 4.9697 - val_acc: 0.2400\n",
      "Epoch 28/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.3213 - acc: 0.9832 - val_loss: 5.3548 - val_acc: 0.3000\n",
      "Epoch 29/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3176 - acc: 0.9748 - val_loss: 5.2630 - val_acc: 0.3000\n",
      "Epoch 30/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2665 - acc: 1.0000 - val_loss: 5.0857 - val_acc: 0.3000\n",
      "Epoch 31/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2725 - acc: 0.9958 - val_loss: 5.0385 - val_acc: 0.3000\n",
      "Epoch 32/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2567 - acc: 1.0000 - val_loss: 4.9488 - val_acc: 0.2800\n",
      "Epoch 33/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2784 - acc: 0.9874 - val_loss: 4.9325 - val_acc: 0.3000\n",
      "Epoch 34/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2635 - acc: 0.9958 - val_loss: 5.0081 - val_acc: 0.3000\n",
      "Epoch 35/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2733 - acc: 0.9874 - val_loss: 4.9137 - val_acc: 0.2600\n",
      "Epoch 36/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2726 - acc: 0.9958 - val_loss: 4.7399 - val_acc: 0.2000\n",
      "Epoch 37/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2627 - acc: 0.9916 - val_loss: 4.6252 - val_acc: 0.2600\n",
      "Epoch 38/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2925 - acc: 0.9832 - val_loss: 4.8414 - val_acc: 0.2800\n",
      "Epoch 39/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2812 - acc: 0.9916 - val_loss: 4.8348 - val_acc: 0.1800\n",
      "Epoch 40/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2687 - acc: 0.9916 - val_loss: 4.7996 - val_acc: 0.2400\n",
      "Epoch 41/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2641 - acc: 0.9916 - val_loss: 4.8340 - val_acc: 0.2400\n",
      "Epoch 42/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2580 - acc: 1.0000 - val_loss: 4.8473 - val_acc: 0.2600\n",
      "Epoch 43/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2510 - acc: 0.9958 - val_loss: 4.8501 - val_acc: 0.2600\n",
      "Epoch 44/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2521 - acc: 1.0000 - val_loss: 4.9914 - val_acc: 0.2800\n",
      "Epoch 45/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2445 - acc: 0.9958 - val_loss: 5.0618 - val_acc: 0.2400\n",
      "Epoch 46/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2517 - acc: 0.9958 - val_loss: 5.0305 - val_acc: 0.2400\n",
      "Epoch 47/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2406 - acc: 1.0000 - val_loss: 4.9912 - val_acc: 0.3000\n",
      "Epoch 48/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2416 - acc: 1.0000 - val_loss: 5.1028 - val_acc: 0.2800\n",
      "Epoch 49/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2525 - acc: 0.9958 - val_loss: 5.0360 - val_acc: 0.2800\n",
      "Epoch 50/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2450 - acc: 0.9916 - val_loss: 4.9400 - val_acc: 0.3000\n",
      "Epoch 51/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2430 - acc: 1.0000 - val_loss: 4.8708 - val_acc: 0.2200\n",
      "Epoch 52/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2433 - acc: 0.9958 - val_loss: 4.7837 - val_acc: 0.2200\n",
      "Epoch 53/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2486 - acc: 0.9874 - val_loss: 4.3034 - val_acc: 0.3000\n",
      "Epoch 54/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2636 - acc: 0.9916 - val_loss: 4.2088 - val_acc: 0.3200\n",
      "Epoch 55/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2512 - acc: 0.9916 - val_loss: 4.6453 - val_acc: 0.3000\n",
      "Epoch 56/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2895 - acc: 0.9874 - val_loss: 5.1764 - val_acc: 0.3000\n",
      "Epoch 57/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3440 - acc: 0.9706 - val_loss: 5.2594 - val_acc: 0.2200\n",
      "Epoch 58/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2942 - acc: 0.9748 - val_loss: 4.6697 - val_acc: 0.2600\n",
      "Epoch 59/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2765 - acc: 0.9916 - val_loss: 4.5132 - val_acc: 0.2400\n",
      "Epoch 60/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2583 - acc: 0.9916 - val_loss: 5.1055 - val_acc: 0.3200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2681 - acc: 0.9874 - val_loss: 5.1361 - val_acc: 0.2400\n",
      "Epoch 62/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3355 - acc: 0.9706 - val_loss: 4.7702 - val_acc: 0.2400\n",
      "Epoch 63/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2791 - acc: 0.9874 - val_loss: 4.2688 - val_acc: 0.2800\n",
      "Epoch 64/1000\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2935 - acc: 0.9874 - val_loss: 4.3563 - val_acc: 0.3400\n",
      "Epoch 65/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2783 - acc: 0.9832 - val_loss: 4.5134 - val_acc: 0.4400\n",
      "Epoch 66/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.3399 - acc: 0.9664 - val_loss: 4.2940 - val_acc: 0.3600\n",
      "Epoch 67/1000\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2747 - acc: 0.9874 - val_loss: 5.1216 - val_acc: 0.2600\n",
      "Epoch 68/1000\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2974 - acc: 0.9748 - val_loss: 5.6660 - val_acc: 0.2800\n",
      "Epoch 69/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2990 - acc: 0.9748 - val_loss: 5.3500 - val_acc: 0.2600\n",
      "Epoch 70/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.3027 - acc: 0.9706 - val_loss: 5.1311 - val_acc: 0.3200\n",
      "Epoch 71/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2649 - acc: 0.9916 - val_loss: 5.0987 - val_acc: 0.3600\n",
      "Epoch 72/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2335 - acc: 1.0000 - val_loss: 4.8598 - val_acc: 0.2800\n",
      "Epoch 73/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2297 - acc: 1.0000 - val_loss: 4.6072 - val_acc: 0.2600\n",
      "Epoch 74/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2266 - acc: 1.0000 - val_loss: 4.5438 - val_acc: 0.2800\n",
      "Epoch 75/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2244 - acc: 1.0000 - val_loss: 4.5067 - val_acc: 0.2800\n",
      "Epoch 76/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2312 - acc: 0.9958 - val_loss: 4.2666 - val_acc: 0.2800\n",
      "Epoch 77/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2264 - acc: 1.0000 - val_loss: 4.1964 - val_acc: 0.2800\n",
      "Epoch 78/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2180 - acc: 1.0000 - val_loss: 4.1661 - val_acc: 0.3000\n",
      "Epoch 79/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2197 - acc: 1.0000 - val_loss: 4.1588 - val_acc: 0.3200\n",
      "Epoch 80/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2148 - acc: 1.0000 - val_loss: 4.2847 - val_acc: 0.3200\n",
      "Epoch 81/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2167 - acc: 1.0000 - val_loss: 4.2745 - val_acc: 0.3000\n",
      "Epoch 82/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2184 - acc: 1.0000 - val_loss: 4.1326 - val_acc: 0.3000\n",
      "Epoch 83/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2146 - acc: 1.0000 - val_loss: 4.0457 - val_acc: 0.3000\n",
      "Epoch 84/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2113 - acc: 1.0000 - val_loss: 4.0239 - val_acc: 0.3000\n",
      "Epoch 85/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2200 - acc: 0.9958 - val_loss: 4.1228 - val_acc: 0.3200\n",
      "Epoch 86/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2123 - acc: 0.9958 - val_loss: 4.2880 - val_acc: 0.3200\n",
      "Epoch 87/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2077 - acc: 1.0000 - val_loss: 4.3577 - val_acc: 0.3000\n",
      "Epoch 88/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2138 - acc: 0.9958 - val_loss: 4.4030 - val_acc: 0.3000\n",
      "Epoch 89/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2090 - acc: 1.0000 - val_loss: 4.5288 - val_acc: 0.2800\n",
      "Epoch 90/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2083 - acc: 1.0000 - val_loss: 4.5928 - val_acc: 0.2800\n",
      "Epoch 91/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2128 - acc: 1.0000 - val_loss: 4.5991 - val_acc: 0.2800\n",
      "Epoch 92/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2126 - acc: 0.9958 - val_loss: 4.4727 - val_acc: 0.3000\n",
      "Epoch 93/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2024 - acc: 1.0000 - val_loss: 4.4099 - val_acc: 0.3200\n",
      "Epoch 94/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2011 - acc: 1.0000 - val_loss: 4.3808 - val_acc: 0.3200\n",
      "Epoch 95/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2023 - acc: 1.0000 - val_loss: 4.3917 - val_acc: 0.3200\n",
      "Epoch 96/1000\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2035 - acc: 1.0000 - val_loss: 4.5295 - val_acc: 0.2600\n",
      "Epoch 97/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2015 - acc: 1.0000 - val_loss: 4.5508 - val_acc: 0.2800\n",
      "Epoch 98/1000\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.1988 - acc: 1.0000 - val_loss: 4.4209 - val_acc: 0.3400\n",
      "Epoch 99/1000\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.1980 - acc: 1.0000 - val_loss: 4.3502 - val_acc: 0.3200\n",
      "Epoch 100/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1964 - acc: 1.0000 - val_loss: 4.3395 - val_acc: 0.3200\n",
      "Epoch 101/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1969 - acc: 1.0000 - val_loss: 4.3769 - val_acc: 0.2800\n",
      "Epoch 102/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1938 - acc: 1.0000 - val_loss: 4.3817 - val_acc: 0.2800\n",
      "Epoch 103/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1931 - acc: 1.0000 - val_loss: 4.3875 - val_acc: 0.2600\n",
      "Epoch 104/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1917 - acc: 1.0000 - val_loss: 4.3718 - val_acc: 0.2800\n",
      "Epoch 105/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1920 - acc: 1.0000 - val_loss: 4.3346 - val_acc: 0.2800\n",
      "Epoch 106/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1898 - acc: 1.0000 - val_loss: 4.2984 - val_acc: 0.2800\n",
      "Epoch 107/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1957 - acc: 0.9958 - val_loss: 4.3602 - val_acc: 0.2400\n",
      "Epoch 108/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1911 - acc: 1.0000 - val_loss: 4.5113 - val_acc: 0.2600\n",
      "Epoch 109/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1967 - acc: 0.9958 - val_loss: 4.4746 - val_acc: 0.2600\n",
      "Epoch 110/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1915 - acc: 0.9958 - val_loss: 4.4271 - val_acc: 0.2800\n",
      "Epoch 111/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2089 - acc: 0.9958 - val_loss: 4.3849 - val_acc: 0.3000\n",
      "Epoch 112/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1985 - acc: 0.9916 - val_loss: 4.3772 - val_acc: 0.2600\n",
      "Epoch 113/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1878 - acc: 1.0000 - val_loss: 4.5385 - val_acc: 0.2200\n",
      "Epoch 114/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2047 - acc: 0.9832 - val_loss: 4.4400 - val_acc: 0.2600\n",
      "Epoch 115/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1843 - acc: 1.0000 - val_loss: 4.5129 - val_acc: 0.2800\n",
      "Epoch 116/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1829 - acc: 1.0000 - val_loss: 4.5647 - val_acc: 0.2800\n",
      "Epoch 117/1000\n",
      "238/238 [==============================] - 10s 43ms/step - loss: 0.1875 - acc: 1.0000 - val_loss: 4.4766 - val_acc: 0.2800\n",
      "Epoch 118/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1817 - acc: 1.0000 - val_loss: 4.4138 - val_acc: 0.2800\n",
      "Epoch 119/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1831 - acc: 1.0000 - val_loss: 4.4793 - val_acc: 0.2400\n",
      "Epoch 120/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1860 - acc: 0.9958 - val_loss: 4.8531 - val_acc: 0.2400\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1786 - acc: 1.0000 - val_loss: 4.9570 - val_acc: 0.2400\n",
      "Epoch 122/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1845 - acc: 0.9958 - val_loss: 4.9353 - val_acc: 0.2400\n",
      "Epoch 123/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1771 - acc: 1.0000 - val_loss: 4.8981 - val_acc: 0.2400\n",
      "Epoch 124/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1849 - acc: 0.9958 - val_loss: 4.9379 - val_acc: 0.2400\n",
      "Epoch 125/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1880 - acc: 0.9958 - val_loss: 4.8933 - val_acc: 0.2400\n",
      "Epoch 126/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1806 - acc: 0.9958 - val_loss: 4.6371 - val_acc: 0.2600\n",
      "Epoch 127/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2052 - acc: 0.9874 - val_loss: 4.6951 - val_acc: 0.2600\n",
      "Epoch 128/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2195 - acc: 0.9958 - val_loss: 4.7211 - val_acc: 0.2600\n",
      "Epoch 129/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2733 - acc: 0.9622 - val_loss: 5.0003 - val_acc: 0.3200\n",
      "Epoch 130/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2708 - acc: 0.9706 - val_loss: 4.7970 - val_acc: 0.3200\n",
      "Epoch 131/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3113 - acc: 0.9496 - val_loss: 6.0057 - val_acc: 0.2200\n",
      "Epoch 132/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2166 - acc: 0.9832 - val_loss: 6.6994 - val_acc: 0.2400\n",
      "Epoch 133/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2029 - acc: 0.9916 - val_loss: 6.5604 - val_acc: 0.2600\n",
      "Epoch 134/1000\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2070 - acc: 0.9832 - val_loss: 6.1142 - val_acc: 0.3200\n",
      "Epoch 135/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1872 - acc: 0.9958 - val_loss: 5.5452 - val_acc: 0.3200\n",
      "Epoch 136/1000\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.1831 - acc: 1.0000 - val_loss: 5.2009 - val_acc: 0.3200\n",
      "Epoch 137/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1769 - acc: 1.0000 - val_loss: 5.0591 - val_acc: 0.3400\n",
      "Epoch 138/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1835 - acc: 1.0000 - val_loss: 4.8935 - val_acc: 0.3400\n",
      "Epoch 139/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2040 - acc: 0.9916 - val_loss: 4.8566 - val_acc: 0.2800\n",
      "Epoch 140/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1849 - acc: 0.9958 - val_loss: 5.0023 - val_acc: 0.2400\n",
      "Epoch 141/1000\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.1836 - acc: 0.9958 - val_loss: 5.3565 - val_acc: 0.2800\n",
      "Epoch 142/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2330 - acc: 0.9874 - val_loss: 5.4694 - val_acc: 0.2600\n",
      "Epoch 143/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2240 - acc: 0.9874 - val_loss: 5.7908 - val_acc: 0.3000\n",
      "Epoch 144/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2083 - acc: 0.9916 - val_loss: 5.4031 - val_acc: 0.3000\n",
      "Epoch 145/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2062 - acc: 0.9916 - val_loss: 5.1477 - val_acc: 0.2600\n",
      "Epoch 146/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1784 - acc: 1.0000 - val_loss: 4.9657 - val_acc: 0.2800\n",
      "Epoch 147/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1835 - acc: 0.9958 - val_loss: 4.7993 - val_acc: 0.2800\n",
      "Epoch 148/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2227 - acc: 0.9832 - val_loss: 4.2900 - val_acc: 0.2600\n",
      "Epoch 149/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.3018 - acc: 0.9622 - val_loss: 4.3354 - val_acc: 0.3000\n",
      "Epoch 150/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2124 - acc: 0.9916 - val_loss: 4.3039 - val_acc: 0.3600\n",
      "Epoch 151/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2214 - acc: 0.9832 - val_loss: 4.7333 - val_acc: 0.4200\n",
      "Epoch 152/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1894 - acc: 0.9916 - val_loss: 4.8498 - val_acc: 0.3400\n",
      "Epoch 153/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2051 - acc: 0.9874 - val_loss: 4.7925 - val_acc: 0.2800\n",
      "Epoch 154/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2727 - acc: 0.9664 - val_loss: 4.5690 - val_acc: 0.3200\n",
      "Epoch 155/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1888 - acc: 0.9916 - val_loss: 4.5510 - val_acc: 0.3400\n",
      "Epoch 156/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1979 - acc: 0.9916 - val_loss: 4.6790 - val_acc: 0.3200\n",
      "Epoch 157/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2063 - acc: 0.9916 - val_loss: 4.6822 - val_acc: 0.3400\n",
      "Epoch 158/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1850 - acc: 0.9958 - val_loss: 4.7964 - val_acc: 0.3600\n",
      "Epoch 159/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1886 - acc: 0.9958 - val_loss: 4.8615 - val_acc: 0.3600\n",
      "Epoch 160/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1938 - acc: 0.9916 - val_loss: 5.4156 - val_acc: 0.3200\n",
      "Epoch 161/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2068 - acc: 0.9874 - val_loss: 5.3139 - val_acc: 0.3400\n",
      "Epoch 162/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1856 - acc: 0.9958 - val_loss: 4.8492 - val_acc: 0.4000\n",
      "Epoch 163/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2488 - acc: 0.9832 - val_loss: 4.6188 - val_acc: 0.3200\n",
      "Epoch 164/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2400 - acc: 0.9706 - val_loss: 4.9882 - val_acc: 0.3200\n",
      "Epoch 165/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2216 - acc: 0.9790 - val_loss: 5.0858 - val_acc: 0.2800\n",
      "Epoch 166/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2019 - acc: 0.9874 - val_loss: 4.6582 - val_acc: 0.3200\n",
      "Epoch 167/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2159 - acc: 0.9874 - val_loss: 4.6577 - val_acc: 0.3000\n",
      "Epoch 168/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.1880 - acc: 0.9958 - val_loss: 4.4560 - val_acc: 0.3200\n",
      "Epoch 169/1000\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.1716 - acc: 1.0000 - val_loss: 4.2723 - val_acc: 0.3400\n",
      "Epoch 170/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1735 - acc: 1.0000 - val_loss: 4.3335 - val_acc: 0.3400\n",
      "Epoch 171/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1640 - acc: 1.0000 - val_loss: 4.3444 - val_acc: 0.3400\n",
      "Epoch 172/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1778 - acc: 0.9958 - val_loss: 4.4883 - val_acc: 0.3400\n",
      "Epoch 173/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1618 - acc: 1.0000 - val_loss: 4.6146 - val_acc: 0.3400\n",
      "Epoch 174/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1671 - acc: 0.9958 - val_loss: 4.6844 - val_acc: 0.3400\n",
      "Epoch 175/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1636 - acc: 1.0000 - val_loss: 4.7500 - val_acc: 0.3200\n",
      "Epoch 176/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1611 - acc: 1.0000 - val_loss: 4.7784 - val_acc: 0.3400\n",
      "Epoch 177/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1594 - acc: 1.0000 - val_loss: 4.7677 - val_acc: 0.3400\n",
      "Epoch 178/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1745 - acc: 0.9874 - val_loss: 4.6967 - val_acc: 0.3400\n",
      "Epoch 179/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1611 - acc: 1.0000 - val_loss: 4.5849 - val_acc: 0.3200\n",
      "Epoch 180/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1679 - acc: 0.9916 - val_loss: 4.5971 - val_acc: 0.3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1980 - acc: 0.9916 - val_loss: 4.5959 - val_acc: 0.3200\n",
      "Epoch 182/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1574 - acc: 1.0000 - val_loss: 4.5534 - val_acc: 0.3400\n",
      "Epoch 183/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1563 - acc: 1.0000 - val_loss: 4.5083 - val_acc: 0.3200\n",
      "Epoch 184/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1751 - acc: 0.9916 - val_loss: 4.4298 - val_acc: 0.3200\n",
      "Epoch 185/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1546 - acc: 1.0000 - val_loss: 4.2322 - val_acc: 0.3400\n",
      "Epoch 186/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1532 - acc: 1.0000 - val_loss: 4.1709 - val_acc: 0.3400\n",
      "Epoch 187/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1595 - acc: 0.9958 - val_loss: 4.1231 - val_acc: 0.3400\n",
      "Epoch 188/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1542 - acc: 1.0000 - val_loss: 4.0170 - val_acc: 0.3800\n",
      "Epoch 189/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1603 - acc: 0.9958 - val_loss: 4.0730 - val_acc: 0.3800\n",
      "Epoch 190/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1658 - acc: 0.9916 - val_loss: 4.1924 - val_acc: 0.3400\n",
      "Epoch 191/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1533 - acc: 1.0000 - val_loss: 4.9096 - val_acc: 0.3000\n",
      "Epoch 192/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1577 - acc: 0.9958 - val_loss: 5.1684 - val_acc: 0.3000\n",
      "Epoch 193/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1652 - acc: 0.9958 - val_loss: 5.2042 - val_acc: 0.3000\n",
      "Epoch 194/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1574 - acc: 0.9958 - val_loss: 4.9345 - val_acc: 0.3600\n",
      "Epoch 195/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1488 - acc: 1.0000 - val_loss: 4.7996 - val_acc: 0.3600\n",
      "Epoch 196/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1481 - acc: 1.0000 - val_loss: 4.7313 - val_acc: 0.3800\n",
      "Epoch 197/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1484 - acc: 1.0000 - val_loss: 4.6981 - val_acc: 0.3600\n",
      "Epoch 198/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1998 - acc: 0.9916 - val_loss: 4.6499 - val_acc: 0.3600\n",
      "Epoch 199/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1840 - acc: 0.9916 - val_loss: 4.8336 - val_acc: 0.3200\n",
      "Epoch 200/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1727 - acc: 0.9874 - val_loss: 5.2943 - val_acc: 0.3600\n",
      "Epoch 201/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1641 - acc: 0.9958 - val_loss: 5.5761 - val_acc: 0.3200\n",
      "Epoch 202/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1630 - acc: 0.9958 - val_loss: 5.7129 - val_acc: 0.2800\n",
      "Epoch 203/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1735 - acc: 0.9916 - val_loss: 5.7095 - val_acc: 0.2800\n",
      "Epoch 204/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.1617 - acc: 0.9916 - val_loss: 5.8181 - val_acc: 0.2800\n",
      "Epoch 205/1000\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.1814 - acc: 0.9874 - val_loss: 6.0121 - val_acc: 0.2800\n",
      "Epoch 206/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1993 - acc: 0.9748 - val_loss: 6.2472 - val_acc: 0.3000\n",
      "Epoch 207/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2049 - acc: 0.9790 - val_loss: 6.0448 - val_acc: 0.2600\n",
      "Epoch 208/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1796 - acc: 0.9874 - val_loss: 5.6689 - val_acc: 0.2600\n",
      "Epoch 209/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1477 - acc: 1.0000 - val_loss: 5.3746 - val_acc: 0.2800\n",
      "Epoch 210/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1661 - acc: 0.9916 - val_loss: 5.2674 - val_acc: 0.2800\n",
      "Epoch 211/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.1521 - acc: 1.0000 - val_loss: 5.3588 - val_acc: 0.2800\n",
      "Epoch 212/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1535 - acc: 0.9958 - val_loss: 5.3684 - val_acc: 0.2600\n",
      "Epoch 213/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1501 - acc: 0.9958 - val_loss: 5.6681 - val_acc: 0.2800\n",
      "Epoch 214/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1486 - acc: 1.0000 - val_loss: 5.4546 - val_acc: 0.2600\n",
      "Epoch 215/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1723 - acc: 0.9958 - val_loss: 5.1160 - val_acc: 0.3000\n",
      "Epoch 216/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1427 - acc: 1.0000 - val_loss: 4.9310 - val_acc: 0.3000\n",
      "Epoch 217/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1489 - acc: 0.9958 - val_loss: 4.8851 - val_acc: 0.3000\n",
      "Epoch 218/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1485 - acc: 1.0000 - val_loss: 4.8777 - val_acc: 0.3000\n",
      "Epoch 219/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1415 - acc: 1.0000 - val_loss: 4.9038 - val_acc: 0.3200\n",
      "Epoch 220/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1484 - acc: 0.9958 - val_loss: 4.8687 - val_acc: 0.3200\n",
      "Epoch 221/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1434 - acc: 1.0000 - val_loss: 4.8670 - val_acc: 0.2600\n",
      "Epoch 222/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1573 - acc: 0.9874 - val_loss: 4.7518 - val_acc: 0.2800\n",
      "Epoch 223/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1411 - acc: 1.0000 - val_loss: 4.9250 - val_acc: 0.3000\n",
      "Epoch 224/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1533 - acc: 0.9916 - val_loss: 4.9840 - val_acc: 0.2800\n",
      "Epoch 225/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1386 - acc: 1.0000 - val_loss: 4.9073 - val_acc: 0.3000\n",
      "Epoch 226/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1609 - acc: 0.9916 - val_loss: 4.9530 - val_acc: 0.3200\n",
      "Epoch 227/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1507 - acc: 0.9958 - val_loss: 4.9992 - val_acc: 0.3200\n",
      "Epoch 228/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1421 - acc: 1.0000 - val_loss: 4.9370 - val_acc: 0.3000\n",
      "Epoch 229/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.1404 - acc: 1.0000 - val_loss: 5.2897 - val_acc: 0.3200\n",
      "Epoch 230/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1608 - acc: 0.9874 - val_loss: 5.3397 - val_acc: 0.3400\n",
      "Epoch 231/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1357 - acc: 1.0000 - val_loss: 5.0789 - val_acc: 0.3800\n",
      "Epoch 232/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1507 - acc: 0.9916 - val_loss: 4.9077 - val_acc: 0.3600\n",
      "Epoch 233/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1649 - acc: 0.9916 - val_loss: 4.6184 - val_acc: 0.3400\n",
      "Epoch 234/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1533 - acc: 0.9958 - val_loss: 4.7966 - val_acc: 0.2600\n",
      "Epoch 235/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1470 - acc: 0.9958 - val_loss: 4.9642 - val_acc: 0.2600\n",
      "Epoch 236/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1575 - acc: 0.9916 - val_loss: 5.0049 - val_acc: 0.3000\n",
      "Epoch 237/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2156 - acc: 0.9748 - val_loss: 4.7919 - val_acc: 0.3000\n",
      "Epoch 238/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2975 - acc: 0.9706 - val_loss: 4.3444 - val_acc: 0.3400\n",
      "Epoch 239/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1769 - acc: 0.9874 - val_loss: 5.1869 - val_acc: 0.2800\n",
      "Epoch 240/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2674 - acc: 0.9664 - val_loss: 4.5306 - val_acc: 0.2800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2028 - acc: 0.9832 - val_loss: 4.1214 - val_acc: 0.3600\n",
      "Epoch 242/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1812 - acc: 0.9874 - val_loss: 4.4426 - val_acc: 0.3400\n",
      "Epoch 243/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1534 - acc: 0.9958 - val_loss: 4.9429 - val_acc: 0.3200\n",
      "Epoch 244/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1497 - acc: 0.9958 - val_loss: 5.2085 - val_acc: 0.3400\n",
      "Epoch 245/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1476 - acc: 0.9958 - val_loss: 5.1830 - val_acc: 0.3400\n",
      "Epoch 246/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1438 - acc: 1.0000 - val_loss: 5.0333 - val_acc: 0.3600\n",
      "Epoch 247/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1464 - acc: 0.9958 - val_loss: 4.5918 - val_acc: 0.3600\n",
      "Epoch 248/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1837 - acc: 0.9874 - val_loss: 4.5517 - val_acc: 0.3600\n",
      "Epoch 249/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1745 - acc: 0.9874 - val_loss: 4.5164 - val_acc: 0.3600\n",
      "Epoch 250/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1729 - acc: 0.9790 - val_loss: 4.6068 - val_acc: 0.3200\n",
      "Epoch 251/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1787 - acc: 0.9916 - val_loss: 4.6172 - val_acc: 0.4000\n",
      "Epoch 252/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1465 - acc: 0.9958 - val_loss: 4.5519 - val_acc: 0.3800\n",
      "Epoch 253/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1520 - acc: 0.9958 - val_loss: 4.4014 - val_acc: 0.3800\n",
      "Epoch 254/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1586 - acc: 0.9958 - val_loss: 4.3120 - val_acc: 0.3600\n",
      "Epoch 255/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1377 - acc: 1.0000 - val_loss: 4.3998 - val_acc: 0.3400\n",
      "Epoch 256/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1480 - acc: 0.9958 - val_loss: 4.4553 - val_acc: 0.3600\n",
      "Epoch 257/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1466 - acc: 0.9958 - val_loss: 4.4557 - val_acc: 0.3400\n",
      "Epoch 258/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1446 - acc: 0.9958 - val_loss: 4.3523 - val_acc: 0.3200\n",
      "Epoch 259/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1340 - acc: 1.0000 - val_loss: 4.3023 - val_acc: 0.3600\n",
      "Epoch 260/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1372 - acc: 0.9958 - val_loss: 4.3186 - val_acc: 0.3600\n",
      "Epoch 261/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1394 - acc: 0.9958 - val_loss: 4.3803 - val_acc: 0.3600\n",
      "Epoch 262/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1344 - acc: 1.0000 - val_loss: 4.3398 - val_acc: 0.3400\n",
      "Epoch 263/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1481 - acc: 0.9958 - val_loss: 4.2905 - val_acc: 0.3200\n",
      "Epoch 264/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1332 - acc: 1.0000 - val_loss: 4.2994 - val_acc: 0.3600\n",
      "Epoch 265/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1533 - acc: 0.9958 - val_loss: 4.3302 - val_acc: 0.3600\n",
      "Epoch 266/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1326 - acc: 1.0000 - val_loss: 4.6345 - val_acc: 0.3400\n",
      "Epoch 267/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1369 - acc: 0.9958 - val_loss: 4.7371 - val_acc: 0.3400\n",
      "Epoch 268/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1399 - acc: 0.9958 - val_loss: 4.7172 - val_acc: 0.3400\n",
      "Epoch 269/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1315 - acc: 1.0000 - val_loss: 4.5875 - val_acc: 0.3400\n",
      "Epoch 270/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1414 - acc: 0.9916 - val_loss: 4.4527 - val_acc: 0.3400\n",
      "Epoch 271/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1324 - acc: 1.0000 - val_loss: 4.2910 - val_acc: 0.3400\n",
      "Epoch 272/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1440 - acc: 0.9958 - val_loss: 4.4712 - val_acc: 0.3200\n",
      "Epoch 273/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1431 - acc: 0.9958 - val_loss: 4.6090 - val_acc: 0.3400\n",
      "Epoch 274/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1444 - acc: 0.9958 - val_loss: 4.4222 - val_acc: 0.3400\n",
      "Epoch 275/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1310 - acc: 1.0000 - val_loss: 4.3385 - val_acc: 0.3400\n",
      "Epoch 276/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1446 - acc: 0.9958 - val_loss: 4.4183 - val_acc: 0.3600\n",
      "Epoch 277/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1268 - acc: 1.0000 - val_loss: 4.4277 - val_acc: 0.3600\n",
      "Epoch 278/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1280 - acc: 1.0000 - val_loss: 4.3984 - val_acc: 0.3600\n",
      "Epoch 279/1000\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.1266 - acc: 1.0000 - val_loss: 4.3443 - val_acc: 0.3600\n",
      "Epoch 280/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1260 - acc: 1.0000 - val_loss: 4.3340 - val_acc: 0.3600\n",
      "Epoch 281/1000\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.1295 - acc: 1.0000 - val_loss: 4.4345 - val_acc: 0.3400\n",
      "Epoch 282/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1235 - acc: 1.0000 - val_loss: 4.5204 - val_acc: 0.3400\n",
      "Epoch 283/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1265 - acc: 0.9958 - val_loss: 4.5976 - val_acc: 0.3400\n",
      "Epoch 284/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1234 - acc: 1.0000 - val_loss: 4.8099 - val_acc: 0.3200\n",
      "Epoch 285/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1247 - acc: 1.0000 - val_loss: 4.8808 - val_acc: 0.3200\n",
      "Epoch 286/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1218 - acc: 1.0000 - val_loss: 4.8697 - val_acc: 0.3200\n",
      "Epoch 287/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1222 - acc: 1.0000 - val_loss: 4.8611 - val_acc: 0.3400\n",
      "Epoch 288/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1222 - acc: 1.0000 - val_loss: 4.8154 - val_acc: 0.3800\n",
      "Epoch 289/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1201 - acc: 1.0000 - val_loss: 4.7625 - val_acc: 0.3800\n",
      "Epoch 290/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1199 - acc: 1.0000 - val_loss: 4.7116 - val_acc: 0.3800\n",
      "Epoch 291/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1194 - acc: 1.0000 - val_loss: 4.6828 - val_acc: 0.3600\n",
      "Epoch 292/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1186 - acc: 1.0000 - val_loss: 4.6517 - val_acc: 0.3600\n",
      "Epoch 293/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1314 - acc: 0.9916 - val_loss: 4.5253 - val_acc: 0.3600\n",
      "Epoch 294/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1204 - acc: 1.0000 - val_loss: 4.2346 - val_acc: 0.4000\n",
      "Epoch 295/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1323 - acc: 0.9916 - val_loss: 4.2381 - val_acc: 0.3800\n",
      "Epoch 296/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1582 - acc: 0.9832 - val_loss: 4.1576 - val_acc: 0.3800\n",
      "Epoch 297/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1357 - acc: 0.9958 - val_loss: 3.5878 - val_acc: 0.3600\n",
      "Epoch 298/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2072 - acc: 0.9664 - val_loss: 4.5328 - val_acc: 0.3400\n",
      "Epoch 299/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1473 - acc: 0.9832 - val_loss: 5.2584 - val_acc: 0.3200\n",
      "Epoch 300/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1576 - acc: 0.9874 - val_loss: 5.4743 - val_acc: 0.3200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1237 - acc: 1.0000 - val_loss: 5.4519 - val_acc: 0.3200\n",
      "Epoch 302/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1494 - acc: 0.9874 - val_loss: 5.3388 - val_acc: 0.3000\n",
      "Epoch 303/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1333 - acc: 0.9958 - val_loss: 5.2271 - val_acc: 0.3400\n",
      "Epoch 304/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.1205 - acc: 1.0000 - val_loss: 5.0825 - val_acc: 0.3400\n",
      "Epoch 305/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1220 - acc: 1.0000 - val_loss: 5.1083 - val_acc: 0.3400\n",
      "Epoch 306/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1207 - acc: 1.0000 - val_loss: 5.1239 - val_acc: 0.3400\n",
      "Epoch 307/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1186 - acc: 1.0000 - val_loss: 5.0189 - val_acc: 0.3000\n",
      "Epoch 308/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1183 - acc: 1.0000 - val_loss: 4.9375 - val_acc: 0.3000\n",
      "Epoch 309/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1175 - acc: 1.0000 - val_loss: 4.8652 - val_acc: 0.3000\n",
      "Epoch 310/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1169 - acc: 1.0000 - val_loss: 4.8038 - val_acc: 0.3000\n",
      "Epoch 311/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1196 - acc: 1.0000 - val_loss: 4.7955 - val_acc: 0.3000\n",
      "Epoch 312/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1186 - acc: 1.0000 - val_loss: 4.9167 - val_acc: 0.3200\n",
      "Epoch 313/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1166 - acc: 1.0000 - val_loss: 4.8456 - val_acc: 0.3200\n",
      "Epoch 314/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1163 - acc: 1.0000 - val_loss: 4.7523 - val_acc: 0.3200\n",
      "Epoch 315/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1153 - acc: 1.0000 - val_loss: 4.6876 - val_acc: 0.3200\n",
      "Epoch 316/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1147 - acc: 1.0000 - val_loss: 4.6508 - val_acc: 0.3400\n",
      "Epoch 317/1000\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.1294 - acc: 0.9958 - val_loss: 4.3219 - val_acc: 0.4000\n",
      "Epoch 318/1000\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.1134 - acc: 1.0000 - val_loss: 4.2350 - val_acc: 0.3400\n",
      "Epoch 319/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.1165 - acc: 1.0000 - val_loss: 4.2043 - val_acc: 0.3600\n",
      "Epoch 320/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1302 - acc: 0.9958 - val_loss: 4.2782 - val_acc: 0.3200\n",
      "Epoch 321/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1130 - acc: 1.0000 - val_loss: 4.3456 - val_acc: 0.3200\n",
      "Epoch 322/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1183 - acc: 0.9958 - val_loss: 4.3909 - val_acc: 0.3200\n",
      "Epoch 323/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1128 - acc: 1.0000 - val_loss: 4.4040 - val_acc: 0.3200\n",
      "Epoch 324/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1109 - acc: 1.0000 - val_loss: 4.4059 - val_acc: 0.3200\n",
      "Epoch 325/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1104 - acc: 1.0000 - val_loss: 4.3981 - val_acc: 0.3200\n",
      "Epoch 326/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.1107 - acc: 1.0000 - val_loss: 4.3959 - val_acc: 0.3200\n",
      "Epoch 327/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1103 - acc: 1.0000 - val_loss: 4.4620 - val_acc: 0.3200\n",
      "Epoch 328/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1388 - acc: 0.9874 - val_loss: 4.3032 - val_acc: 0.3000\n",
      "Epoch 329/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2983 - acc: 0.9622 - val_loss: 6.4923 - val_acc: 0.2200\n",
      "Epoch 330/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2062 - acc: 0.9790 - val_loss: 6.8615 - val_acc: 0.2800\n",
      "Epoch 331/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1455 - acc: 0.9916 - val_loss: 6.0539 - val_acc: 0.2800\n",
      "Epoch 332/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1373 - acc: 0.9916 - val_loss: 5.5158 - val_acc: 0.2800\n",
      "Epoch 333/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1218 - acc: 1.0000 - val_loss: 5.2008 - val_acc: 0.3400\n",
      "Epoch 334/1000\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.1237 - acc: 0.9958 - val_loss: 4.9520 - val_acc: 0.3200\n",
      "Epoch 335/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1246 - acc: 0.9958 - val_loss: 4.7218 - val_acc: 0.3000\n",
      "Epoch 336/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1207 - acc: 0.9958 - val_loss: 4.5494 - val_acc: 0.3200\n",
      "Epoch 337/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1426 - acc: 0.9916 - val_loss: 4.6292 - val_acc: 0.3400\n",
      "Epoch 338/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1568 - acc: 0.9916 - val_loss: 4.7804 - val_acc: 0.3200\n",
      "Epoch 339/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1717 - acc: 0.9958 - val_loss: 4.8190 - val_acc: 0.3400\n",
      "Epoch 340/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1575 - acc: 0.9874 - val_loss: 4.7050 - val_acc: 0.3400\n",
      "Epoch 341/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1848 - acc: 0.9832 - val_loss: 4.4311 - val_acc: 0.3400\n",
      "Epoch 342/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1530 - acc: 0.9874 - val_loss: 4.2014 - val_acc: 0.3200\n",
      "Epoch 343/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1343 - acc: 0.9958 - val_loss: 4.0685 - val_acc: 0.3800\n",
      "Epoch 344/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1209 - acc: 1.0000 - val_loss: 4.0136 - val_acc: 0.3600\n",
      "Epoch 345/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1334 - acc: 0.9916 - val_loss: 3.9643 - val_acc: 0.3400\n",
      "Epoch 346/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1185 - acc: 1.0000 - val_loss: 3.9812 - val_acc: 0.3400\n",
      "Epoch 347/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1428 - acc: 0.9958 - val_loss: 4.0624 - val_acc: 0.3200\n",
      "Epoch 348/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1495 - acc: 0.9958 - val_loss: 4.3748 - val_acc: 0.2600\n",
      "Epoch 349/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1200 - acc: 1.0000 - val_loss: 4.2149 - val_acc: 0.2600\n",
      "Epoch 350/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1604 - acc: 0.9832 - val_loss: 4.1458 - val_acc: 0.2400\n",
      "Epoch 351/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1257 - acc: 0.9958 - val_loss: 4.0700 - val_acc: 0.3200\n",
      "Epoch 352/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1741 - acc: 0.9790 - val_loss: 3.6437 - val_acc: 0.2800\n",
      "Epoch 353/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1178 - acc: 1.0000 - val_loss: 3.3308 - val_acc: 0.3000\n",
      "Epoch 354/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1214 - acc: 0.9958 - val_loss: 3.3437 - val_acc: 0.3200\n",
      "Epoch 355/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1259 - acc: 0.9916 - val_loss: 3.3826 - val_acc: 0.3200\n",
      "Epoch 356/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1233 - acc: 0.9958 - val_loss: 3.3707 - val_acc: 0.3000\n",
      "Epoch 357/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1188 - acc: 1.0000 - val_loss: 3.4034 - val_acc: 0.3000\n",
      "Epoch 358/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1151 - acc: 1.0000 - val_loss: 3.4422 - val_acc: 0.3000\n",
      "Epoch 359/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1157 - acc: 1.0000 - val_loss: 3.4870 - val_acc: 0.3400\n",
      "Epoch 360/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1195 - acc: 1.0000 - val_loss: 3.6127 - val_acc: 0.3400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1142 - acc: 1.0000 - val_loss: 3.8129 - val_acc: 0.3000\n",
      "Epoch 362/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1138 - acc: 1.0000 - val_loss: 3.9058 - val_acc: 0.2800\n",
      "Epoch 363/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1201 - acc: 0.9958 - val_loss: 3.9078 - val_acc: 0.3200\n",
      "Epoch 364/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1109 - acc: 1.0000 - val_loss: 3.9058 - val_acc: 0.3400\n",
      "Epoch 365/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1120 - acc: 1.0000 - val_loss: 3.9142 - val_acc: 0.3400\n",
      "Epoch 366/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1096 - acc: 1.0000 - val_loss: 3.8672 - val_acc: 0.3400\n",
      "Epoch 367/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1108 - acc: 1.0000 - val_loss: 3.8188 - val_acc: 0.3600\n",
      "Epoch 368/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1088 - acc: 1.0000 - val_loss: 3.6506 - val_acc: 0.3600\n",
      "Epoch 369/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1086 - acc: 1.0000 - val_loss: 3.5739 - val_acc: 0.3600\n",
      "Epoch 370/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1093 - acc: 1.0000 - val_loss: 3.5521 - val_acc: 0.3600\n",
      "Epoch 371/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1080 - acc: 1.0000 - val_loss: 3.5454 - val_acc: 0.3400\n",
      "Epoch 372/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1067 - acc: 1.0000 - val_loss: 3.5354 - val_acc: 0.3400\n",
      "Epoch 373/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1062 - acc: 1.0000 - val_loss: 3.5241 - val_acc: 0.3600\n",
      "Epoch 374/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1065 - acc: 1.0000 - val_loss: 3.5236 - val_acc: 0.3600\n",
      "Epoch 375/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1053 - acc: 1.0000 - val_loss: 3.5040 - val_acc: 0.3600\n",
      "Epoch 376/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1047 - acc: 1.0000 - val_loss: 3.4931 - val_acc: 0.3600\n",
      "Epoch 377/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1044 - acc: 1.0000 - val_loss: 3.4885 - val_acc: 0.3600\n",
      "Epoch 378/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1041 - acc: 1.0000 - val_loss: 3.4963 - val_acc: 0.3600\n",
      "Epoch 379/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1038 - acc: 1.0000 - val_loss: 3.5172 - val_acc: 0.3600\n",
      "Epoch 380/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1057 - acc: 1.0000 - val_loss: 3.5510 - val_acc: 0.3600\n",
      "Epoch 381/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1029 - acc: 1.0000 - val_loss: 3.9175 - val_acc: 0.3600\n",
      "Epoch 382/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1140 - acc: 0.9958 - val_loss: 4.0967 - val_acc: 0.3600\n",
      "Epoch 383/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1048 - acc: 1.0000 - val_loss: 4.1305 - val_acc: 0.3800\n",
      "Epoch 384/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1048 - acc: 1.0000 - val_loss: 4.1011 - val_acc: 0.3800\n",
      "Epoch 385/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1034 - acc: 1.0000 - val_loss: 3.9648 - val_acc: 0.3800\n",
      "Epoch 386/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1018 - acc: 1.0000 - val_loss: 3.8769 - val_acc: 0.4000\n",
      "Epoch 387/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1021 - acc: 1.0000 - val_loss: 3.8414 - val_acc: 0.4000\n",
      "Epoch 388/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1008 - acc: 1.0000 - val_loss: 3.8087 - val_acc: 0.4000\n",
      "Epoch 389/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1003 - acc: 1.0000 - val_loss: 3.7864 - val_acc: 0.4000\n",
      "Epoch 390/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1147 - acc: 0.9958 - val_loss: 3.7567 - val_acc: 0.3800\n",
      "Epoch 391/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1123 - acc: 0.9958 - val_loss: 3.8149 - val_acc: 0.3400\n",
      "Epoch 392/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1181 - acc: 0.9958 - val_loss: 4.1153 - val_acc: 0.2800\n",
      "Epoch 393/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1153 - acc: 0.9874 - val_loss: 4.1932 - val_acc: 0.2600\n",
      "Epoch 394/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1033 - acc: 1.0000 - val_loss: 4.3624 - val_acc: 0.2800\n",
      "Epoch 395/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1236 - acc: 0.9916 - val_loss: 4.3141 - val_acc: 0.2800\n",
      "Epoch 396/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1202 - acc: 0.9916 - val_loss: 4.1145 - val_acc: 0.3200\n",
      "Epoch 397/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1901 - acc: 0.9874 - val_loss: 4.2427 - val_acc: 0.3000\n",
      "Epoch 398/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2296 - acc: 0.9748 - val_loss: 4.6320 - val_acc: 0.3000\n",
      "Epoch 399/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.4662 - acc: 0.9118 - val_loss: 4.8926 - val_acc: 0.2600\n",
      "Epoch 400/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2156 - acc: 0.9832 - val_loss: 5.9358 - val_acc: 0.2000\n",
      "Epoch 401/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2149 - acc: 0.9538 - val_loss: 6.0269 - val_acc: 0.2200\n",
      "Epoch 402/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1850 - acc: 0.9832 - val_loss: 5.9675 - val_acc: 0.2400\n",
      "Epoch 403/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2113 - acc: 0.9790 - val_loss: 5.9150 - val_acc: 0.2000\n",
      "Epoch 404/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1475 - acc: 0.9958 - val_loss: 5.7558 - val_acc: 0.2600\n",
      "Epoch 405/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1268 - acc: 1.0000 - val_loss: 5.6261 - val_acc: 0.2600\n",
      "Epoch 406/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1452 - acc: 0.9916 - val_loss: 5.5787 - val_acc: 0.2800\n",
      "Epoch 407/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1417 - acc: 0.9958 - val_loss: 5.9571 - val_acc: 0.2600\n",
      "Epoch 408/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1243 - acc: 1.0000 - val_loss: 6.1045 - val_acc: 0.2800\n",
      "Epoch 409/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1271 - acc: 0.9958 - val_loss: 6.2158 - val_acc: 0.2600\n",
      "Epoch 410/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1338 - acc: 0.9916 - val_loss: 6.1043 - val_acc: 0.2400\n",
      "Epoch 411/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1187 - acc: 1.0000 - val_loss: 5.4356 - val_acc: 0.3000\n",
      "Epoch 412/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1236 - acc: 1.0000 - val_loss: 5.1890 - val_acc: 0.3200\n",
      "Epoch 413/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1381 - acc: 0.9958 - val_loss: 4.9592 - val_acc: 0.3200\n",
      "Epoch 414/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1184 - acc: 1.0000 - val_loss: 4.5821 - val_acc: 0.3200\n",
      "Epoch 415/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1415 - acc: 0.9874 - val_loss: 4.6032 - val_acc: 0.3200\n",
      "Epoch 416/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1173 - acc: 1.0000 - val_loss: 4.5836 - val_acc: 0.3000\n",
      "Epoch 417/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1185 - acc: 1.0000 - val_loss: 4.6721 - val_acc: 0.3000\n",
      "Epoch 418/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1143 - acc: 1.0000 - val_loss: 4.6728 - val_acc: 0.3000\n",
      "Epoch 419/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1148 - acc: 1.0000 - val_loss: 4.6427 - val_acc: 0.3000\n",
      "Epoch 420/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1165 - acc: 1.0000 - val_loss: 4.5992 - val_acc: 0.2800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1182 - acc: 1.0000 - val_loss: 4.6258 - val_acc: 0.2200\n",
      "Epoch 422/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1115 - acc: 1.0000 - val_loss: 4.6179 - val_acc: 0.2200\n",
      "Epoch 423/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1118 - acc: 1.0000 - val_loss: 4.6078 - val_acc: 0.2200\n",
      "Epoch 424/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1132 - acc: 1.0000 - val_loss: 4.5791 - val_acc: 0.2200\n",
      "Epoch 425/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1099 - acc: 1.0000 - val_loss: 4.5964 - val_acc: 0.2400\n",
      "Epoch 426/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1094 - acc: 1.0000 - val_loss: 4.5884 - val_acc: 0.2400\n",
      "Epoch 427/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1100 - acc: 1.0000 - val_loss: 4.6118 - val_acc: 0.2400\n",
      "Epoch 428/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1089 - acc: 1.0000 - val_loss: 4.5979 - val_acc: 0.2600\n",
      "Epoch 429/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1346 - acc: 0.9916 - val_loss: 4.6715 - val_acc: 0.2400\n",
      "Epoch 430/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1281 - acc: 0.9916 - val_loss: 4.6358 - val_acc: 0.2600\n",
      "Epoch 431/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1076 - acc: 1.0000 - val_loss: 4.3929 - val_acc: 0.2200\n",
      "Epoch 432/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1076 - acc: 1.0000 - val_loss: 4.2822 - val_acc: 0.2400\n",
      "Epoch 433/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1131 - acc: 1.0000 - val_loss: 4.2382 - val_acc: 0.2400\n",
      "Epoch 434/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1087 - acc: 1.0000 - val_loss: 4.1049 - val_acc: 0.2600\n",
      "Epoch 435/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1065 - acc: 1.0000 - val_loss: 4.0459 - val_acc: 0.2600\n",
      "Epoch 436/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1163 - acc: 0.9958 - val_loss: 4.2172 - val_acc: 0.2600\n",
      "Epoch 437/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1168 - acc: 0.9958 - val_loss: 4.4992 - val_acc: 0.2400\n",
      "Epoch 438/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1272 - acc: 0.9958 - val_loss: 4.5977 - val_acc: 0.2200\n",
      "Epoch 439/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1060 - acc: 1.0000 - val_loss: 4.6259 - val_acc: 0.2200\n",
      "Epoch 440/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1061 - acc: 1.0000 - val_loss: 4.6163 - val_acc: 0.2600\n",
      "Epoch 441/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1051 - acc: 1.0000 - val_loss: 4.6873 - val_acc: 0.2600\n",
      "Epoch 442/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1042 - acc: 1.0000 - val_loss: 4.7053 - val_acc: 0.2600\n",
      "Epoch 443/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1034 - acc: 1.0000 - val_loss: 4.6832 - val_acc: 0.2600\n",
      "Epoch 444/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1040 - acc: 1.0000 - val_loss: 4.6233 - val_acc: 0.2600\n",
      "Epoch 445/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1031 - acc: 1.0000 - val_loss: 4.5596 - val_acc: 0.2600\n",
      "Epoch 446/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1023 - acc: 1.0000 - val_loss: 4.5373 - val_acc: 0.2600\n",
      "Epoch 447/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1014 - acc: 1.0000 - val_loss: 4.5652 - val_acc: 0.2600\n",
      "Epoch 448/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1009 - acc: 1.0000 - val_loss: 4.5564 - val_acc: 0.2400\n",
      "Epoch 449/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1005 - acc: 1.0000 - val_loss: 4.5410 - val_acc: 0.2400\n",
      "Epoch 450/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1000 - acc: 1.0000 - val_loss: 4.5205 - val_acc: 0.2400\n",
      "Epoch 451/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0999 - acc: 1.0000 - val_loss: 4.4942 - val_acc: 0.2400\n",
      "Epoch 452/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0991 - acc: 1.0000 - val_loss: 4.4340 - val_acc: 0.2600\n",
      "Epoch 453/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0986 - acc: 1.0000 - val_loss: 4.3875 - val_acc: 0.2600\n",
      "Epoch 454/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0989 - acc: 1.0000 - val_loss: 4.3342 - val_acc: 0.2800\n",
      "Epoch 455/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0978 - acc: 1.0000 - val_loss: 4.3099 - val_acc: 0.2800\n",
      "Epoch 456/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0987 - acc: 1.0000 - val_loss: 4.2830 - val_acc: 0.3000\n",
      "Epoch 457/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0972 - acc: 1.0000 - val_loss: 4.2780 - val_acc: 0.3000\n",
      "Epoch 458/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1326 - acc: 0.9916 - val_loss: 4.1907 - val_acc: 0.3000\n",
      "Epoch 459/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3159 - acc: 0.9496 - val_loss: 4.2423 - val_acc: 0.2600\n",
      "Epoch 460/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1491 - acc: 0.9832 - val_loss: 5.0256 - val_acc: 0.2600\n",
      "Epoch 461/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1707 - acc: 0.9706 - val_loss: 4.3521 - val_acc: 0.3200\n",
      "Epoch 462/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1317 - acc: 0.9916 - val_loss: 4.5218 - val_acc: 0.3200\n",
      "Epoch 463/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1336 - acc: 0.9916 - val_loss: 4.5337 - val_acc: 0.3000\n",
      "Epoch 464/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1370 - acc: 0.9916 - val_loss: 4.4379 - val_acc: 0.3000\n",
      "Epoch 465/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1236 - acc: 0.9958 - val_loss: 4.2995 - val_acc: 0.3200\n",
      "Epoch 466/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1211 - acc: 0.9958 - val_loss: 4.0569 - val_acc: 0.3000\n",
      "Epoch 467/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1186 - acc: 1.0000 - val_loss: 3.9693 - val_acc: 0.3000\n",
      "Epoch 468/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1127 - acc: 1.0000 - val_loss: 3.9708 - val_acc: 0.3600\n",
      "Epoch 469/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1103 - acc: 1.0000 - val_loss: 4.0790 - val_acc: 0.2800\n",
      "Epoch 470/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1108 - acc: 1.0000 - val_loss: 4.1677 - val_acc: 0.2800\n",
      "Epoch 471/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1149 - acc: 0.9958 - val_loss: 4.0485 - val_acc: 0.3000\n",
      "Epoch 472/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1083 - acc: 1.0000 - val_loss: 3.8646 - val_acc: 0.2800\n",
      "Epoch 473/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1070 - acc: 1.0000 - val_loss: 3.7786 - val_acc: 0.3000\n",
      "Epoch 474/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1054 - acc: 1.0000 - val_loss: 3.7777 - val_acc: 0.3200\n",
      "Epoch 475/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1050 - acc: 1.0000 - val_loss: 3.7727 - val_acc: 0.3200\n",
      "Epoch 476/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1045 - acc: 1.0000 - val_loss: 3.7709 - val_acc: 0.3200\n",
      "Epoch 477/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1036 - acc: 1.0000 - val_loss: 3.7792 - val_acc: 0.3200\n",
      "Epoch 478/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1108 - acc: 0.9958 - val_loss: 3.7800 - val_acc: 0.3200\n",
      "Epoch 479/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1040 - acc: 1.0000 - val_loss: 4.2806 - val_acc: 0.2600\n",
      "Epoch 480/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1298 - acc: 0.9874 - val_loss: 4.1033 - val_acc: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1147 - acc: 0.9958 - val_loss: 4.1223 - val_acc: 0.2400\n",
      "Epoch 482/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1065 - acc: 1.0000 - val_loss: 4.2189 - val_acc: 0.2200\n",
      "Epoch 483/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.2522 - acc: 0.9706 - val_loss: 4.3803 - val_acc: 0.2600\n",
      "Epoch 484/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2525 - acc: 0.9622 - val_loss: 5.2174 - val_acc: 0.2800\n",
      "Epoch 485/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1534 - acc: 0.9832 - val_loss: 5.1941 - val_acc: 0.2800\n",
      "Epoch 486/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1462 - acc: 0.9874 - val_loss: 5.1247 - val_acc: 0.2200\n",
      "Epoch 487/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2092 - acc: 0.9748 - val_loss: 5.4484 - val_acc: 0.2000\n",
      "Epoch 488/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2558 - acc: 0.9748 - val_loss: 5.3327 - val_acc: 0.2400\n",
      "Epoch 489/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1322 - acc: 0.9916 - val_loss: 6.3645 - val_acc: 0.2400\n",
      "Epoch 490/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2029 - acc: 0.9790 - val_loss: 5.6609 - val_acc: 0.2400\n",
      "Epoch 491/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1463 - acc: 0.9916 - val_loss: 5.0146 - val_acc: 0.2600\n",
      "Epoch 492/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1367 - acc: 0.9916 - val_loss: 4.7465 - val_acc: 0.2400\n",
      "Epoch 493/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1203 - acc: 1.0000 - val_loss: 4.5877 - val_acc: 0.2200\n",
      "Epoch 494/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1291 - acc: 0.9958 - val_loss: 4.4316 - val_acc: 0.2200\n",
      "Epoch 495/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1245 - acc: 0.9958 - val_loss: 4.2538 - val_acc: 0.2400\n",
      "Epoch 496/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1160 - acc: 1.0000 - val_loss: 4.1721 - val_acc: 0.2800\n",
      "Epoch 497/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1148 - acc: 1.0000 - val_loss: 4.1324 - val_acc: 0.2800\n",
      "Epoch 498/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1695 - acc: 0.9958 - val_loss: 4.0709 - val_acc: 0.2800\n",
      "Epoch 499/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1204 - acc: 1.0000 - val_loss: 4.2403 - val_acc: 0.2800\n",
      "Epoch 500/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2031 - acc: 0.9748 - val_loss: 4.1251 - val_acc: 0.2600\n",
      "Epoch 501/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1254 - acc: 0.9958 - val_loss: 4.1376 - val_acc: 0.2400\n",
      "Epoch 502/1000\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.1185 - acc: 1.0000 - val_loss: 4.4520 - val_acc: 0.2600\n",
      "Epoch 503/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1488 - acc: 0.9916 - val_loss: 4.5738 - val_acc: 0.2800\n",
      "Epoch 504/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1136 - acc: 1.0000 - val_loss: 4.5086 - val_acc: 0.2800\n",
      "Epoch 505/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1205 - acc: 0.9958 - val_loss: 4.3665 - val_acc: 0.2600\n",
      "Epoch 506/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1153 - acc: 1.0000 - val_loss: 4.1327 - val_acc: 0.2600\n",
      "Epoch 507/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1154 - acc: 1.0000 - val_loss: 4.0627 - val_acc: 0.2600\n",
      "Epoch 508/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1155 - acc: 0.9958 - val_loss: 4.1130 - val_acc: 0.2400\n",
      "Epoch 509/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1105 - acc: 1.0000 - val_loss: 4.2310 - val_acc: 0.2400\n",
      "Epoch 510/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1174 - acc: 0.9958 - val_loss: 4.3244 - val_acc: 0.2200\n",
      "Epoch 511/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1259 - acc: 0.9916 - val_loss: 4.4254 - val_acc: 0.2200\n",
      "Epoch 512/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1335 - acc: 0.9874 - val_loss: 4.7480 - val_acc: 0.2000\n",
      "Epoch 513/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1245 - acc: 0.9958 - val_loss: 4.9943 - val_acc: 0.2000\n",
      "Epoch 514/1000\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.1587 - acc: 0.9916 - val_loss: 4.9450 - val_acc: 0.1800\n",
      "Epoch 515/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1147 - acc: 1.0000 - val_loss: 4.9232 - val_acc: 0.1600\n",
      "Epoch 516/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1310 - acc: 0.9916 - val_loss: 4.8701 - val_acc: 0.1600\n",
      "Epoch 517/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1434 - acc: 0.9958 - val_loss: 4.7356 - val_acc: 0.2000\n",
      "Epoch 518/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1152 - acc: 1.0000 - val_loss: 4.6371 - val_acc: 0.2200\n",
      "Epoch 519/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1132 - acc: 1.0000 - val_loss: 4.6246 - val_acc: 0.2000\n",
      "Epoch 520/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1090 - acc: 1.0000 - val_loss: 4.5879 - val_acc: 0.2200\n",
      "Epoch 521/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1122 - acc: 1.0000 - val_loss: 4.5838 - val_acc: 0.2200\n",
      "Epoch 522/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1092 - acc: 1.0000 - val_loss: 4.5917 - val_acc: 0.2200\n",
      "Epoch 523/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1094 - acc: 1.0000 - val_loss: 4.6210 - val_acc: 0.2200\n",
      "Epoch 524/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1071 - acc: 1.0000 - val_loss: 4.6172 - val_acc: 0.2400\n",
      "Epoch 525/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1069 - acc: 1.0000 - val_loss: 4.6131 - val_acc: 0.2400\n",
      "Epoch 526/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1056 - acc: 1.0000 - val_loss: 4.5931 - val_acc: 0.2600\n",
      "Epoch 527/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1053 - acc: 1.0000 - val_loss: 4.5808 - val_acc: 0.2400\n",
      "Epoch 528/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1053 - acc: 1.0000 - val_loss: 4.5726 - val_acc: 0.2400\n",
      "Epoch 529/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1056 - acc: 1.0000 - val_loss: 4.5611 - val_acc: 0.2400\n",
      "Epoch 530/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1046 - acc: 1.0000 - val_loss: 4.5430 - val_acc: 0.2400\n",
      "Epoch 531/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1036 - acc: 1.0000 - val_loss: 4.5190 - val_acc: 0.2400\n",
      "Epoch 532/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1030 - acc: 1.0000 - val_loss: 4.5231 - val_acc: 0.2800\n",
      "Epoch 533/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1097 - acc: 0.9958 - val_loss: 4.4742 - val_acc: 0.2600\n",
      "Epoch 534/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1021 - acc: 1.0000 - val_loss: 4.3391 - val_acc: 0.2600\n",
      "Epoch 535/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1944 - acc: 0.9832 - val_loss: 4.1955 - val_acc: 0.3000\n",
      "Epoch 536/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1240 - acc: 0.9958 - val_loss: 4.0937 - val_acc: 0.2400\n",
      "Epoch 537/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1203 - acc: 0.9958 - val_loss: 3.9315 - val_acc: 0.2200\n",
      "Epoch 538/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1190 - acc: 0.9958 - val_loss: 3.8274 - val_acc: 0.2400\n",
      "Epoch 539/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1200 - acc: 0.9958 - val_loss: 3.9312 - val_acc: 0.2400\n",
      "Epoch 540/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1030 - acc: 1.0000 - val_loss: 4.0117 - val_acc: 0.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1177 - acc: 0.9958 - val_loss: 4.0158 - val_acc: 0.2400\n",
      "Epoch 542/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1031 - acc: 1.0000 - val_loss: 3.9585 - val_acc: 0.2800\n",
      "Epoch 543/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1067 - acc: 0.9958 - val_loss: 3.9025 - val_acc: 0.2800\n",
      "Epoch 544/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1020 - acc: 1.0000 - val_loss: 3.8760 - val_acc: 0.2800\n",
      "Epoch 545/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1010 - acc: 1.0000 - val_loss: 3.8910 - val_acc: 0.2800\n",
      "Epoch 546/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1003 - acc: 1.0000 - val_loss: 3.9168 - val_acc: 0.2800\n",
      "Epoch 547/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1027 - acc: 0.9958 - val_loss: 3.9084 - val_acc: 0.2600\n",
      "Epoch 548/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0990 - acc: 1.0000 - val_loss: 3.8027 - val_acc: 0.2600\n",
      "Epoch 549/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0988 - acc: 1.0000 - val_loss: 3.7645 - val_acc: 0.2800\n",
      "Epoch 550/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0994 - acc: 1.0000 - val_loss: 3.7235 - val_acc: 0.2800\n",
      "Epoch 551/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0986 - acc: 1.0000 - val_loss: 3.7251 - val_acc: 0.2800\n",
      "Epoch 552/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0982 - acc: 1.0000 - val_loss: 3.7435 - val_acc: 0.2800\n",
      "Epoch 553/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0984 - acc: 1.0000 - val_loss: 3.7905 - val_acc: 0.3000\n",
      "Epoch 554/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0983 - acc: 1.0000 - val_loss: 3.8636 - val_acc: 0.3000\n",
      "Epoch 555/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1025 - acc: 0.9958 - val_loss: 4.0473 - val_acc: 0.3000\n",
      "Epoch 556/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0963 - acc: 1.0000 - val_loss: 4.2674 - val_acc: 0.2800\n",
      "Epoch 557/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0964 - acc: 1.0000 - val_loss: 4.3585 - val_acc: 0.2800\n",
      "Epoch 558/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0965 - acc: 1.0000 - val_loss: 4.3762 - val_acc: 0.2800\n",
      "Epoch 559/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1024 - acc: 0.9958 - val_loss: 4.0969 - val_acc: 0.2800\n",
      "Epoch 560/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0956 - acc: 1.0000 - val_loss: 3.9903 - val_acc: 0.2600\n",
      "Epoch 561/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0995 - acc: 1.0000 - val_loss: 3.6792 - val_acc: 0.2800\n",
      "Epoch 562/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1117 - acc: 0.9958 - val_loss: 3.5468 - val_acc: 0.3000\n",
      "Epoch 563/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0949 - acc: 1.0000 - val_loss: 3.5185 - val_acc: 0.3000\n",
      "Epoch 564/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1302 - acc: 0.9874 - val_loss: 4.0076 - val_acc: 0.3200\n",
      "Epoch 565/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1053 - acc: 0.9958 - val_loss: 4.6190 - val_acc: 0.3000\n",
      "Epoch 566/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0982 - acc: 1.0000 - val_loss: 4.8352 - val_acc: 0.2400\n",
      "Epoch 567/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0967 - acc: 1.0000 - val_loss: 4.7203 - val_acc: 0.2800\n",
      "Epoch 568/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1286 - acc: 0.9958 - val_loss: 4.6931 - val_acc: 0.2800\n",
      "Epoch 569/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0958 - acc: 1.0000 - val_loss: 4.7156 - val_acc: 0.2800\n",
      "Epoch 570/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0965 - acc: 1.0000 - val_loss: 4.6780 - val_acc: 0.2800\n",
      "Epoch 571/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0954 - acc: 1.0000 - val_loss: 4.6362 - val_acc: 0.2800\n",
      "Epoch 572/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0978 - acc: 1.0000 - val_loss: 4.6311 - val_acc: 0.2800\n",
      "Epoch 573/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0949 - acc: 1.0000 - val_loss: 4.6262 - val_acc: 0.2800\n",
      "Epoch 574/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0940 - acc: 1.0000 - val_loss: 4.6069 - val_acc: 0.2800\n",
      "Epoch 575/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0938 - acc: 1.0000 - val_loss: 4.5916 - val_acc: 0.2800\n",
      "Epoch 576/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0935 - acc: 1.0000 - val_loss: 4.5673 - val_acc: 0.2800\n",
      "Epoch 577/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0928 - acc: 1.0000 - val_loss: 4.5443 - val_acc: 0.2800\n",
      "Epoch 578/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0931 - acc: 1.0000 - val_loss: 4.5181 - val_acc: 0.2800\n",
      "Epoch 579/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0916 - acc: 1.0000 - val_loss: 4.4878 - val_acc: 0.2800\n",
      "Epoch 580/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0913 - acc: 1.0000 - val_loss: 4.4715 - val_acc: 0.2800\n",
      "Epoch 581/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0917 - acc: 1.0000 - val_loss: 4.4691 - val_acc: 0.2800\n",
      "Epoch 582/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1061 - acc: 0.9916 - val_loss: 4.5440 - val_acc: 0.2800\n",
      "Epoch 583/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1553 - acc: 0.9832 - val_loss: 4.9818 - val_acc: 0.2800\n",
      "Epoch 584/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1225 - acc: 0.9832 - val_loss: 5.4000 - val_acc: 0.3000\n",
      "Epoch 585/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1352 - acc: 0.9874 - val_loss: 5.2422 - val_acc: 0.3000\n",
      "Epoch 586/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1278 - acc: 0.9916 - val_loss: 5.2558 - val_acc: 0.2800\n",
      "Epoch 587/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1476 - acc: 0.9832 - val_loss: 5.0379 - val_acc: 0.2800\n",
      "Epoch 588/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1107 - acc: 0.9958 - val_loss: 5.2956 - val_acc: 0.2600\n",
      "Epoch 589/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1161 - acc: 0.9958 - val_loss: 5.5938 - val_acc: 0.2600\n",
      "Epoch 590/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1166 - acc: 0.9958 - val_loss: 5.6911 - val_acc: 0.2600\n",
      "Epoch 591/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1180 - acc: 0.9916 - val_loss: 5.4719 - val_acc: 0.2400\n",
      "Epoch 592/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1167 - acc: 0.9958 - val_loss: 5.7184 - val_acc: 0.2000\n",
      "Epoch 593/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1136 - acc: 0.9916 - val_loss: 6.0688 - val_acc: 0.2000\n",
      "Epoch 594/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1122 - acc: 1.0000 - val_loss: 5.9662 - val_acc: 0.1800\n",
      "Epoch 595/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1072 - acc: 0.9958 - val_loss: 5.3710 - val_acc: 0.2600\n",
      "Epoch 596/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1410 - acc: 0.9958 - val_loss: 5.2668 - val_acc: 0.2600\n",
      "Epoch 597/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1150 - acc: 0.9958 - val_loss: 5.6579 - val_acc: 0.2200\n",
      "Epoch 598/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1279 - acc: 0.9874 - val_loss: 5.4874 - val_acc: 0.1600\n",
      "Epoch 599/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1071 - acc: 1.0000 - val_loss: 5.2931 - val_acc: 0.1600\n",
      "Epoch 600/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1126 - acc: 0.9958 - val_loss: 4.9438 - val_acc: 0.1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1131 - acc: 0.9958 - val_loss: 4.8299 - val_acc: 0.2200\n",
      "Epoch 602/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1044 - acc: 1.0000 - val_loss: 4.8338 - val_acc: 0.2000\n",
      "Epoch 603/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1033 - acc: 1.0000 - val_loss: 4.9380 - val_acc: 0.2000\n",
      "Epoch 604/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0997 - acc: 1.0000 - val_loss: 4.9612 - val_acc: 0.2200\n",
      "Epoch 605/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1128 - acc: 0.9958 - val_loss: 5.0029 - val_acc: 0.1800\n",
      "Epoch 606/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0996 - acc: 1.0000 - val_loss: 4.9988 - val_acc: 0.1800\n",
      "Epoch 607/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1130 - acc: 0.9958 - val_loss: 4.8164 - val_acc: 0.2200\n",
      "Epoch 608/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1122 - acc: 0.9958 - val_loss: 4.7727 - val_acc: 0.2200\n",
      "Epoch 609/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1334 - acc: 0.9874 - val_loss: 4.6652 - val_acc: 0.2200\n",
      "Epoch 610/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1625 - acc: 0.9832 - val_loss: 4.7164 - val_acc: 0.2400\n",
      "Epoch 611/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1361 - acc: 0.9874 - val_loss: 4.5251 - val_acc: 0.2200\n",
      "Epoch 612/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1101 - acc: 0.9958 - val_loss: 4.2988 - val_acc: 0.2200\n",
      "Epoch 613/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1475 - acc: 0.9874 - val_loss: 5.1813 - val_acc: 0.1800\n",
      "Epoch 614/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1530 - acc: 0.9874 - val_loss: 5.9760 - val_acc: 0.2200\n",
      "Epoch 615/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1093 - acc: 1.0000 - val_loss: 6.1433 - val_acc: 0.2200\n",
      "Epoch 616/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1522 - acc: 0.9832 - val_loss: 6.0017 - val_acc: 0.2200\n",
      "Epoch 617/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1276 - acc: 0.9958 - val_loss: 5.7412 - val_acc: 0.2400\n",
      "Epoch 618/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1074 - acc: 1.0000 - val_loss: 5.6748 - val_acc: 0.2400\n",
      "Epoch 619/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1053 - acc: 1.0000 - val_loss: 5.5619 - val_acc: 0.2400\n",
      "Epoch 620/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1260 - acc: 0.9916 - val_loss: 5.1984 - val_acc: 0.2600\n",
      "Epoch 621/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1308 - acc: 0.9958 - val_loss: 5.0890 - val_acc: 0.2800\n",
      "Epoch 622/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1076 - acc: 1.0000 - val_loss: 5.2367 - val_acc: 0.2600\n",
      "Epoch 623/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2134 - acc: 0.9790 - val_loss: 5.2217 - val_acc: 0.2800\n",
      "Epoch 624/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1077 - acc: 1.0000 - val_loss: 4.6033 - val_acc: 0.3200\n",
      "Epoch 625/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1795 - acc: 0.9748 - val_loss: 4.5906 - val_acc: 0.3000\n",
      "Epoch 626/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1085 - acc: 1.0000 - val_loss: 4.2711 - val_acc: 0.3400\n",
      "Epoch 627/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1385 - acc: 0.9832 - val_loss: 4.3110 - val_acc: 0.3600\n",
      "Epoch 628/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1529 - acc: 0.9874 - val_loss: 4.5293 - val_acc: 0.3600\n",
      "Epoch 629/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1621 - acc: 0.9874 - val_loss: 4.5961 - val_acc: 0.3400\n",
      "Epoch 630/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1582 - acc: 0.9874 - val_loss: 4.5817 - val_acc: 0.4200\n",
      "Epoch 631/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1533 - acc: 0.9874 - val_loss: 4.4030 - val_acc: 0.4000\n",
      "Epoch 632/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1200 - acc: 0.9958 - val_loss: 4.2690 - val_acc: 0.4000\n",
      "Epoch 633/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1141 - acc: 1.0000 - val_loss: 4.1593 - val_acc: 0.4000\n",
      "Epoch 634/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1173 - acc: 1.0000 - val_loss: 4.1789 - val_acc: 0.3600\n",
      "Epoch 635/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1147 - acc: 1.0000 - val_loss: 4.1837 - val_acc: 0.3600\n",
      "Epoch 636/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1163 - acc: 0.9958 - val_loss: 4.1524 - val_acc: 0.3800\n",
      "Epoch 637/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1099 - acc: 1.0000 - val_loss: 4.1504 - val_acc: 0.3600\n",
      "Epoch 638/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1137 - acc: 1.0000 - val_loss: 4.0856 - val_acc: 0.3600\n",
      "Epoch 639/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1101 - acc: 1.0000 - val_loss: 4.0314 - val_acc: 0.3800\n",
      "Epoch 640/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1078 - acc: 1.0000 - val_loss: 3.9516 - val_acc: 0.3600\n",
      "Epoch 641/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1072 - acc: 1.0000 - val_loss: 3.9138 - val_acc: 0.3800\n",
      "Epoch 642/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1093 - acc: 1.0000 - val_loss: 3.8475 - val_acc: 0.3800\n",
      "Epoch 643/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1069 - acc: 1.0000 - val_loss: 3.8111 - val_acc: 0.3800\n",
      "Epoch 644/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1057 - acc: 1.0000 - val_loss: 3.7980 - val_acc: 0.3800\n",
      "Epoch 645/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1049 - acc: 1.0000 - val_loss: 3.7886 - val_acc: 0.3800\n",
      "Epoch 646/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1065 - acc: 1.0000 - val_loss: 3.7725 - val_acc: 0.3800\n",
      "Epoch 647/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1063 - acc: 1.0000 - val_loss: 3.7569 - val_acc: 0.4000\n",
      "Epoch 648/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1043 - acc: 1.0000 - val_loss: 3.7617 - val_acc: 0.4000\n",
      "Epoch 649/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1157 - acc: 0.9958 - val_loss: 3.7481 - val_acc: 0.4000\n",
      "Epoch 650/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1034 - acc: 1.0000 - val_loss: 3.7494 - val_acc: 0.3400\n",
      "Epoch 651/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1032 - acc: 1.0000 - val_loss: 3.7562 - val_acc: 0.3400\n",
      "Epoch 652/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1096 - acc: 0.9958 - val_loss: 3.7565 - val_acc: 0.3400\n",
      "Epoch 653/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1039 - acc: 1.0000 - val_loss: 3.8292 - val_acc: 0.3600\n",
      "Epoch 654/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1061 - acc: 1.0000 - val_loss: 3.8997 - val_acc: 0.3600\n",
      "Epoch 655/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1051 - acc: 1.0000 - val_loss: 4.0388 - val_acc: 0.3600\n",
      "Epoch 656/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1125 - acc: 0.9958 - val_loss: 4.0784 - val_acc: 0.3400\n",
      "Epoch 657/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1170 - acc: 0.9958 - val_loss: 4.1329 - val_acc: 0.3600\n",
      "Epoch 658/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1457 - acc: 0.9958 - val_loss: 4.3104 - val_acc: 0.3400\n",
      "Epoch 659/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1247 - acc: 0.9832 - val_loss: 4.0589 - val_acc: 0.3400\n",
      "Epoch 660/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1530 - acc: 0.9916 - val_loss: 3.8389 - val_acc: 0.3800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1111 - acc: 1.0000 - val_loss: 3.7535 - val_acc: 0.4000\n",
      "Epoch 662/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1333 - acc: 0.9874 - val_loss: 4.0811 - val_acc: 0.3600\n",
      "Epoch 663/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1281 - acc: 0.9958 - val_loss: 4.3398 - val_acc: 0.3400\n",
      "Epoch 664/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1481 - acc: 0.9916 - val_loss: 4.4986 - val_acc: 0.3600\n",
      "Epoch 665/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1137 - acc: 1.0000 - val_loss: 5.0116 - val_acc: 0.3400\n",
      "Epoch 666/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1948 - acc: 0.9706 - val_loss: 4.9828 - val_acc: 0.3000\n",
      "Epoch 667/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1174 - acc: 1.0000 - val_loss: 5.0184 - val_acc: 0.2800\n",
      "Epoch 668/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1261 - acc: 0.9958 - val_loss: 4.7764 - val_acc: 0.3200\n",
      "Epoch 669/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1340 - acc: 0.9958 - val_loss: 4.4420 - val_acc: 0.3000\n",
      "Epoch 670/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1181 - acc: 1.0000 - val_loss: 4.2109 - val_acc: 0.3400\n",
      "Epoch 671/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1161 - acc: 1.0000 - val_loss: 4.1310 - val_acc: 0.3400\n",
      "Epoch 672/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1253 - acc: 0.9958 - val_loss: 4.0238 - val_acc: 0.3800\n",
      "Epoch 673/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1110 - acc: 1.0000 - val_loss: 4.0478 - val_acc: 0.3800\n",
      "Epoch 674/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1099 - acc: 1.0000 - val_loss: 4.0461 - val_acc: 0.3600\n",
      "Epoch 675/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1093 - acc: 1.0000 - val_loss: 4.0174 - val_acc: 0.3800\n",
      "Epoch 676/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1088 - acc: 1.0000 - val_loss: 3.9846 - val_acc: 0.4000\n",
      "Epoch 677/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1154 - acc: 0.9958 - val_loss: 4.0261 - val_acc: 0.3600\n",
      "Epoch 678/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1226 - acc: 0.9958 - val_loss: 4.0811 - val_acc: 0.3800\n",
      "Epoch 679/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1225 - acc: 0.9958 - val_loss: 3.7486 - val_acc: 0.3800\n",
      "Epoch 680/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1088 - acc: 1.0000 - val_loss: 3.7958 - val_acc: 0.4000\n",
      "Epoch 681/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1149 - acc: 0.9958 - val_loss: 3.7847 - val_acc: 0.3800\n",
      "Epoch 682/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1114 - acc: 1.0000 - val_loss: 3.7615 - val_acc: 0.4000\n",
      "Epoch 683/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1075 - acc: 1.0000 - val_loss: 3.7670 - val_acc: 0.4200\n",
      "Epoch 684/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1066 - acc: 1.0000 - val_loss: 3.7569 - val_acc: 0.4200\n",
      "Epoch 685/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1062 - acc: 1.0000 - val_loss: 3.7275 - val_acc: 0.4200\n",
      "Epoch 686/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1052 - acc: 1.0000 - val_loss: 3.7437 - val_acc: 0.4200\n",
      "Epoch 687/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1141 - acc: 0.9958 - val_loss: 3.8062 - val_acc: 0.4200\n",
      "Epoch 688/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1036 - acc: 1.0000 - val_loss: 3.9744 - val_acc: 0.4000\n",
      "Epoch 689/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1033 - acc: 1.0000 - val_loss: 4.0268 - val_acc: 0.4000\n",
      "Epoch 690/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1027 - acc: 1.0000 - val_loss: 4.0313 - val_acc: 0.4000\n",
      "Epoch 691/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1029 - acc: 1.0000 - val_loss: 4.0196 - val_acc: 0.4000\n",
      "Epoch 692/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1018 - acc: 1.0000 - val_loss: 3.9922 - val_acc: 0.4000\n",
      "Epoch 693/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1011 - acc: 1.0000 - val_loss: 3.9595 - val_acc: 0.4000\n",
      "Epoch 694/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1024 - acc: 1.0000 - val_loss: 3.9494 - val_acc: 0.4000\n",
      "Epoch 695/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1003 - acc: 1.0000 - val_loss: 3.9438 - val_acc: 0.3600\n",
      "Epoch 696/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0996 - acc: 1.0000 - val_loss: 3.9329 - val_acc: 0.3600\n",
      "Epoch 697/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1023 - acc: 1.0000 - val_loss: 3.9854 - val_acc: 0.3600\n",
      "Epoch 698/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.0988 - acc: 1.0000 - val_loss: 4.0825 - val_acc: 0.3800\n",
      "Epoch 699/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0986 - acc: 1.0000 - val_loss: 4.0965 - val_acc: 0.3000\n",
      "Epoch 700/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1010 - acc: 1.0000 - val_loss: 4.0460 - val_acc: 0.3000\n",
      "Epoch 701/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0999 - acc: 1.0000 - val_loss: 3.9738 - val_acc: 0.3400\n",
      "Epoch 702/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0978 - acc: 1.0000 - val_loss: 3.9406 - val_acc: 0.3600\n",
      "Epoch 703/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0971 - acc: 1.0000 - val_loss: 3.9153 - val_acc: 0.3800\n",
      "Epoch 704/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0975 - acc: 1.0000 - val_loss: 3.8960 - val_acc: 0.3400\n",
      "Epoch 705/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0977 - acc: 1.0000 - val_loss: 3.8582 - val_acc: 0.3800\n",
      "Epoch 706/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0959 - acc: 1.0000 - val_loss: 3.7975 - val_acc: 0.3600\n",
      "Epoch 707/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0954 - acc: 1.0000 - val_loss: 3.7672 - val_acc: 0.3600\n",
      "Epoch 708/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1197 - acc: 0.9958 - val_loss: 3.7345 - val_acc: 0.3800\n",
      "Epoch 709/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1275 - acc: 0.9958 - val_loss: 3.7277 - val_acc: 0.3600\n",
      "Epoch 710/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1168 - acc: 0.9958 - val_loss: 4.1185 - val_acc: 0.3600\n",
      "Epoch 711/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1281 - acc: 0.9916 - val_loss: 4.0770 - val_acc: 0.3400\n",
      "Epoch 712/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1077 - acc: 1.0000 - val_loss: 3.8591 - val_acc: 0.3600\n",
      "Epoch 713/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1621 - acc: 0.9874 - val_loss: 3.6518 - val_acc: 0.3600\n",
      "Epoch 714/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1087 - acc: 1.0000 - val_loss: 3.8199 - val_acc: 0.3400\n",
      "Epoch 715/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1127 - acc: 1.0000 - val_loss: 3.9526 - val_acc: 0.3600\n",
      "Epoch 716/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1198 - acc: 0.9958 - val_loss: 4.1981 - val_acc: 0.2800\n",
      "Epoch 717/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1657 - acc: 0.9916 - val_loss: 4.4111 - val_acc: 0.3000\n",
      "Epoch 718/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1593 - acc: 0.9874 - val_loss: 3.9596 - val_acc: 0.3200\n",
      "Epoch 719/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1157 - acc: 1.0000 - val_loss: 3.8224 - val_acc: 0.3200\n",
      "Epoch 720/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1270 - acc: 0.9874 - val_loss: 4.0974 - val_acc: 0.3200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1175 - acc: 0.9958 - val_loss: 4.6686 - val_acc: 0.3600\n",
      "Epoch 722/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1975 - acc: 0.9874 - val_loss: 4.7402 - val_acc: 0.3600\n",
      "Epoch 723/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1617 - acc: 0.9832 - val_loss: 4.9303 - val_acc: 0.3200\n",
      "Epoch 724/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1422 - acc: 0.9916 - val_loss: 5.0061 - val_acc: 0.2600\n",
      "Epoch 725/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1401 - acc: 0.9916 - val_loss: 5.4054 - val_acc: 0.2400\n",
      "Epoch 726/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1432 - acc: 0.9958 - val_loss: 5.1142 - val_acc: 0.2800\n",
      "Epoch 727/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1716 - acc: 0.9874 - val_loss: 5.4227 - val_acc: 0.2800\n",
      "Epoch 728/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1617 - acc: 0.9916 - val_loss: 5.2632 - val_acc: 0.2600\n",
      "Epoch 729/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2471 - acc: 0.9664 - val_loss: 6.0448 - val_acc: 0.3200\n",
      "Epoch 730/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1664 - acc: 0.9832 - val_loss: 5.2108 - val_acc: 0.2800\n",
      "Epoch 731/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1504 - acc: 0.9916 - val_loss: 5.3166 - val_acc: 0.3000\n",
      "Epoch 732/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1494 - acc: 0.9916 - val_loss: 5.4071 - val_acc: 0.3000\n",
      "Epoch 733/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1961 - acc: 0.9916 - val_loss: 5.5095 - val_acc: 0.3000\n",
      "Epoch 734/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1795 - acc: 0.9832 - val_loss: 5.1227 - val_acc: 0.2800\n",
      "Epoch 735/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1757 - acc: 0.9874 - val_loss: 4.7223 - val_acc: 0.2800\n",
      "Epoch 736/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1432 - acc: 0.9916 - val_loss: 4.4971 - val_acc: 0.2800\n",
      "Epoch 737/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1343 - acc: 1.0000 - val_loss: 4.3739 - val_acc: 0.2600\n",
      "Epoch 738/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1300 - acc: 1.0000 - val_loss: 4.2878 - val_acc: 0.2600\n",
      "Epoch 739/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1431 - acc: 0.9958 - val_loss: 4.1983 - val_acc: 0.2600\n",
      "Epoch 740/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1276 - acc: 1.0000 - val_loss: 3.9695 - val_acc: 0.2600\n",
      "Epoch 741/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1456 - acc: 0.9958 - val_loss: 3.9298 - val_acc: 0.3200\n",
      "Epoch 742/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1247 - acc: 1.0000 - val_loss: 4.0448 - val_acc: 0.3800\n",
      "Epoch 743/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1321 - acc: 1.0000 - val_loss: 4.1593 - val_acc: 0.3400\n",
      "Epoch 744/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1263 - acc: 1.0000 - val_loss: 4.2240 - val_acc: 0.3400\n",
      "Epoch 745/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1233 - acc: 1.0000 - val_loss: 4.2477 - val_acc: 0.3200\n",
      "Epoch 746/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1790 - acc: 0.9916 - val_loss: 4.2366 - val_acc: 0.3000\n",
      "Epoch 747/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1393 - acc: 0.9916 - val_loss: 4.5241 - val_acc: 0.3200\n",
      "Epoch 748/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1299 - acc: 1.0000 - val_loss: 4.5488 - val_acc: 0.3200\n",
      "Epoch 749/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1291 - acc: 0.9958 - val_loss: 4.4340 - val_acc: 0.3000\n",
      "Epoch 750/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1251 - acc: 1.0000 - val_loss: 4.2891 - val_acc: 0.3000\n",
      "Epoch 751/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1231 - acc: 1.0000 - val_loss: 4.2333 - val_acc: 0.3000\n",
      "Epoch 752/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1227 - acc: 1.0000 - val_loss: 4.1930 - val_acc: 0.3000\n",
      "Epoch 753/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1204 - acc: 1.0000 - val_loss: 4.1802 - val_acc: 0.3000\n",
      "Epoch 754/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1222 - acc: 1.0000 - val_loss: 4.1692 - val_acc: 0.3000\n",
      "Epoch 755/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1207 - acc: 1.0000 - val_loss: 4.2176 - val_acc: 0.2800\n",
      "Epoch 756/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1184 - acc: 1.0000 - val_loss: 4.2273 - val_acc: 0.2600\n",
      "Epoch 757/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1178 - acc: 1.0000 - val_loss: 4.2316 - val_acc: 0.2400\n",
      "Epoch 758/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1221 - acc: 0.9958 - val_loss: 4.1904 - val_acc: 0.3000\n",
      "Epoch 759/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1167 - acc: 1.0000 - val_loss: 4.1728 - val_acc: 0.2600\n",
      "Epoch 760/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1163 - acc: 1.0000 - val_loss: 4.1539 - val_acc: 0.2400\n",
      "Epoch 761/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1151 - acc: 1.0000 - val_loss: 4.1307 - val_acc: 0.2400\n",
      "Epoch 762/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1145 - acc: 1.0000 - val_loss: 4.1166 - val_acc: 0.2800\n",
      "Epoch 763/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1136 - acc: 1.0000 - val_loss: 4.1148 - val_acc: 0.2600\n",
      "Epoch 764/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1129 - acc: 1.0000 - val_loss: 4.1174 - val_acc: 0.3000\n",
      "Epoch 765/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1121 - acc: 1.0000 - val_loss: 4.1021 - val_acc: 0.3000\n",
      "Epoch 766/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1140 - acc: 1.0000 - val_loss: 4.0998 - val_acc: 0.3000\n",
      "Epoch 767/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1127 - acc: 1.0000 - val_loss: 4.0616 - val_acc: 0.3000\n",
      "Epoch 768/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1122 - acc: 1.0000 - val_loss: 4.0479 - val_acc: 0.3000\n",
      "Epoch 769/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1209 - acc: 0.9958 - val_loss: 3.8389 - val_acc: 0.2600\n",
      "Epoch 770/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1124 - acc: 1.0000 - val_loss: 3.8495 - val_acc: 0.2400\n",
      "Epoch 771/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1097 - acc: 1.0000 - val_loss: 3.8823 - val_acc: 0.2600\n",
      "Epoch 772/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1111 - acc: 1.0000 - val_loss: 3.8978 - val_acc: 0.2600\n",
      "Epoch 773/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1102 - acc: 1.0000 - val_loss: 3.9496 - val_acc: 0.2600\n",
      "Epoch 774/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1089 - acc: 1.0000 - val_loss: 3.9715 - val_acc: 0.2600\n",
      "Epoch 775/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1083 - acc: 1.0000 - val_loss: 3.9690 - val_acc: 0.2600\n",
      "Epoch 776/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1079 - acc: 1.0000 - val_loss: 3.9707 - val_acc: 0.2600\n",
      "Epoch 777/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1075 - acc: 1.0000 - val_loss: 3.9671 - val_acc: 0.2600\n",
      "Epoch 778/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1066 - acc: 1.0000 - val_loss: 3.9536 - val_acc: 0.2600\n",
      "Epoch 779/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1077 - acc: 1.0000 - val_loss: 3.9468 - val_acc: 0.2600\n",
      "Epoch 780/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1227 - acc: 0.9958 - val_loss: 3.9608 - val_acc: 0.2600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1051 - acc: 1.0000 - val_loss: 3.9775 - val_acc: 0.2600\n",
      "Epoch 782/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1053 - acc: 1.0000 - val_loss: 3.9938 - val_acc: 0.2800\n",
      "Epoch 783/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1047 - acc: 1.0000 - val_loss: 4.0105 - val_acc: 0.2800\n",
      "Epoch 784/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1057 - acc: 1.0000 - val_loss: 4.0165 - val_acc: 0.2800\n",
      "Epoch 785/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1040 - acc: 1.0000 - val_loss: 4.0263 - val_acc: 0.3000\n",
      "Epoch 786/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1032 - acc: 1.0000 - val_loss: 4.0350 - val_acc: 0.3000\n",
      "Epoch 787/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1080 - acc: 0.9958 - val_loss: 3.9724 - val_acc: 0.2800\n",
      "Epoch 788/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1036 - acc: 1.0000 - val_loss: 3.6188 - val_acc: 0.3000\n",
      "Epoch 789/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1083 - acc: 1.0000 - val_loss: 3.5653 - val_acc: 0.2800\n",
      "Epoch 790/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1064 - acc: 1.0000 - val_loss: 3.5714 - val_acc: 0.2800\n",
      "Epoch 791/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1038 - acc: 1.0000 - val_loss: 3.6061 - val_acc: 0.2800\n",
      "Epoch 792/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1078 - acc: 0.9958 - val_loss: 3.5935 - val_acc: 0.3000\n",
      "Epoch 793/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1032 - acc: 1.0000 - val_loss: 3.5680 - val_acc: 0.3200\n",
      "Epoch 794/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1249 - acc: 0.9958 - val_loss: 3.5282 - val_acc: 0.3200\n",
      "Epoch 795/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1149 - acc: 0.9916 - val_loss: 3.5694 - val_acc: 0.3400\n",
      "Epoch 796/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1070 - acc: 1.0000 - val_loss: 3.7366 - val_acc: 0.3000\n",
      "Epoch 797/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1121 - acc: 1.0000 - val_loss: 3.9276 - val_acc: 0.2800\n",
      "Epoch 798/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1254 - acc: 0.9916 - val_loss: 4.0568 - val_acc: 0.2800\n",
      "Epoch 799/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1103 - acc: 0.9958 - val_loss: 3.8692 - val_acc: 0.3200\n",
      "Epoch 800/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1125 - acc: 0.9958 - val_loss: 3.8713 - val_acc: 0.3000\n",
      "Epoch 801/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1065 - acc: 1.0000 - val_loss: 3.8771 - val_acc: 0.3200\n",
      "Epoch 802/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1059 - acc: 1.0000 - val_loss: 3.8555 - val_acc: 0.3200\n",
      "Epoch 803/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1097 - acc: 0.9958 - val_loss: 3.8207 - val_acc: 0.3200\n",
      "Epoch 804/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1055 - acc: 1.0000 - val_loss: 3.7550 - val_acc: 0.3200\n",
      "Epoch 805/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1043 - acc: 1.0000 - val_loss: 3.7280 - val_acc: 0.2800\n",
      "Epoch 806/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1146 - acc: 0.9958 - val_loss: 3.6829 - val_acc: 0.2600\n",
      "Epoch 807/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1035 - acc: 1.0000 - val_loss: 3.6493 - val_acc: 0.2200\n",
      "Epoch 808/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1035 - acc: 1.0000 - val_loss: 3.7855 - val_acc: 0.2200\n",
      "Epoch 809/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1261 - acc: 0.9874 - val_loss: 3.8881 - val_acc: 0.2200\n",
      "Epoch 810/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1049 - acc: 1.0000 - val_loss: 4.0387 - val_acc: 0.2600\n",
      "Epoch 811/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1110 - acc: 0.9958 - val_loss: 4.0551 - val_acc: 0.2800\n",
      "Epoch 812/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1043 - acc: 1.0000 - val_loss: 4.0405 - val_acc: 0.3000\n",
      "Epoch 813/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1190 - acc: 0.9958 - val_loss: 4.1919 - val_acc: 0.3000\n",
      "Epoch 814/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1448 - acc: 0.9832 - val_loss: 4.3653 - val_acc: 0.2600\n",
      "Epoch 815/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1349 - acc: 0.9916 - val_loss: 4.3157 - val_acc: 0.3000\n",
      "Epoch 816/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1444 - acc: 0.9916 - val_loss: 4.3329 - val_acc: 0.2600\n",
      "Epoch 817/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1101 - acc: 1.0000 - val_loss: 4.3301 - val_acc: 0.2600\n",
      "Epoch 818/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1083 - acc: 1.0000 - val_loss: 4.2897 - val_acc: 0.3000\n",
      "Epoch 819/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1084 - acc: 1.0000 - val_loss: 4.2385 - val_acc: 0.3200\n",
      "Epoch 820/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1064 - acc: 1.0000 - val_loss: 4.1834 - val_acc: 0.3200\n",
      "Epoch 821/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1065 - acc: 1.0000 - val_loss: 4.1452 - val_acc: 0.3200\n",
      "Epoch 822/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1044 - acc: 1.0000 - val_loss: 4.1181 - val_acc: 0.3200\n",
      "Epoch 823/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1293 - acc: 0.9916 - val_loss: 4.1586 - val_acc: 0.3200\n",
      "Epoch 824/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1073 - acc: 1.0000 - val_loss: 4.3319 - val_acc: 0.3400\n",
      "Epoch 825/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1627 - acc: 0.9916 - val_loss: 4.2717 - val_acc: 0.3400\n",
      "Epoch 826/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1321 - acc: 0.9958 - val_loss: 4.2128 - val_acc: 0.3000\n",
      "Epoch 827/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1419 - acc: 0.9958 - val_loss: 4.1871 - val_acc: 0.2800\n",
      "Epoch 828/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1289 - acc: 0.9958 - val_loss: 4.8389 - val_acc: 0.3200\n",
      "Epoch 829/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1183 - acc: 0.9958 - val_loss: 4.9307 - val_acc: 0.2800\n",
      "Epoch 830/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1153 - acc: 0.9958 - val_loss: 4.6848 - val_acc: 0.3200\n",
      "Epoch 831/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1186 - acc: 0.9958 - val_loss: 4.5193 - val_acc: 0.2800\n",
      "Epoch 832/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1113 - acc: 1.0000 - val_loss: 4.3639 - val_acc: 0.2600\n",
      "Epoch 833/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1193 - acc: 0.9958 - val_loss: 4.3872 - val_acc: 0.2800\n",
      "Epoch 834/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1233 - acc: 0.9958 - val_loss: 4.7165 - val_acc: 0.2800\n",
      "Epoch 835/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1131 - acc: 1.0000 - val_loss: 4.7954 - val_acc: 0.3000\n",
      "Epoch 836/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1349 - acc: 0.9958 - val_loss: 4.7634 - val_acc: 0.3200\n",
      "Epoch 837/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1324 - acc: 0.9874 - val_loss: 5.0047 - val_acc: 0.3000\n",
      "Epoch 838/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1224 - acc: 0.9958 - val_loss: 5.4438 - val_acc: 0.3200\n",
      "Epoch 839/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1161 - acc: 0.9958 - val_loss: 5.3429 - val_acc: 0.3600\n",
      "Epoch 840/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1507 - acc: 0.9958 - val_loss: 4.7821 - val_acc: 0.3200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1345 - acc: 0.9874 - val_loss: 5.0605 - val_acc: 0.3000\n",
      "Epoch 842/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1178 - acc: 1.0000 - val_loss: 5.2859 - val_acc: 0.3000\n",
      "Epoch 843/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1191 - acc: 1.0000 - val_loss: 5.1502 - val_acc: 0.3000\n",
      "Epoch 844/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1360 - acc: 0.9958 - val_loss: 4.8667 - val_acc: 0.3400\n",
      "Epoch 845/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1268 - acc: 0.9916 - val_loss: 5.0901 - val_acc: 0.3400\n",
      "Epoch 846/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1247 - acc: 0.9958 - val_loss: 4.9122 - val_acc: 0.3400\n",
      "Epoch 847/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1283 - acc: 0.9958 - val_loss: 4.6537 - val_acc: 0.3400\n",
      "Epoch 848/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1129 - acc: 1.0000 - val_loss: 4.4473 - val_acc: 0.3600\n",
      "Epoch 849/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1544 - acc: 0.9874 - val_loss: 4.7772 - val_acc: 0.3400\n",
      "Epoch 850/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1358 - acc: 0.9916 - val_loss: 5.1607 - val_acc: 0.3000\n",
      "Epoch 851/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1204 - acc: 0.9958 - val_loss: 4.9393 - val_acc: 0.3600\n",
      "Epoch 852/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1821 - acc: 0.9916 - val_loss: 4.8630 - val_acc: 0.3800\n",
      "Epoch 853/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1650 - acc: 0.9916 - val_loss: 4.6689 - val_acc: 0.3600\n",
      "Epoch 854/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1806 - acc: 0.9748 - val_loss: 4.5695 - val_acc: 0.4000\n",
      "Epoch 855/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1409 - acc: 1.0000 - val_loss: 4.8225 - val_acc: 0.3800\n",
      "Epoch 856/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1975 - acc: 0.9832 - val_loss: 4.8226 - val_acc: 0.3600\n",
      "Epoch 857/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1299 - acc: 1.0000 - val_loss: 4.4797 - val_acc: 0.3400\n",
      "Epoch 858/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1438 - acc: 0.9874 - val_loss: 4.3631 - val_acc: 0.3600\n",
      "Epoch 859/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1325 - acc: 0.9958 - val_loss: 4.3756 - val_acc: 0.3600\n",
      "Epoch 860/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1291 - acc: 1.0000 - val_loss: 4.2950 - val_acc: 0.3400\n",
      "Epoch 861/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1300 - acc: 0.9958 - val_loss: 4.2314 - val_acc: 0.3600\n",
      "Epoch 862/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1341 - acc: 0.9916 - val_loss: 4.1595 - val_acc: 0.3600\n",
      "Epoch 863/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1274 - acc: 0.9958 - val_loss: 4.0267 - val_acc: 0.3000\n",
      "Epoch 864/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1225 - acc: 1.0000 - val_loss: 3.9842 - val_acc: 0.3000\n",
      "Epoch 865/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1225 - acc: 1.0000 - val_loss: 3.9648 - val_acc: 0.2800\n",
      "Epoch 866/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1194 - acc: 1.0000 - val_loss: 3.9638 - val_acc: 0.2600\n",
      "Epoch 867/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1176 - acc: 1.0000 - val_loss: 3.9459 - val_acc: 0.2400\n",
      "Epoch 868/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1167 - acc: 1.0000 - val_loss: 3.9245 - val_acc: 0.2600\n",
      "Epoch 869/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1331 - acc: 0.9958 - val_loss: 3.8715 - val_acc: 0.2800\n",
      "Epoch 870/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1358 - acc: 0.9958 - val_loss: 3.6323 - val_acc: 0.2600\n",
      "Epoch 871/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1635 - acc: 0.9916 - val_loss: 3.4996 - val_acc: 0.3000\n",
      "Epoch 872/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1234 - acc: 0.9958 - val_loss: 3.3693 - val_acc: 0.3600\n",
      "Epoch 873/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1174 - acc: 1.0000 - val_loss: 3.3421 - val_acc: 0.3800\n",
      "Epoch 874/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1221 - acc: 0.9958 - val_loss: 3.3519 - val_acc: 0.3600\n",
      "Epoch 875/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1176 - acc: 1.0000 - val_loss: 3.4969 - val_acc: 0.3200\n",
      "Epoch 876/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1297 - acc: 0.9916 - val_loss: 3.5169 - val_acc: 0.3200\n",
      "Epoch 877/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1197 - acc: 1.0000 - val_loss: 3.4485 - val_acc: 0.3200\n",
      "Epoch 878/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1299 - acc: 0.9916 - val_loss: 3.4181 - val_acc: 0.3200\n",
      "Epoch 879/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1164 - acc: 1.0000 - val_loss: 3.2912 - val_acc: 0.3200\n",
      "Epoch 880/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1180 - acc: 1.0000 - val_loss: 3.2801 - val_acc: 0.3200\n",
      "Epoch 881/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1180 - acc: 1.0000 - val_loss: 3.3194 - val_acc: 0.3200\n",
      "Epoch 882/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1280 - acc: 0.9958 - val_loss: 3.2331 - val_acc: 0.3000\n",
      "Epoch 883/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1391 - acc: 0.9916 - val_loss: 3.0963 - val_acc: 0.3200\n",
      "Epoch 884/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1941 - acc: 0.9874 - val_loss: 3.2230 - val_acc: 0.3800\n",
      "Epoch 885/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1471 - acc: 0.9874 - val_loss: 3.3387 - val_acc: 0.3400\n",
      "Epoch 886/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1255 - acc: 0.9958 - val_loss: 3.2049 - val_acc: 0.3600\n",
      "Epoch 887/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1439 - acc: 0.9874 - val_loss: 3.2952 - val_acc: 0.3600\n",
      "Epoch 888/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1229 - acc: 1.0000 - val_loss: 3.9159 - val_acc: 0.3400\n",
      "Epoch 889/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1349 - acc: 0.9916 - val_loss: 4.0834 - val_acc: 0.3600\n",
      "Epoch 890/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1227 - acc: 1.0000 - val_loss: 4.0925 - val_acc: 0.3200\n",
      "Epoch 891/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1218 - acc: 1.0000 - val_loss: 4.0657 - val_acc: 0.3400\n",
      "Epoch 892/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1200 - acc: 1.0000 - val_loss: 4.0039 - val_acc: 0.3400\n",
      "Epoch 893/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1200 - acc: 1.0000 - val_loss: 3.9290 - val_acc: 0.3400\n",
      "Epoch 894/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1286 - acc: 0.9958 - val_loss: 4.0033 - val_acc: 0.3000\n",
      "Epoch 895/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1172 - acc: 1.0000 - val_loss: 4.2778 - val_acc: 0.3000\n",
      "Epoch 896/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1326 - acc: 0.9916 - val_loss: 4.0991 - val_acc: 0.2800\n",
      "Epoch 897/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1160 - acc: 1.0000 - val_loss: 3.4992 - val_acc: 0.3400\n",
      "Epoch 898/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1293 - acc: 0.9958 - val_loss: 3.3358 - val_acc: 0.3600\n",
      "Epoch 899/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1199 - acc: 0.9958 - val_loss: 3.5764 - val_acc: 0.3800\n",
      "Epoch 900/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1495 - acc: 0.9916 - val_loss: 3.5918 - val_acc: 0.3600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1172 - acc: 1.0000 - val_loss: 3.5447 - val_acc: 0.3600\n",
      "Epoch 902/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1194 - acc: 1.0000 - val_loss: 3.6052 - val_acc: 0.3800\n",
      "Epoch 903/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1189 - acc: 1.0000 - val_loss: 3.8261 - val_acc: 0.3600\n",
      "Epoch 904/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1162 - acc: 1.0000 - val_loss: 3.8809 - val_acc: 0.3600\n",
      "Epoch 905/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1295 - acc: 0.9958 - val_loss: 3.8565 - val_acc: 0.3800\n",
      "Epoch 906/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1138 - acc: 1.0000 - val_loss: 3.6961 - val_acc: 0.4000\n",
      "Epoch 907/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1238 - acc: 0.9958 - val_loss: 3.6317 - val_acc: 0.4200\n",
      "Epoch 908/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1150 - acc: 1.0000 - val_loss: 3.6647 - val_acc: 0.3800\n",
      "Epoch 909/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1203 - acc: 0.9958 - val_loss: 3.6814 - val_acc: 0.3600\n",
      "Epoch 910/1000\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.1158 - acc: 1.0000 - val_loss: 3.7899 - val_acc: 0.3600\n",
      "Epoch 911/1000\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.1138 - acc: 1.0000 - val_loss: 3.8363 - val_acc: 0.3600\n",
      "Epoch 912/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1135 - acc: 1.0000 - val_loss: 3.8480 - val_acc: 0.3400\n",
      "Epoch 913/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1183 - acc: 0.9958 - val_loss: 3.8652 - val_acc: 0.3600\n",
      "Epoch 914/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1130 - acc: 1.0000 - val_loss: 3.8878 - val_acc: 0.3600\n",
      "Epoch 915/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1107 - acc: 1.0000 - val_loss: 3.8917 - val_acc: 0.3600\n",
      "Epoch 916/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1502 - acc: 0.9958 - val_loss: 3.7272 - val_acc: 0.3600\n",
      "Epoch 917/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1175 - acc: 0.9958 - val_loss: 3.4335 - val_acc: 0.3200\n",
      "Epoch 918/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1180 - acc: 0.9958 - val_loss: 3.3825 - val_acc: 0.3200\n",
      "Epoch 919/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1115 - acc: 1.0000 - val_loss: 3.3689 - val_acc: 0.3200\n",
      "Epoch 920/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1123 - acc: 1.0000 - val_loss: 3.3613 - val_acc: 0.3200\n",
      "Epoch 921/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1271 - acc: 0.9916 - val_loss: 3.2587 - val_acc: 0.3600\n",
      "Epoch 922/1000\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.1482 - acc: 0.9874 - val_loss: 3.3233 - val_acc: 0.3400\n",
      "Epoch 923/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1536 - acc: 0.9874 - val_loss: 3.3079 - val_acc: 0.3200\n",
      "Epoch 924/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1437 - acc: 0.9874 - val_loss: 3.5149 - val_acc: 0.3200\n",
      "Epoch 925/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1745 - acc: 0.9832 - val_loss: 3.6271 - val_acc: 0.3400\n",
      "Epoch 926/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1301 - acc: 0.9958 - val_loss: 3.5093 - val_acc: 0.3800\n",
      "Epoch 927/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1208 - acc: 1.0000 - val_loss: 3.4088 - val_acc: 0.4200\n",
      "Epoch 928/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1255 - acc: 0.9958 - val_loss: 3.4171 - val_acc: 0.4000\n",
      "Epoch 929/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1264 - acc: 0.9916 - val_loss: 3.4185 - val_acc: 0.4000\n",
      "Epoch 930/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1182 - acc: 1.0000 - val_loss: 3.4098 - val_acc: 0.4400\n",
      "Epoch 931/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1208 - acc: 1.0000 - val_loss: 3.4074 - val_acc: 0.4400\n",
      "Epoch 932/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1155 - acc: 1.0000 - val_loss: 3.4035 - val_acc: 0.4400\n",
      "Epoch 933/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1147 - acc: 1.0000 - val_loss: 3.3951 - val_acc: 0.4400\n",
      "Epoch 934/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1135 - acc: 1.0000 - val_loss: 3.3828 - val_acc: 0.4400\n",
      "Epoch 935/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1129 - acc: 1.0000 - val_loss: 3.3670 - val_acc: 0.4400\n",
      "Epoch 936/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1119 - acc: 1.0000 - val_loss: 3.3856 - val_acc: 0.4400\n",
      "Epoch 937/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1121 - acc: 1.0000 - val_loss: 3.3968 - val_acc: 0.4200\n",
      "Epoch 938/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1101 - acc: 1.0000 - val_loss: 3.3727 - val_acc: 0.4200\n",
      "Epoch 939/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1095 - acc: 1.0000 - val_loss: 3.3489 - val_acc: 0.4200\n",
      "Epoch 940/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1212 - acc: 0.9958 - val_loss: 3.3350 - val_acc: 0.4200\n",
      "Epoch 941/1000\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.1192 - acc: 0.9958 - val_loss: 3.3119 - val_acc: 0.4000\n",
      "Epoch 942/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1094 - acc: 1.0000 - val_loss: 3.2847 - val_acc: 0.3600\n",
      "Epoch 943/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1163 - acc: 1.0000 - val_loss: 3.3642 - val_acc: 0.3600\n",
      "Epoch 944/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1094 - acc: 1.0000 - val_loss: 3.4780 - val_acc: 0.3600\n",
      "Epoch 945/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1127 - acc: 1.0000 - val_loss: 3.4885 - val_acc: 0.3400\n",
      "Epoch 946/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1089 - acc: 1.0000 - val_loss: 3.4773 - val_acc: 0.3600\n",
      "Epoch 947/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1084 - acc: 1.0000 - val_loss: 3.4805 - val_acc: 0.3600\n",
      "Epoch 948/1000\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.1072 - acc: 1.0000 - val_loss: 3.4739 - val_acc: 0.3400\n",
      "Epoch 949/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1066 - acc: 1.0000 - val_loss: 3.4546 - val_acc: 0.3400\n",
      "Epoch 950/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1061 - acc: 1.0000 - val_loss: 3.4487 - val_acc: 0.3400\n",
      "Epoch 951/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1058 - acc: 1.0000 - val_loss: 3.4298 - val_acc: 0.3400\n",
      "Epoch 952/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1048 - acc: 1.0000 - val_loss: 3.4127 - val_acc: 0.3400\n",
      "Epoch 953/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1046 - acc: 1.0000 - val_loss: 3.4005 - val_acc: 0.3400\n",
      "Epoch 954/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1039 - acc: 1.0000 - val_loss: 3.4006 - val_acc: 0.3200\n",
      "Epoch 955/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1033 - acc: 1.0000 - val_loss: 3.3901 - val_acc: 0.3200\n",
      "Epoch 956/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1029 - acc: 1.0000 - val_loss: 3.3750 - val_acc: 0.3000\n",
      "Epoch 957/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1160 - acc: 0.9916 - val_loss: 3.2921 - val_acc: 0.3400\n",
      "Epoch 958/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1684 - acc: 0.9790 - val_loss: 3.4990 - val_acc: 0.3000\n",
      "Epoch 959/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1159 - acc: 0.9958 - val_loss: 4.1596 - val_acc: 0.3200\n",
      "Epoch 960/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1120 - acc: 1.0000 - val_loss: 4.3154 - val_acc: 0.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1135 - acc: 1.0000 - val_loss: 4.3565 - val_acc: 0.2400\n",
      "Epoch 962/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1134 - acc: 1.0000 - val_loss: 4.3121 - val_acc: 0.2800\n",
      "Epoch 963/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1117 - acc: 1.0000 - val_loss: 4.2327 - val_acc: 0.2800\n",
      "Epoch 964/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1099 - acc: 1.0000 - val_loss: 4.1691 - val_acc: 0.2800\n",
      "Epoch 965/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1091 - acc: 1.0000 - val_loss: 4.1469 - val_acc: 0.2800\n",
      "Epoch 966/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1074 - acc: 1.0000 - val_loss: 4.1262 - val_acc: 0.2600\n",
      "Epoch 967/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1061 - acc: 1.0000 - val_loss: 4.1029 - val_acc: 0.2600\n",
      "Epoch 968/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1052 - acc: 1.0000 - val_loss: 4.0734 - val_acc: 0.2600\n",
      "Epoch 969/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1041 - acc: 1.0000 - val_loss: 4.0589 - val_acc: 0.2800\n",
      "Epoch 970/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1036 - acc: 1.0000 - val_loss: 4.0411 - val_acc: 0.2800\n",
      "Epoch 971/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1028 - acc: 1.0000 - val_loss: 4.0133 - val_acc: 0.2600\n",
      "Epoch 972/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1035 - acc: 1.0000 - val_loss: 3.9559 - val_acc: 0.2600\n",
      "Epoch 973/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1014 - acc: 1.0000 - val_loss: 3.8991 - val_acc: 0.2600\n",
      "Epoch 974/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1012 - acc: 1.0000 - val_loss: 3.8608 - val_acc: 0.2600\n",
      "Epoch 975/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1019 - acc: 1.0000 - val_loss: 3.8167 - val_acc: 0.2600\n",
      "Epoch 976/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.0997 - acc: 1.0000 - val_loss: 3.7874 - val_acc: 0.2600\n",
      "Epoch 977/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.0992 - acc: 1.0000 - val_loss: 3.7684 - val_acc: 0.2600\n",
      "Epoch 978/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.0991 - acc: 1.0000 - val_loss: 3.7574 - val_acc: 0.2600\n",
      "Epoch 979/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.0979 - acc: 1.0000 - val_loss: 3.7429 - val_acc: 0.2800\n",
      "Epoch 980/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.1090 - acc: 0.9958 - val_loss: 3.6871 - val_acc: 0.2800\n",
      "Epoch 981/1000\n",
      "238/238 [==============================] - 10s 43ms/step - loss: 0.0977 - acc: 1.0000 - val_loss: 3.4534 - val_acc: 0.2800\n",
      "Epoch 982/1000\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.0994 - acc: 1.0000 - val_loss: 3.3576 - val_acc: 0.2800\n",
      "Epoch 983/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1074 - acc: 0.9958 - val_loss: 3.3364 - val_acc: 0.3000\n",
      "Epoch 984/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1011 - acc: 1.0000 - val_loss: 3.7775 - val_acc: 0.3400\n",
      "Epoch 985/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1271 - acc: 0.9916 - val_loss: 4.1969 - val_acc: 0.2600\n",
      "Epoch 986/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1105 - acc: 1.0000 - val_loss: 4.7656 - val_acc: 0.2800\n",
      "Epoch 987/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1131 - acc: 1.0000 - val_loss: 4.9058 - val_acc: 0.2600\n",
      "Epoch 988/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1192 - acc: 0.9958 - val_loss: 5.1953 - val_acc: 0.2800\n",
      "Epoch 989/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1197 - acc: 0.9916 - val_loss: 5.0659 - val_acc: 0.2800\n",
      "Epoch 990/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1079 - acc: 1.0000 - val_loss: 5.2042 - val_acc: 0.3200\n",
      "Epoch 991/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1067 - acc: 1.0000 - val_loss: 5.1110 - val_acc: 0.3200\n",
      "Epoch 992/1000\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.1058 - acc: 1.0000 - val_loss: 4.9030 - val_acc: 0.3200\n",
      "Epoch 993/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1046 - acc: 1.0000 - val_loss: 4.7107 - val_acc: 0.3000\n",
      "Epoch 994/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1169 - acc: 0.9916 - val_loss: 4.5272 - val_acc: 0.2800\n",
      "Epoch 995/1000\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.1358 - acc: 0.9874 - val_loss: 4.4866 - val_acc: 0.2600\n",
      "Epoch 996/1000\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.1556 - acc: 0.9874 - val_loss: 4.8120 - val_acc: 0.2600\n",
      "Epoch 997/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2012 - acc: 0.9748 - val_loss: 3.5616 - val_acc: 0.3000\n",
      "Epoch 998/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2278 - acc: 0.9706 - val_loss: 3.1311 - val_acc: 0.3600\n",
      "Epoch 999/1000\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.1365 - acc: 1.0000 - val_loss: 3.2886 - val_acc: 0.4200\n",
      "Epoch 1000/1000\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.1564 - acc: 0.9916 - val_loss: 3.5553 - val_acc: 0.4200\n",
      "50/50 [==============================] - 0s 3ms/step\n",
      "\n",
      "Testing loss: 3.5552880001068115, acc: 0.4200000023841858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
    "#csv_logger = CSVLogger('resnet18_cifar10.csv')\n",
    "\n",
    "model.fit(x1_train_add, y1_train_onehot,\n",
    "              batch_size=32,\n",
    "              epochs=1000,shuffle=True,\n",
    "          callbacks=[time_callback,acc_callback],\n",
    "         validation_data=(x1_test_add, y1_test_onehot),verbose=1)\n",
    "times = time_callback.times\n",
    "loss,acc=model.evaluate(x1_test_add, y1_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d21199beb8>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(times[1:],acc_callback.testaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetBuilder.build_resnet_50((1000,1,22), 4)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "time_callback = TimeHistory()\n",
    "acc_callback = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 50 samples\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - 27s 113ms/step - loss: 6.4039 - acc: 0.2857 - val_loss: 12.5188 - val_acc: 0.2800\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - 17s 72ms/step - loss: 5.8706 - acc: 0.5084 - val_loss: 10.3069 - val_acc: 0.1800\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 4.8417 - acc: 0.6597 - val_loss: 8.4307 - val_acc: 0.2400\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 4.3469 - acc: 0.8277 - val_loss: 7.5763 - val_acc: 0.2600\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - 16s 69ms/step - loss: 4.0497 - acc: 0.8613 - val_loss: 6.8572 - val_acc: 0.2400\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - 16s 69ms/step - loss: 3.8795 - acc: 0.9328 - val_loss: 7.3732 - val_acc: 0.2800\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 3.7564 - acc: 0.9622 - val_loss: 7.2449 - val_acc: 0.2000\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 3.8350 - acc: 0.9538 - val_loss: 6.9651 - val_acc: 0.2800\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 3.7228 - acc: 0.9580 - val_loss: 6.7837 - val_acc: 0.2600\n",
      "Epoch 10/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 3.6503 - acc: 0.9706 - val_loss: 7.0479 - val_acc: 0.2600\n",
      "Epoch 11/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 3.7383 - acc: 0.9244 - val_loss: 6.7841 - val_acc: 0.3200\n",
      "Epoch 12/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 3.6407 - acc: 0.9454 - val_loss: 7.0463 - val_acc: 0.2800\n",
      "Epoch 13/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 3.7093 - acc: 0.9202 - val_loss: 7.2750 - val_acc: 0.2600\n",
      "Epoch 14/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 3.6910 - acc: 0.9118 - val_loss: 8.0906 - val_acc: 0.2800\n",
      "Epoch 15/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 3.7184 - acc: 0.9118 - val_loss: 8.0572 - val_acc: 0.2400\n",
      "Epoch 16/100\n",
      "238/238 [==============================] - 16s 65ms/step - loss: 3.6469 - acc: 0.8992 - val_loss: 7.4906 - val_acc: 0.2600\n",
      "Epoch 17/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 3.5791 - acc: 0.9286 - val_loss: 7.3112 - val_acc: 0.2600\n",
      "Epoch 18/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 3.4039 - acc: 0.9790 - val_loss: 7.4101 - val_acc: 0.2800\n",
      "Epoch 19/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 3.4019 - acc: 0.9706 - val_loss: 7.8398 - val_acc: 0.2400\n",
      "Epoch 20/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 3.3270 - acc: 0.9664 - val_loss: 8.4205 - val_acc: 0.2400\n",
      "Epoch 21/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 3.4052 - acc: 0.9412 - val_loss: 8.4187 - val_acc: 0.2200\n",
      "Epoch 22/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 3.3758 - acc: 0.9538 - val_loss: 8.9665 - val_acc: 0.2200\n",
      "Epoch 23/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 3.4263 - acc: 0.9328 - val_loss: 7.9880 - val_acc: 0.2600\n",
      "Epoch 24/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 3.3964 - acc: 0.9370 - val_loss: 7.5869 - val_acc: 0.3000\n",
      "Epoch 25/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 3.2589 - acc: 0.9244 - val_loss: 7.5553 - val_acc: 0.2800\n",
      "Epoch 26/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 3.2048 - acc: 0.9706 - val_loss: 7.8379 - val_acc: 0.2400\n",
      "Epoch 27/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 3.1553 - acc: 0.9622 - val_loss: 8.0796 - val_acc: 0.2800\n",
      "Epoch 28/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 3.2654 - acc: 0.9286 - val_loss: 7.7944 - val_acc: 0.3400\n",
      "Epoch 29/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 3.1610 - acc: 0.9580 - val_loss: 7.3452 - val_acc: 0.3200\n",
      "Epoch 30/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 3.2117 - acc: 0.9286 - val_loss: 8.0341 - val_acc: 0.2800\n",
      "Epoch 31/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 3.0737 - acc: 0.9496 - val_loss: 8.0159 - val_acc: 0.2600\n",
      "Epoch 32/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.9837 - acc: 0.9790 - val_loss: 8.2208 - val_acc: 0.3200\n",
      "Epoch 33/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 2.9370 - acc: 0.9706 - val_loss: 8.0277 - val_acc: 0.3200\n",
      "Epoch 34/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 2.9184 - acc: 0.9748 - val_loss: 7.7008 - val_acc: 0.3600\n",
      "Epoch 35/100\n",
      "238/238 [==============================] - 17s 69ms/step - loss: 2.9214 - acc: 0.9622 - val_loss: 7.2919 - val_acc: 0.3800\n",
      "Epoch 36/100\n",
      "238/238 [==============================] - 16s 69ms/step - loss: 2.8774 - acc: 0.9874 - val_loss: 7.5213 - val_acc: 0.3400\n",
      "Epoch 37/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 2.8450 - acc: 0.9706 - val_loss: 7.5779 - val_acc: 0.2200\n",
      "Epoch 38/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.7864 - acc: 0.9916 - val_loss: 7.5747 - val_acc: 0.2800\n",
      "Epoch 39/100\n",
      "238/238 [==============================] - 16s 69ms/step - loss: 2.7429 - acc: 0.9874 - val_loss: 7.5231 - val_acc: 0.3200\n",
      "Epoch 40/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.7841 - acc: 0.9790 - val_loss: 7.2837 - val_acc: 0.3000\n",
      "Epoch 41/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.6805 - acc: 0.9958 - val_loss: 6.7206 - val_acc: 0.3000\n",
      "Epoch 42/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.6743 - acc: 0.9832 - val_loss: 6.6927 - val_acc: 0.3000\n",
      "Epoch 43/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 2.6683 - acc: 0.9874 - val_loss: 6.6730 - val_acc: 0.3000\n",
      "Epoch 44/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 2.6060 - acc: 0.9874 - val_loss: 6.4426 - val_acc: 0.2800\n",
      "Epoch 45/100\n",
      "238/238 [==============================] - 16s 69ms/step - loss: 2.5742 - acc: 0.9916 - val_loss: 6.3654 - val_acc: 0.3400\n",
      "Epoch 46/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 2.5700 - acc: 0.9874 - val_loss: 6.6958 - val_acc: 0.3200\n",
      "Epoch 47/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.5876 - acc: 0.9748 - val_loss: 6.2644 - val_acc: 0.3000\n",
      "Epoch 48/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.5309 - acc: 0.9916 - val_loss: 6.2524 - val_acc: 0.3000\n",
      "Epoch 49/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 2.4979 - acc: 0.9832 - val_loss: 6.2310 - val_acc: 0.3000\n",
      "Epoch 50/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 2.4644 - acc: 0.9874 - val_loss: 6.2681 - val_acc: 0.3400\n",
      "Epoch 51/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 2.4121 - acc: 1.0000 - val_loss: 6.3852 - val_acc: 0.3600\n",
      "Epoch 52/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.3941 - acc: 1.0000 - val_loss: 6.4418 - val_acc: 0.3600\n",
      "Epoch 53/100\n",
      "238/238 [==============================] - 16s 69ms/step - loss: 2.3784 - acc: 0.9916 - val_loss: 6.3907 - val_acc: 0.4000\n",
      "Epoch 54/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.3656 - acc: 0.9874 - val_loss: 6.4377 - val_acc: 0.3600\n",
      "Epoch 55/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.4111 - acc: 0.9748 - val_loss: 6.6916 - val_acc: 0.3400\n",
      "Epoch 56/100\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 2.4585 - acc: 0.9706 - val_loss: 7.1245 - val_acc: 0.3800\n",
      "Epoch 57/100\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 2.3340 - acc: 0.9790 - val_loss: 7.3387 - val_acc: 0.3400\n",
      "Epoch 58/100\n",
      "238/238 [==============================] - 18s 77ms/step - loss: 2.3828 - acc: 0.9664 - val_loss: 7.3856 - val_acc: 0.3800\n",
      "Epoch 59/100\n",
      "238/238 [==============================] - 17s 72ms/step - loss: 2.2336 - acc: 1.0000 - val_loss: 7.5818 - val_acc: 0.3600\n",
      "Epoch 60/100\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 2.2434 - acc: 0.9916 - val_loss: 7.2354 - val_acc: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.2225 - acc: 0.9832 - val_loss: 6.8868 - val_acc: 0.4600\n",
      "Epoch 62/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 2.2089 - acc: 0.9832 - val_loss: 7.3439 - val_acc: 0.3800\n",
      "Epoch 63/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 2.1574 - acc: 0.9916 - val_loss: 7.5413 - val_acc: 0.3400\n",
      "Epoch 64/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 2.1515 - acc: 0.9958 - val_loss: 7.2237 - val_acc: 0.3600\n",
      "Epoch 65/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 2.1168 - acc: 0.9916 - val_loss: 6.8618 - val_acc: 0.3600\n",
      "Epoch 66/100\n",
      "238/238 [==============================] - 18s 75ms/step - loss: 2.1257 - acc: 0.9832 - val_loss: 6.8662 - val_acc: 0.3200\n",
      "Epoch 67/100\n",
      "238/238 [==============================] - 17s 72ms/step - loss: 2.0686 - acc: 0.9916 - val_loss: 6.9265 - val_acc: 0.3600\n",
      "Epoch 68/100\n",
      "238/238 [==============================] - 16s 69ms/step - loss: 2.0677 - acc: 0.9874 - val_loss: 6.6798 - val_acc: 0.4000\n",
      "Epoch 69/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 2.0416 - acc: 0.9874 - val_loss: 6.4571 - val_acc: 0.3400\n",
      "Epoch 70/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.0054 - acc: 1.0000 - val_loss: 6.8385 - val_acc: 0.3600\n",
      "Epoch 71/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 2.0205 - acc: 0.9916 - val_loss: 7.0829 - val_acc: 0.3000\n",
      "Epoch 72/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 2.0170 - acc: 0.9748 - val_loss: 6.7520 - val_acc: 0.3000\n",
      "Epoch 73/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 1.9997 - acc: 0.9790 - val_loss: 6.7906 - val_acc: 0.3200\n",
      "Epoch 74/100\n",
      "238/238 [==============================] - 16s 69ms/step - loss: 1.9452 - acc: 0.9874 - val_loss: 6.8369 - val_acc: 0.3600\n",
      "Epoch 75/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 1.9456 - acc: 0.9832 - val_loss: 6.5886 - val_acc: 0.3200\n",
      "Epoch 76/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 1.8970 - acc: 0.9958 - val_loss: 6.5877 - val_acc: 0.3000\n",
      "Epoch 77/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 1.9069 - acc: 0.9916 - val_loss: 6.5349 - val_acc: 0.3000\n",
      "Epoch 78/100\n",
      "238/238 [==============================] - 17s 69ms/step - loss: 1.9391 - acc: 0.9748 - val_loss: 6.4547 - val_acc: 0.3800\n",
      "Epoch 79/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 1.9882 - acc: 0.9664 - val_loss: 7.1923 - val_acc: 0.4000\n",
      "Epoch 80/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 1.9782 - acc: 0.9580 - val_loss: 7.4873 - val_acc: 0.2800\n",
      "Epoch 81/100\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 1.8916 - acc: 0.9664 - val_loss: 7.2394 - val_acc: 0.3000\n",
      "Epoch 82/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 1.8859 - acc: 0.9664 - val_loss: 7.2167 - val_acc: 0.3000\n",
      "Epoch 83/100\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 1.8249 - acc: 0.9832 - val_loss: 7.2395 - val_acc: 0.2600\n",
      "Epoch 84/100\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 1.8187 - acc: 0.9748 - val_loss: 7.5535 - val_acc: 0.3000\n",
      "Epoch 85/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 1.7705 - acc: 0.9874 - val_loss: 7.5526 - val_acc: 0.3000\n",
      "Epoch 86/100\n",
      "238/238 [==============================] - 16s 66ms/step - loss: 1.8366 - acc: 0.9790 - val_loss: 7.6693 - val_acc: 0.3000\n",
      "Epoch 87/100\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 1.7437 - acc: 0.9916 - val_loss: 7.0102 - val_acc: 0.3200\n",
      "Epoch 88/100\n",
      "238/238 [==============================] - 16s 69ms/step - loss: 1.7908 - acc: 0.9748 - val_loss: 6.8898 - val_acc: 0.3400\n",
      "Epoch 89/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 1.7315 - acc: 0.9832 - val_loss: 7.0058 - val_acc: 0.3200\n",
      "Epoch 90/100\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 1.7701 - acc: 0.9790 - val_loss: 7.1323 - val_acc: 0.2600\n",
      "Epoch 91/100\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 1.7037 - acc: 0.9832 - val_loss: 6.8192 - val_acc: 0.3000\n",
      "Epoch 92/100\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 1.7109 - acc: 0.9706 - val_loss: 7.4139 - val_acc: 0.3000\n",
      "Epoch 93/100\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 1.6727 - acc: 0.9790 - val_loss: 7.5143 - val_acc: 0.3200\n",
      "Epoch 94/100\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 1.6789 - acc: 0.9790 - val_loss: 7.3900 - val_acc: 0.3600\n",
      "Epoch 95/100\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 1.7287 - acc: 0.9748 - val_loss: 7.3094 - val_acc: 0.3400\n",
      "Epoch 96/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 1.6278 - acc: 0.9790 - val_loss: 7.2030 - val_acc: 0.3400\n",
      "Epoch 97/100\n",
      "238/238 [==============================] - 17s 71ms/step - loss: 1.6337 - acc: 0.9790 - val_loss: 6.9687 - val_acc: 0.3000\n",
      "Epoch 98/100\n",
      "238/238 [==============================] - 16s 68ms/step - loss: 1.6500 - acc: 0.9664 - val_loss: 7.2756 - val_acc: 0.3200\n",
      "Epoch 99/100\n",
      "238/238 [==============================] - 16s 67ms/step - loss: 1.6990 - acc: 0.9622 - val_loss: 7.4365 - val_acc: 0.3400\n",
      "Epoch 100/100\n",
      "238/238 [==============================] - 17s 70ms/step - loss: 1.5684 - acc: 0.9874 - val_loss: 7.6742 - val_acc: 0.3200\n",
      "50/50 [==============================] - 0s 5ms/step\n",
      "\n",
      "Testing loss: 7.67420768737793, acc: 0.32000000059604644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(x1_train_add, y1_train_onehot,\n",
    "              batch_size=32,\n",
    "              epochs=100,shuffle=True,\n",
    "          callbacks=[time_callback,acc_callback],\n",
    "         validation_data=(x1_test_add, y1_test_onehot),verbose=1)\n",
    "times = time_callback.times\n",
    "loss,acc=model.evaluate(x1_test_add, y1_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d227d4a0f0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(times[1:],acc_callback.testaccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Conv2D, Conv3D, MaxPooling1D,MaxPooling2D, AveragePooling2D, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4, input_shape=(1000, 22, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',kernel_initializer='uniform', padding='valid', name='block1_conv1'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='uniform',padding='same', name='block1_conv2'))\n",
    "model.add(MaxPooling2D((3,1), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu',kernel_initializer='uniform', padding='same', name='block2_conv1'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='uniform',padding='same', name='block2_conv2'))\n",
    "model.add(MaxPooling2D((3, 1), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='uniform',padding='same', name='block3_conv1'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu',kernel_initializer='uniform', padding='same', name='block3_conv2'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu',kernel_initializer='uniform', padding='same', name='block3_conv3'))\n",
    "model.add(MaxPooling2D((3, 1), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',kernel_initializer='uniform', padding='same', name='block4_conv1'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',kernel_initializer='uniform', padding='same', name='block4_conv2'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='uniform',padding='same', name='block4_conv3'))\n",
    "model.add(MaxPooling2D((3, 1), strides=(2, 2), name='block4_pool'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',kernel_initializer='uniform', padding='same', name='block5_conv1'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',kernel_initializer='uniform', padding='same', name='block5_conv2'))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu',kernel_initializer='uniform', padding='same', name='block5_conv3'))\n",
    "model.add(MaxPooling2D((3, 1), strides=(2, 2), name='block5_pool'))\n",
    "model.add(Flatten())  \n",
    "\n",
    "model.add(Dense(4096,activation='relu'))  \n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(4096,activation='relu'))  \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096,activation='relu'))  \n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(4,activation='softmax'))  \n",
    "\n",
    "# 991*22*25\n",
    "\n",
    "# 22*25*991\n",
    "#model.add(Conv2D(filters=976, kernel_size=(22,1), strides=1,activation='relu',padding='valid',kernel_regularizer = regularizers.l2(0.01),kernel_initializer='uniform'))\n",
    "# 1*25*991\n",
    "#model.add(Reshape((976,40,1), input_shape=(1,40,976)))\n",
    "# 991*25*1\n",
    "#model.add(AveragePooling2D(pool_size=(75,1),strides=(15,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "time_callback = TimeHistory()\n",
    "acc_callback = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "238/238 [==============================] - 143s 601ms/step - loss: 11.1004 - acc: 0.2143 - val_loss: 11.9274 - val_acc: 0.2600\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 119s 500ms/step - loss: 12.1224 - acc: 0.2479 - val_loss: 11.9274 - val_acc: 0.2600\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 116s 488ms/step - loss: 12.1224 - acc: 0.2479 - val_loss: 11.9274 - val_acc: 0.2600\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 116s 489ms/step - loss: 12.1224 - acc: 0.2479 - val_loss: 11.9274 - val_acc: 0.2600\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 117s 492ms/step - loss: 12.1224 - acc: 0.2479 - val_loss: 11.9274 - val_acc: 0.2600\n",
      "Epoch 6/10\n",
      "238/238 [==============================] - 123s 516ms/step - loss: 12.1224 - acc: 0.2479 - val_loss: 11.9274 - val_acc: 0.2600\n",
      "Epoch 7/10\n",
      "238/238 [==============================] - 121s 508ms/step - loss: 12.1224 - acc: 0.2479 - val_loss: 11.9274 - val_acc: 0.2600\n",
      "Epoch 8/10\n",
      " 32/238 [===>..........................] - ETA: 1:36 - loss: 12.5923 - acc: 0.2188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-6c1a5080eeb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_callback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m          validation_data=(x1_test_add.transpose(0,3,2,1), y1_test_onehot),verbose=1)\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_test_add\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1_test_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x1_train_add.transpose(0,3,2,1), y1_train_onehot,\n",
    "              batch_size=32,\n",
    "              epochs=10,shuffle=True,\n",
    "          callbacks=[time_callback,acc_callback],\n",
    "         validation_data=(x1_test_add.transpose(0,3,2,1), y1_test_onehot),verbose=1)\n",
    "times = time_callback.times\n",
    "loss,acc=model.evaluate(x1_test_add.transpose(0,3,2,1), y1_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d226ad1dd8>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(times[1:],acc_callback.testaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train_tr=x1_train.transpose(0,2,1)\n",
    "x1_test_tr=x1_test.transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#model.add(Dense(4, input_shape=x1_train_tr.shape[1:]))\n",
    "model.add(Conv1D(64, 25, strides=4,kernel_initializer='uniform',activation='relu', padding='valid', input_shape=x1_train_tr.shape[1:], name='block1_conv1'))\n",
    "model.add(Conv1D(64, 25, strides=1,activation='relu', kernel_initializer='uniform',padding='same', name='block1_conv2'))\n",
    "model.add(MaxPooling1D(3, strides=2, name='block1_pool'))\n",
    "\n",
    "model.add(Conv1D(128, 25, strides=1,activation='relu',kernel_initializer='uniform', padding='same', name='block2_conv1'))\n",
    "model.add(Conv1D(128, 25, strides=1,activation='relu',kernel_initializer='uniform', padding='same', name='block2_conv2'))\n",
    "model.add(MaxPooling1D(3, strides=2, name='block2_pool'))\n",
    "\n",
    "model.add(Conv1D(256, 25, strides=1,activation='relu',kernel_initializer='uniform', padding='same', name='block3_conv1'))\n",
    "model.add(Conv1D(256, 25, strides=1,activation='relu', kernel_initializer='uniform',padding='same', name='block3_conv2'))\n",
    "model.add(Conv1D(256, 25, strides=1,activation='relu', kernel_initializer='uniform',padding='same', name='block3_conv3'))\n",
    "model.add(MaxPooling1D(3, strides=2, name='block3_pool'))\n",
    "\n",
    "model.add(Conv1D(512, 25,strides=1, activation='relu',kernel_initializer='uniform', padding='same', name='block4_conv1'))\n",
    "model.add(Conv1D(512, 25, strides=1,activation='relu', kernel_initializer='uniform',padding='same', name='block4_conv2'))\n",
    "model.add(Conv1D(512, 25, strides=1,activation='relu',kernel_initializer='uniform', padding='same', name='block4_conv3'))\n",
    "model.add(MaxPooling1D(3, strides=2, name='block4_pool'))\n",
    "\n",
    "model.add(Conv1D(512, 25, strides=1,activation='relu',kernel_initializer='uniform', padding='same', name='block5_conv1'))\n",
    "model.add(Conv1D(512, 25, strides=1,activation='relu',kernel_initializer='uniform', padding='same', name='block5_conv2'))\n",
    "model.add(Conv1D(512, 25, strides=1,activation='relu',kernel_initializer='uniform', padding='same', name='block5_conv3'))\n",
    "model.add(MaxPooling1D(3, strides=2, name='block5_pool'))\n",
    "model.add(Flatten())  \n",
    "\n",
    "model.add(Dense(4096,activation='relu'))  \n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(4096,activation='relu'))  \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096,activation='relu'))  \n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(4,activation='softmax'))  \n",
    "\n",
    "#model.add(Dense(4096,activation='relu'))  \n",
    "#model.add(Dropout(0.5)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "time_callback = TimeHistory()\n",
    "acc_callback = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 50 samples\n",
      "Epoch 1/30\n",
      "238/238 [==============================] - 42s 176ms/step - loss: 12.5965 - acc: 0.2185 - val_loss: 11.4677 - val_acc: 0.2800\n",
      "Epoch 2/30\n",
      "238/238 [==============================] - 36s 153ms/step - loss: 12.5292 - acc: 0.2227 - val_loss: 12.2498 - val_acc: 0.2400\n",
      "Epoch 3/30\n",
      "238/238 [==============================] - 36s 152ms/step - loss: 12.0547 - acc: 0.2521 - val_loss: 12.2498 - val_acc: 0.2400\n",
      "Epoch 4/30\n",
      "238/238 [==============================] - 36s 153ms/step - loss: 12.0547 - acc: 0.2521 - val_loss: 12.2498 - val_acc: 0.2400\n",
      "Epoch 5/30\n",
      "238/238 [==============================] - 36s 153ms/step - loss: 12.0547 - acc: 0.2521 - val_loss: 12.2498 - val_acc: 0.2400\n",
      "Epoch 6/30\n",
      "238/238 [==============================] - 37s 154ms/step - loss: 12.0547 - acc: 0.2521 - val_loss: 12.2498 - val_acc: 0.2400\n",
      "Epoch 7/30\n",
      "238/238 [==============================] - 37s 155ms/step - loss: 12.0547 - acc: 0.2521 - val_loss: 12.2498 - val_acc: 0.2400\n",
      "Epoch 8/30\n",
      "238/238 [==============================] - 37s 156ms/step - loss: 12.0547 - acc: 0.2521 - val_loss: 12.2498 - val_acc: 0.2400\n",
      "Epoch 9/30\n",
      "238/238 [==============================] - 37s 154ms/step - loss: 12.0547 - acc: 0.2521 - val_loss: 12.2498 - val_acc: 0.2400\n",
      "Epoch 10/30\n",
      " 80/238 [=========>....................] - ETA: 23s - loss: 11.4841 - acc: 0.2875"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-de46716904a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_callback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m          validation_data=(x1_test_tr, y1_test_onehot),verbose=1)\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_test_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1_test_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x1_train_tr, y1_train_onehot,\n",
    "              batch_size=80,\n",
    "              epochs=30,shuffle=True,\n",
    "          callbacks=[time_callback,acc_callback],\n",
    "         validation_data=(x1_test_tr, y1_test_onehot),verbose=1)\n",
    "times = time_callback.times\n",
    "loss,acc=model.evaluate(x1_test_tr, y1_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0005, nesterov=False)\n",
    "model2 = ResnetBuilder.build_resnet_18((1000,1,22), 4)\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "time_callback = TimeHistory()\n",
    "acc_callback = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 50 samples\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7391 - acc: 1.0000 - val_loss: 5.4733 - val_acc: 0.1200\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7348 - acc: 1.0000 - val_loss: 5.5225 - val_acc: 0.1200\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7424 - acc: 0.9958 - val_loss: 5.5829 - val_acc: 0.1200\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7336 - acc: 1.0000 - val_loss: 5.5814 - val_acc: 0.1200\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7324 - acc: 1.0000 - val_loss: 5.5596 - val_acc: 0.1400\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7336 - acc: 1.0000 - val_loss: 5.5520 - val_acc: 0.1400\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7325 - acc: 1.0000 - val_loss: 5.5543 - val_acc: 0.1400\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7321 - acc: 1.0000 - val_loss: 5.5590 - val_acc: 0.1400\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7509 - acc: 0.9916 - val_loss: 5.5741 - val_acc: 0.1400\n",
      "Epoch 10/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7310 - acc: 1.0000 - val_loss: 5.7165 - val_acc: 0.1600\n",
      "Epoch 11/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7717 - acc: 0.9748 - val_loss: 5.6393 - val_acc: 0.1600\n",
      "Epoch 12/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7333 - acc: 1.0000 - val_loss: 5.6631 - val_acc: 0.1400\n",
      "Epoch 13/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7470 - acc: 0.9916 - val_loss: 5.6441 - val_acc: 0.1400\n",
      "Epoch 14/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7365 - acc: 1.0000 - val_loss: 5.6554 - val_acc: 0.1600\n",
      "Epoch 15/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7333 - acc: 1.0000 - val_loss: 5.6910 - val_acc: 0.1600\n",
      "Epoch 16/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7919 - acc: 0.9832 - val_loss: 5.6205 - val_acc: 0.1600\n",
      "Epoch 17/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7504 - acc: 0.9832 - val_loss: 5.3371 - val_acc: 0.2000\n",
      "Epoch 18/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7414 - acc: 0.9958 - val_loss: 5.2986 - val_acc: 0.1800\n",
      "Epoch 19/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7478 - acc: 0.9958 - val_loss: 5.2599 - val_acc: 0.1800\n",
      "Epoch 20/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7404 - acc: 1.0000 - val_loss: 5.0512 - val_acc: 0.2000\n",
      "Epoch 21/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.7392 - acc: 0.9916 - val_loss: 5.0401 - val_acc: 0.2000\n",
      "Epoch 22/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7307 - acc: 1.0000 - val_loss: 5.0477 - val_acc: 0.2000\n",
      "Epoch 23/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.7369 - acc: 0.9958 - val_loss: 5.0403 - val_acc: 0.1800\n",
      "Epoch 24/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7309 - acc: 1.0000 - val_loss: 5.0416 - val_acc: 0.1800\n",
      "Epoch 25/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7311 - acc: 1.0000 - val_loss: 5.0412 - val_acc: 0.2000\n",
      "Epoch 26/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7323 - acc: 1.0000 - val_loss: 5.0624 - val_acc: 0.2000\n",
      "Epoch 27/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7300 - acc: 1.0000 - val_loss: 5.0949 - val_acc: 0.2200\n",
      "Epoch 28/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7344 - acc: 0.9958 - val_loss: 5.1152 - val_acc: 0.2200\n",
      "Epoch 29/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.7282 - acc: 1.0000 - val_loss: 5.1403 - val_acc: 0.2200\n",
      "Epoch 30/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7277 - acc: 1.0000 - val_loss: 5.1504 - val_acc: 0.2200\n",
      "Epoch 31/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7314 - acc: 1.0000 - val_loss: 5.1427 - val_acc: 0.2200\n",
      "Epoch 32/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7318 - acc: 1.0000 - val_loss: 5.1217 - val_acc: 0.2200\n",
      "Epoch 33/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7302 - acc: 1.0000 - val_loss: 5.1384 - val_acc: 0.2200\n",
      "Epoch 34/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7282 - acc: 1.0000 - val_loss: 5.1430 - val_acc: 0.2000\n",
      "Epoch 35/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7275 - acc: 1.0000 - val_loss: 5.1502 - val_acc: 0.2000\n",
      "Epoch 36/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7291 - acc: 1.0000 - val_loss: 5.1556 - val_acc: 0.2000\n",
      "Epoch 37/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.7278 - acc: 1.0000 - val_loss: 5.1620 - val_acc: 0.2000\n",
      "Epoch 38/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.7283 - acc: 1.0000 - val_loss: 5.1534 - val_acc: 0.2000\n",
      "Epoch 39/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7270 - acc: 1.0000 - val_loss: 5.1360 - val_acc: 0.1800\n",
      "Epoch 40/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7271 - acc: 1.0000 - val_loss: 5.1273 - val_acc: 0.1800\n",
      "Epoch 41/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7267 - acc: 1.0000 - val_loss: 5.1255 - val_acc: 0.1800\n",
      "Epoch 42/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7263 - acc: 1.0000 - val_loss: 5.1250 - val_acc: 0.1800\n",
      "Epoch 43/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7261 - acc: 1.0000 - val_loss: 5.1244 - val_acc: 0.1800\n",
      "Epoch 44/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7259 - acc: 1.0000 - val_loss: 5.1261 - val_acc: 0.1800\n",
      "Epoch 45/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7254 - acc: 1.0000 - val_loss: 5.1297 - val_acc: 0.1800\n",
      "Epoch 46/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7251 - acc: 1.0000 - val_loss: 5.1260 - val_acc: 0.1800\n",
      "Epoch 47/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7249 - acc: 1.0000 - val_loss: 5.1269 - val_acc: 0.1800\n",
      "Epoch 48/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7253 - acc: 1.0000 - val_loss: 5.1243 - val_acc: 0.1800\n",
      "Epoch 49/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7269 - acc: 1.0000 - val_loss: 5.1355 - val_acc: 0.1800\n",
      "Epoch 50/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7256 - acc: 1.0000 - val_loss: 5.1618 - val_acc: 0.1600\n",
      "Epoch 51/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7264 - acc: 1.0000 - val_loss: 5.1701 - val_acc: 0.1600\n",
      "Epoch 52/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7292 - acc: 0.9958 - val_loss: 5.1720 - val_acc: 0.1600\n",
      "Epoch 53/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7242 - acc: 1.0000 - val_loss: 5.1525 - val_acc: 0.1800\n",
      "Epoch 54/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7239 - acc: 1.0000 - val_loss: 5.1418 - val_acc: 0.1800\n",
      "Epoch 55/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7258 - acc: 1.0000 - val_loss: 5.1484 - val_acc: 0.1800\n",
      "Epoch 56/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7242 - acc: 1.0000 - val_loss: 5.1545 - val_acc: 0.1800\n",
      "Epoch 57/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7236 - acc: 1.0000 - val_loss: 5.1915 - val_acc: 0.1800\n",
      "Epoch 58/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7233 - acc: 1.0000 - val_loss: 5.2055 - val_acc: 0.1800\n",
      "Epoch 59/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7233 - acc: 1.0000 - val_loss: 5.2124 - val_acc: 0.1800\n",
      "Epoch 60/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.7233 - acc: 1.0000 - val_loss: 5.2141 - val_acc: 0.1800\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 9s 36ms/step - loss: 0.7231 - acc: 1.0000 - val_loss: 5.2184 - val_acc: 0.1800\n",
      "Epoch 62/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7230 - acc: 1.0000 - val_loss: 5.2266 - val_acc: 0.1800\n",
      "Epoch 63/100\n",
      "238/238 [==============================] - 8s 36ms/step - loss: 0.7229 - acc: 1.0000 - val_loss: 5.2243 - val_acc: 0.1800\n",
      "Epoch 64/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.7225 - acc: 1.0000 - val_loss: 5.2292 - val_acc: 0.1800\n",
      "Epoch 65/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.7223 - acc: 1.0000 - val_loss: 5.2297 - val_acc: 0.1800\n",
      "Epoch 66/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.7221 - acc: 1.0000 - val_loss: 5.2345 - val_acc: 0.1800\n",
      "Epoch 67/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.7224 - acc: 1.0000 - val_loss: 5.2435 - val_acc: 0.1800\n",
      "Epoch 68/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7218 - acc: 1.0000 - val_loss: 5.2275 - val_acc: 0.1800\n",
      "Epoch 69/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7244 - acc: 1.0000 - val_loss: 5.2289 - val_acc: 0.1800\n",
      "Epoch 70/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7219 - acc: 1.0000 - val_loss: 5.2319 - val_acc: 0.1800\n",
      "Epoch 71/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7215 - acc: 1.0000 - val_loss: 5.2496 - val_acc: 0.1800\n",
      "Epoch 72/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7216 - acc: 1.0000 - val_loss: 5.2521 - val_acc: 0.1800\n",
      "Epoch 73/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7211 - acc: 1.0000 - val_loss: 5.2510 - val_acc: 0.1800\n",
      "Epoch 74/100\n",
      "238/238 [==============================] - 8s 32ms/step - loss: 0.7218 - acc: 1.0000 - val_loss: 5.2524 - val_acc: 0.1800\n",
      "Epoch 75/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7229 - acc: 1.0000 - val_loss: 5.2425 - val_acc: 0.1800\n",
      "Epoch 76/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7209 - acc: 1.0000 - val_loss: 5.2313 - val_acc: 0.1800\n",
      "Epoch 77/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7207 - acc: 1.0000 - val_loss: 5.2296 - val_acc: 0.1800\n",
      "Epoch 78/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7205 - acc: 1.0000 - val_loss: 5.2349 - val_acc: 0.1800\n",
      "Epoch 79/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7211 - acc: 1.0000 - val_loss: 5.2388 - val_acc: 0.1800\n",
      "Epoch 80/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7204 - acc: 1.0000 - val_loss: 5.2498 - val_acc: 0.1800\n",
      "Epoch 81/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7206 - acc: 1.0000 - val_loss: 5.2563 - val_acc: 0.1800\n",
      "Epoch 82/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7223 - acc: 1.0000 - val_loss: 5.2645 - val_acc: 0.1800\n",
      "Epoch 83/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7201 - acc: 1.0000 - val_loss: 5.2264 - val_acc: 0.1800\n",
      "Epoch 84/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7200 - acc: 1.0000 - val_loss: 5.2204 - val_acc: 0.2000\n",
      "Epoch 85/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7196 - acc: 1.0000 - val_loss: 5.2184 - val_acc: 0.2000\n",
      "Epoch 86/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7195 - acc: 1.0000 - val_loss: 5.2208 - val_acc: 0.2000\n",
      "Epoch 87/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7192 - acc: 1.0000 - val_loss: 5.2202 - val_acc: 0.1800\n",
      "Epoch 88/100\n",
      "238/238 [==============================] - 8s 33ms/step - loss: 0.7191 - acc: 1.0000 - val_loss: 5.2276 - val_acc: 0.1800\n",
      "Epoch 89/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7208 - acc: 1.0000 - val_loss: 5.2246 - val_acc: 0.1800\n",
      "Epoch 90/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7186 - acc: 1.0000 - val_loss: 5.2071 - val_acc: 0.1600\n",
      "Epoch 91/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7198 - acc: 1.0000 - val_loss: 5.2079 - val_acc: 0.1600\n",
      "Epoch 92/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7200 - acc: 1.0000 - val_loss: 5.2031 - val_acc: 0.1600\n",
      "Epoch 93/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7184 - acc: 1.0000 - val_loss: 5.1814 - val_acc: 0.1600\n",
      "Epoch 94/100\n",
      "238/238 [==============================] - 8s 34ms/step - loss: 0.7184 - acc: 1.0000 - val_loss: 5.1763 - val_acc: 0.1600\n",
      "Epoch 95/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.7183 - acc: 1.0000 - val_loss: 5.1661 - val_acc: 0.1800\n",
      "Epoch 96/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.7180 - acc: 1.0000 - val_loss: 5.1648 - val_acc: 0.1800\n",
      "Epoch 97/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.7184 - acc: 1.0000 - val_loss: 5.1700 - val_acc: 0.1600\n",
      "Epoch 98/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.7176 - acc: 1.0000 - val_loss: 5.1774 - val_acc: 0.1400\n",
      "Epoch 99/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.7182 - acc: 1.0000 - val_loss: 5.1862 - val_acc: 0.1600\n",
      "Epoch 100/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.7178 - acc: 1.0000 - val_loss: 5.1899 - val_acc: 0.1400\n",
      "50/50 [==============================] - 0s 5ms/step\n",
      "\n",
      "Testing loss: 6.43531753540039, acc: 0.4000000023841858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2.fit(x2_train_add, y2_train_onehot,\n",
    "              batch_size=32,\n",
    "              epochs=100,shuffle=True,\n",
    "          callbacks=[time_callback,acc_callback],\n",
    "         validation_data=(x2_test_add, y2_test_onehot),verbose=1)\n",
    "times = time_callback.times\n",
    "loss,acc=model.evaluate(x2_test_add, y2_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d257603a58>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3X1wZFd55/Hv02+SWtKMWpqxMTMev4ANDOBgkG1ebZIQY5OsnU1sYm+y4K0kJstSlZfdSpklRQJkN7skm2KpeBMmCSEkIY4hkBAwIQ5xIAkYbPNiGL8xGGMPxoxn1JoZdUvqt7N/3HtarVZ360pqSbd1f5+qqem+ffv2menup8997jnPMeccIiKSDKntboCIiGwdBX0RkQRR0BcRSRAFfRGRBFHQFxFJEAV9EZEEUdAXEUkQBX0RkQRR0BcRSZDMdjeg3Z49e9y555673c0QERko991333Hn3N7V9otd0D/33HO59957t7sZIiIDxcy+E2U/pXdERBJEQV9EJEEU9EVEEkRBX0QkQRT0RUQSJFLQN7OrzOxhMztiZrd0ePxXzOwBM7vfzD5jZueE219kZl8ws8PhYz/V73+AiIhEt2rQN7M0cCtwNXAQuNHMDrbt9hVg2jl3EfAR4N3h9jLwBufc84GrgPeY2US/Gi8iImsTZZz+pcAR59yjAGZ2G3At8IDfwTl3V8v+dwM/E25/pGWfJ83sGLAXmN1406Xf7nroGF95vNiXY+0ayfKfXnEe6ZT15Xgi0h9Rgv4+4ImW+0eBy3rs/7PAp9o3mtmlQA74VofHbgZuBjhw4ECEJslm+LW/+QbfnZ3HNhin/bLLl503xQv37954w0Skb6IE/U4hoONq6mb2M8A0cEXb9rOAPwPe6JxrrDiYc4eAQwDT09NaqX0bOOc4PrfImy4/n7e+7nkbOtZ93ynyk7//eU6UFvvUOhHplyhB/yhwdsv9/cCT7TuZ2WuAtwFXOOcWW7bvAj4J/Jpz7u6NNVc2y3y1zmKtQWE0t+FjFfJZAIrlyoaPJSL9FWX0zj3ABWZ2npnlgBuAj7fuYGYXA+8DrnHOHWvZngM+BnzQOffh/jVb+m2mFAToyfzGg/5k+MNRLFU3fCwR6a9Vg75zrga8Bfg08CBwu3PusJm908yuCXf7bWAM+LCZfdXM/I/C64HLgZvC7V81sxf1/58hG+UDdD96+ruGs6QMZtXTF4mdSFU2nXN3AHe0bXt7y+3XdHnenwN/vpEGytaYCQP05Gh2w8dKpYzdI9nmMUUkPjQjVwAohumdQh/SO/44xbLSOyJxo6AvQEtOvw/pHQjSRErviMSPgr4AQdBPp4xdwxtP70AwgmdGF3JFYkdBX4Agp1/IZ0n1aQbtRF49fZE4UtAXIMjp9yufD0GaSOP0ReJHQV+AIL3Tj+Ga3kQ+y0K1wXyl3rdjisjGKegLEMye7cfELM+fNai3LxIvCvoCwEyp2teevoK+SDwp6AvOuaCn34eJWV6z/o5G8IjEioK+cGqhRr3h+noh1581qKcvEi8K+tKcjduviVmwlN7RsE2ReFHQl2aNnH6P3gE0QUskZhT0Zamn38f0TjadYnwoo/SOSMwo6Evf6+54qr8jEj8K+rJ5QT+fZUaVNkViRUFfmClXyGVS5HPpvh5X9XdE4kdBXyiWgtm4Zv0ptuYV8lnl9EViRkFf+j4b1yuM5jQ5SyRmFPSl77NxvUI+x9xijUqt0fdji8j6KOhL38sqe74Uw+y8UjwicaGgL8yUK30fuQMtpRiU4hGJDQX9hKvVG5ycr25ST1/1d0TiRkE/4U7OV3EOpsb6H/R9KQYN2xSJDwX9hPO98M3o6fuUkerviMSHgn7C+YC8KTl9pXdEYkdBP+F8CYbN6OkPZ9MMZ1NK74jEiIJ+wvle+Gb09CGo3Kn0jkh8KOgnnO/p+4uu/ab6OyLxoqCfcDOlCqO5NMPZ/hZb8wqjqr8jEicK+glXLFU2pe6ON5HPUVR5ZZHYiBT0zewqM3vYzI6Y2S0dHv8VM3vAzO43s8+Y2Tktj73RzL4Z/nljPxsvG7dZs3G9yXxOPX2RGFk16JtZGrgVuBo4CNxoZgfbdvsKMO2cuwj4CPDu8LmTwK8DlwGXAr9uZoX+NV82arPq7niFfJaT81XqDbdpryEi0UXp6V8KHHHOPeqcqwC3Ade27uCcu8s5Vw7v3g3sD2+/FrjTOTfjnCsCdwJX9afp0g8z5QpTm5zecS6Y+Ssi2y8TYZ99wBMt948S9Ny7+VngUz2eu28tDUyS+75T5G0f+zofffPLyec6vzXFUoUr3/M5TnbJk1/9wmfwf2+4uOtrlBZr/Mjvfpbjc0HKpVJv8NqDmxf0fXmHy/7nP2JEX6TllRfs4f03XbJZzZId4qmTC/zoe/+F0wu1FY8NZ1N8+BdeznOeMb4NLYuvKEG/0ze147m6mf0MMA1csZbnmtnNwM0ABw4ciNCknenwkyd56KnTPDEz3/WD+u0TJZ4+vciPXXQWZ0/mlz1210PHuOfbMz1f44limSdPLnDV85/BeXtHSRlc/5Kz+/ZvaPeDzz2DX37NhSzU6pGf8/lvneCex3r/O0QAjhyb40Spwk9cvI8zdw83t5+ar/IXX3ych546paDfJkrQPwq0RoX9wJPtO5nZa4C3AVc45xZbnvvqtuf+c/tznXOHgEMA09PTiU3+litBYPRj5zspho/9/KvO5wfOnlj2WL3h+NPPP4ZzruvSh/7Yb3z5ubzsWVP9aHZPu4az/OJrLljTc977mW/ytSdmqdYbZNMaYCbd+UECv/DqZ3HhmUvBfaZU4S+++Hjz+yJLonyj7gEuMLPzzCwH3AB8vHUHM7sYeB9wjXPuWMtDnwauNLNCeAH3ynCbdDAfJeiHaZ1OF18nR3Ms1hrNH4+Ozw9nx25GVc1+adbh16gfWYWf+Nc+uXD3SBYzmNFw4RVWDfrOuRrwFoJg/SBwu3PusJm908yuCXf7bWAM+LCZfdXMPh4+dwZ4F8EPxz3AO8Nt0sFCNQz6PYKd77kUOixvuFTVsvvzZ0rBSdhmjtjZqMm8Fl+RaHyJj/bPczpl7B7JajZ4B1HSOzjn7gDuaNv29pbbr+nx3PcD719vA5Okmd6Z6xG0yxWyaWNsaOVb50fhnChVVuT7m88PvySbVXahH/wyi71+vEQgOBscH8p0TAMWNDGwIyVMY2Q+7On3SmsUSxUm8rmOOfulnv7iise8mdIiu0eysc6V+/SOemmymtlyhYkOZ70QdGyU018pvt/8BPJB/0TPnH6lmf5oNzU6FDy/55lCdVNn4PZD88dLQV9WMVPuvtSnZoN3pqAfIwtheqdX76RYqnbM5wNMjkXL6RdinNqBpdSTemmymtly9xnlQYVXpXfaKejHSJQhm71q5Yzm0gxlUj3PFGZKVSbDM4K4GsqkGRvKqA6/rKpYrnTtxBTyWV0X6kBBP0Z8eme1cfoTXXo2ZsbUaK5neqdYqjDZ5UwhTlSSWaIolqpdvw+F0Rzz1XpzVJwEFPRjpHXIpnMr56g1Go7Z+WrXnD4EKZ5uF3Kdc8yUKrHv6YNfcUtBX7qr1BrMLda6nvn6tI9SPMsp6MeIT+9Uag1KHSZYnV6oUW+4nvXvJ0eHugbLUqVOpd4YkJ6+LsJJb7Pzfn3n7ukd0NDfdgr6MTJfrZMLh1J2uojpR7P0uhA7NZrrmtP34//jPDHLK6inL6soNuecdE/vgIb+tlPQj5GFSp1nTgRFozoFbt/z7d3T7x4s/Y9GnEsweAWNvJBV+O/DaukdDf1dTkE/RuardZ45MQJ07un7bT1z+qM5ypV6s45Pp+cPQk9/cjTL3GKNxTVU55Rk6VZ3x/NnxJqVu5yCfkxUag1qDce+MOh36un7HnyvyVVLpRhWXsz1x5wagAu5S6fm+sJKZ93q7ng+7TOrNOEyCvox4Ydr7iv06Omv0rMBmBoLAnqnFE+vYm1x489mlNeXbprpzi5BP5dJBfM9lN5ZRkE/Jvxwzb3jQ2TT1iWnX+1abM2bbCm61u5EqXuxtrhplldW0JcuZssVhrMpRnLprvtM5LM6W2yjoB8TfrhmPpcOqgN26akXuhRb83x6p1OlzmBiVu/nx4Xq78hqij3q7niTGvq7goJ+TPgLryPZNJNdhl3OlLqXYPB61d85UepepyRuCnn19KW3YoTP80SXDlSSKejHhM/pj+QyXXsns+XqqnXwg9ri3dJDlYEYrglL1y1Uf0e6KZYrq16fKuSzGr3TRkE/JnxO3/f0O/XUexVb88wsfP7K0TtRekZxkU2nGB/O6NRcugo6Qb0/zwWVV15BQT8mypXVg37UoN2tFMOJCOmhOFE+VnqZ6VFh0yvkc5xeqFGtN7aoVfGnoB8TS+mdIOifnK9Sa/mgNhouLCO7etDeM5bjeNuF3Fq9wcn5+C+g0kqlGKSbesMFn+fVevph+kcjeJYo6MeEX0DFB31YPpPw9EKNhutdgsHrdKbgjzVIQV89fenm1HwV57rX3fGaAwL0OWpS0I+JcqUGBOmdTh/UmWadkdUnVnUO+oNTgsELhq6qhyYrNYsPrnohV6PA2inox8R8NUjl5HPppVIKLSkaH8SjBO2p0dyKujUzzRIMgxP0J0e18pF0NhuxEzOh+jsrKOjHhM/pD2VSS7NRW3r6UT/kQHORlNaA2fzRGKCg71c+6lQ8TpKtuErdHW+yw3cp6RT0Y2KhWmckm24ueQjLSylEKbbmTfY4Uxiknr7ysdLNTMROkD5DKynox0S5UmvWEJnokIeMUkvfm+owK9ffXu3CV5zoCyvdzEbM6Y/k0gxlUhq900JBPybmKw1GskHQz2WCiUnLg3ZQbG20R3Epr1N55ZlShfGhDLnM4LzlzVNzXcyVNsVylUwqWvHAXgsLJdHgRIAdbqFaX1YtsP2DOltevdia5+vlt6d3JgekBIPnRyqp6Jq0my1XmIj4fZjI57RkYgsF/ZgoV2rNnj6sDPpRiq15u0YyZFK27PlRJ3bFiYbbSTfB9yHauhCqv7Ocgn5MzLf39Ntmo64laJsZhQ4/GoN0ERdg90gWMy2kIisVI9Td8QqjqrTZSkE/JuarjVV7+mtZ8WqqrTxz8PzBCvqZdIrdI1ldyJUVZiPU3fGCnr4+Q56CfkwsVOorg365gnMOCGqHrCU90/qj4ZxbU3ooTtrPeEQgGNgQ9ftQyOeYna9Sb7hNbtVgiBT0zewqM3vYzI6Y2S0dHr/czL5sZjUzu67tsXeb2WEze9DM3muDsGzTNihXaysu5FZqDUqVerPY2lqCdmvQL1fqLNYaAxn0J9RLkzbOuaCnH/HzXMjncC6o1yMRgr6ZpYFbgauBg8CNZnawbbfHgZuAD7U99+XAK4CLgBcAlwBXbLjVO9B8pbEs6LeuEXtqoUojQnGpVlOjOU7MBUM2mxO7BuxCLoRF1zRkU1rMLdaoNVz09M6oL8WgzgNAlBWyLwWOOOceBTCz24BrgQf8Ds65x8LH2otWO2AYyAEGZIHvb7jVO5Cfkev5AP3BLzzGcLg96mgFgKmxIU4t1Pijf3mUY6cXw+cPXtAv5HPc81iRP/7Xb2/5a++bGOaqF5wVad8nZ+f5+288hRIIm+9k2GOP2gny+/353Y+zrzCy7LGhTIqffPH+nourR3H4yZPc/ehM8/74UIbrXrKfVCp+iY0oQX8f8ETL/aPAZVEO7pz7gpndBXyPIOj/nnPuwfb9zOxm4GaAAwcORDn0juKcWzFk81lnjJFNG3/4L0GwS6eMZ+0di3zM5zxjHIDf/GTw351NG+fvHe1jq7fGc54xzofvO8q7PvHA6jtvgq+9/Up2R+hRHvrco3zg849tfoMEgJTBs8+I9n04f88ouXSK9/9b545DIZ/jRy+K9uPezTv+7gG+9O2ZZdsuOHOMiw8UNnTczRAl6Hf6qYrUoTGzZwPPA/aHm+40s8udc59bdjDnDgGHAKanpxPXWarUGzQcy3ob5+0Z5eu/8VoWa8HJUy6dWlNv5LXPfwaH3/FaauHFq6FMqnnGMEh+7lXn8/pLzsZt8afik/d/j//+sa9zorQYKegfn1vk3Kk8f/uWV25B6ySbNvK5KOELzpka5f7fuLL5XfKKpQqv/p1/XjZzfb2On17ktc8/k3df9wM89L1T/NShu5tn2HET5X/tKHB2y/39wJMRj//vgbudc3MAZvYp4KXA53o+K2EWKsGHcaQtKA9n0xsK1KMRpqgPgl3D0dNa/XLW7mEgeklef6F998jWt1VW1+m75Eua9GN02IlShVfuGmb3SJazJ/N9O+5miDJ65x7gAjM7z8xywA3AxyMe/3HgCjPLmFmW4CLuivRO0rUulSjx4OuwR52+XywN1lKUEswD2TWc2XAxtmrbUqT+74EN+s65GvAW4NMEAft259xhM3unmV0DYGaXmNlR4HrgfWZ2OHz6R4BvAV8HvgZ8zTn3d5vw7xhoratmSTwsVfiM3tMfpAqmEmifub4eflSQn/E+nE0zNpTh+Nzgpndwzt0B3NG27e0tt+9hKW/fuk8deNMG27jjqacfPz7oR+7pr3EehcRDIb/xdZiX1roYam6Lc2VPzciNgQUf9NXTj43x4Qwpiza2e75SZ6HaGLiCdhLOA9lo0J9bucDR1FhuWZXbOFHQj4FyRT39uEmljIl8LlJ6Z2nReV3EHTQT+eyGJ//5GldTLaXL22tfxYmCfgz4NWDV04+XQj4bKb0ziOsPS2Cyr+md1qA/1JwRHzcK+jGgnH48FfLRSkD40R9K7wyewmiOcqXeTLGux4lSBbPl7//kWPBj4rZ6gkkECvoxoJx+PE1E7AX6lb3WUiZD4mHpgv36UzwzpUUmRrKkW0ouTI3mqNYdpxZqG25jvynox0BZ6Z1YCtI7UXr6g7fovAT8dZiNpHg6lS33+f04pngU9GNA6Z14KkQc2eFzuhOajTtwWqvZrteJuUpzXWrPD9+M47BNBf0YWKjUMQvq40h8TOSzLNYazQvt3RRLFXYNZ8ik9f4NGp/emel3Tz+8fzyGwzb1KY2BcrhqltaXiZelWbm9v7jFskowDKqlWvsbyelXmBzrnN5RT186mq/WySu1EztR870qwTC4JkY2lt7xq9pNtf3o+06AcvrS0Xy1PpBlj3e6iYgjO1SCYXDlMinGhzLrvpA7Ox+satf+/g9l0owPZWI5QUtBPwbaV82SeIic3ilVm1U5ZfBMjGbX3dOfKXVflW5qLJ71dxT0Y6BcqWvkTgwtpXci9PSV3hlYkxHLbXTi6+u0j96B4IegHwu09JuCfgzMV9TTj6NmeqdHb22hWqdcqasEwwCLOjS3k04lGLypsaFYFl1T0I+Bhap6+nGUy6QYzaV79gJVgmHwbaS8cqdia15ci64p6MdAWT392JrI53oWXVvq6SmnP6ii1ljqpFlsr8OP/uRojmKpQqMRr/o7CvoxMK+efmwVRrM9e4EqwTD4Cvksc4s1Km0Lp0cxU6owPpwh12Fi5dTYELWG49TCxko395uCfgxo9E58FVa5yLdUbE1Bf1D56zFRV0lrdaK0coy+57fHLcWjoB8DupAbX6uld/wPgoZsDq61rofcaqa02PUHP66zchX0t5lzjrLSO7FVyGd7BoNij5yuDAZfimE9wfnEXGXZ2rit4jorV0F/my3WGjinCptxNZHPcWqhSr3LxbiZUoXxoQxZFVsbWFEn4XUy0yO9s2cs+DFQekeW0QIq8VbIZ3EOTs537u3Plisaoz/gfI98rUHfuaDuTnuxNc//mMRtrL6C/jbTAirxtlovcKZc1YLoA85fj1lrKYZTCzWqdde1p5/LpNg1nFFOX5bTAirx5gNCt4u56ukPvqFMetVJeJ30mo3rTY0NcVw5fWk1r55+rDV7+l0m78yUKrqIuwNM5HNr7un3KrbmTY7Gr+iagv42W1BPP9ZWS+/MlqsK+jvA5Drq7/QqtuZNKehLO+X0421i1Kd3Vvb0K7UGc4s1lWDYAQqjOWbWm97pciEXgrH6cVsyUUF/mymnH2/jQxkyKevYC1QJhp2jkM+ueUZus9har5z+6BDFcrzq7yjobzMN2Yw3M2Mi37n+jkow7ByF/NrTMDOlCvlcuueqd5OjOeoN13XI73ZQ0N9mzfSOevqxNdGlCqPfphIMg6+Qz3F6oUa1Hr3oWpSL+L4UQ5wmaEUK+mZ2lZk9bGZHzOyWDo9fbmZfNrOamV3X9tgBM/sHM3vQzB4ws3P70/SdwY/eyWcz29wS6abQpadfVE9/x5jsce2mm5lSpWMd/Vb+Im+cLuauGvTNLA3cClwNHARuNLODbbs9DtwEfKjDIT4I/LZz7nnApcCxjTR4p/E5/eGcTrriKii6tjIY9KqlLoNlYh2lGGZKlVV/8Js9/RiN1Y8SaS4FjjjnHnXOVYDbgGtbd3DOPeacux9Ydm4U/jhknHN3hvvNOefK/Wn6zrBQrZMyyKl2S2x16+kvXchVemfQNUsxrKFHHinox7C8cpScwj7giZb7R4HLIh7/QmDWzD4KnAf8I3CLc66+plbG0G996kE++uXvNu+/6fLz+blXnd91/1vvOsIHPv/Yiu1zCzVGsmnMbDOaKX1QGM1x7PQil/yPf1y2fW6hxmguzVBG12MGnT9b+/kP3stQxEEVT59e7DlyB5Zq9Xeqv1OpNbjpT77Ef73yQl5yzuQaW7x+UYJ+p2gUdfxRBngVcDFBCuivCNJAf7zsBcxuBm4GOHDgQMRDb6/PPvw0w9kUr3z2Xu584Cn+9cjxnkH/s488TdqMH3zuGSsee8G+XZvZVNmg61+yn9JijU7X+C7av3vrGyR9d+GZY7z51c9aUymGlMHrp8/uuU82nWIin+VEaWV653sn5/n8t07wikdnYhf0jwKt/7L9wJMRj38U+Ipz7lEAM/sb4KW0BX3n3CHgEMD09HR8BrT2UCxXePWFZ/BbP/FCvjs7v+pp4UypwovPmeC3fuKFW9RC6ZdnnzHOb/643redLJNO8atXPXdTjr2nS/0dP2lrq2vzREkk3wNcYGbnmVkOuAH4eMTj3wMUzGxveP+HgAfW3sx4cc5RLFWbp26Tqyy0AUGuUBf8RJJnajTH8dMrO4X+4u5Wl15eNeg752rAW4BPAw8CtzvnDpvZO83sGgAzu8TMjgLXA+8zs8Phc+vAfwM+Y2ZfJ0gV/eHm/FO2TqlSp1JvNId5TeR71+1oNIK626vl/0Rk59kz3rmn70d/bfVwzkiDw51zdwB3tG17e8vtewjSPp2eeydw0QbaGDs+leOHebVO7Oi0gtLJ+SoNh0rwiiTQ3rEhPtch6PsRPXFM70ib5qQcH/RXmdih6foiybVnLOgU+pIrng/2Wz2cU0F/HZqTcsIg7nv83Qo2RVlsQUR2pm5r5fpc/kxpawuyKeivg+/p+2XyJpuz+bovtBHsr6AvkjQ+6B8/vTyN44dxbnVBNgX9dfCFtiabPf1wjc1Vevqr1ekQkZ1nz3gY9Nty962jdrYyxaOgvw7FcoWUwa7hINj7NM9q6R319EWSZ0/Y2VsR9EsVDkzmg9tbeDFXQX8dfEnVVCqYrOzTPDM91lFdre62iOxMzfROS8++0XDMlCpceOYYoJ5+7BXLlWVFtkayaYYyqa49/WKEwkwisjMNZ9OMD2V4uiWnf3K+Sr3huODMcUA9/dgrlqrLgriZUegxQeuEgr5IorVP0PI9+wvOUE9/IBTLK0sqTPQoxVAsK+iLJNmesdzyoB/ePnPXMIV8dktLMSjor0OnOtqFfK7nhdxJXcQVSayg6NrK0TqTozkmR3Mdq3BuFgX9NXLOMVuuNidkeYXRbNcaGlEWWxCRnau90qbv6U+N5Zhq+0HYbAr6a9RebM0rdFlSb6Fap1ypq+6OSILtGRtitlxtLrze7Onnc+wZy+lCbpwVu4y5L+RzzM5XcW75dGqVYBCRPePLV9A6MReMAMykU0yNDm1ppU0F/TXqNtFqIp+l3nCcWqh13F9BXyS5pkaXz8o9UVpaanFyNEexXKXWaWm2TaCgv0bNujsdLuTCylm5Cvoisjfs6T8dBv3jcxWmwklbfsbuTI81OfpJQX+Nil3KJPvyyu2nad32F5HkaC+6NlOqNIO9D/5bNWxTQX+NfKmF9iGYSz395Rdz/RupIZsiydVeXvnE3GKzI+jTPFuV11fQX6NiKSi2Nj68fNGxQrO88sqefspg98jy0T4ikhyjQxlGsmmOn16kVm9QLFebef6pLgXZNouC/hr52bi+2JpX6FJTv704m4gk057xYFauz9030zujSu/EWrFc6Tjmfnw4Q8o6X8jVGH0R8bNyl9bXCIL97pEs6ZRt2axcBf01CnruK1M1qZQxkc+tyMtpNq6IwNKs3OZ1vjAupFLG5OjK2LFZFPTXaLZc7boYSiGfXXEhV3V3RASWgr7P3e9pWUlvajS3ZaUYFPTXqFfPvVN55WK5wqSWSRRJvL1jQW/e19X3uXwILuZuVSkGBf01cM51zekDTORzyy7kNhqOYrmqnr6IsGd8iIaDI8fmSKds2Yi+qdGhLaupr6C/BnOLNap11zGnDz69s/TGnVoIVsfRhVwR8WP1H3rq9IoRfUFPX0E/dny+vmtOv+1iTPMqvYK+SOL5oP/I908vy+f7x+YWayxU65veDgX9NVitjk4hn2Ox1mC+Ul+2v3r6IuIDfblSb07I8ia3cFaugv4azHQptub5tI+/mKuevoh4e8aXLtxOtlzEhaUYsRUpHgX9NfD5+m7pnYm2Ugzq6YuINz6UIZcJQm57R9BP1Dq+BRO0FPTXoFuxNa/Z0w/382cGGr0jImbGnjDYr8zph+kd9fTjpViqkE7ZimJrnu/RN3v6cxVGsmlGcukta6OIxJdP8fievedz+ltRiiFS0Dezq8zsYTM7Yma3dHj8cjP7spnVzOy6Do/vMrPvmtnv9aPR22WmXGFiJNu1eFr7QiozZZVgEJElfgRPe1wYC1M/scjpm1kauBW4GjgI3GhmB9t2exy4CfhQl8O8C/js+psZD7M9JmZBsGQiLFXaVN0dEWnl0zjt6R2f+tmKUgyd8xTLXQoccc49CmBmtwHXAg/4HZwAyvH8AAAKDUlEQVRzj4WPrVjk0cxeApwJ/D0wvfEm98/nHnm6OSU6im9+f65nfj6bTjE+lOG+7xT56/uO8u3jJc6ZGu1HU0VkB/A9/am20TsQpHy2Ir0TJejvA55ouX8UuCzKwc0sBfwf4D8CP9xjv5uBmwEOHDgQ5dAbduz0Am94/5fW/LzrX7K/5+Pn7hnls488zWcfeRqAV1+4d13tE5Gd57ln7WLXcIYzdw2veGyrKm1GCfqdEtgu4vHfDNzhnHvCrPsiIs65Q8AhgOnp6ajH3hDfw3/Xj7+AKy6IHpifObHyzWp1+5tetuzsYV9hZH0NFJEd599ddBZXHjyT4ezKwR3/6ydfSDa9+WNrogT9o8DZLff3A09GPP7LgFeZ2ZuBMSBnZnPOuRUXg7eaL6lwwRljHJjK9+24I7l0X48nIjuHmXUM+ABn7d6aDmKUoH8PcIGZnQd8F7gB+A9RDu6c+2l/28xuAqbjEPBhaVhlt4lWIiI70arnEs65GvAW4NPAg8DtzrnDZvZOM7sGwMwuMbOjwPXA+8zs8GY2uh+KzdmyWrBcRJIjSk8f59wdwB1t297ecvsegrRPr2N8APjAmlu4SfywyokR9fRFJDkSOyN3plRpTogQEUmKxEa8YKKVUjsikiyJDfrFHguci4jsVAkO+hUFfRFJnIQHfaV3RCRZEhv0Z0vV5qInIiJJkcigX6k1OL1YUwVMEUmcRAb92Xk/G1fpHRFJlkQGfb+codauFZGkSWbQV90dEUmoRAb9WQV9EUmoRAb9mWZ6Rzl9EUmWRAZ9pXdEJKmSGfRLFUay6a6LGYiI7FTJDPrlqoZrikgiJTLoBxU2ldoRkeRJZNCfUbE1EUmoRAb92XKVCaV3RCSBEhn0i+WK6u6ISCIlLujXG46T86qwKSLJlLigf3K+inMwqfSOiCRQ4oL+TCmcmKX0jogkUOKCvq+7o/SOiCRR4oJ+sRzU3ZlU0BeRBEpe0C/5nr5y+iKSPMkL+mF6R0M2RSSJEhf0Z8oVcukU+ZyKrYlI8iQu6M+WqhRGs5jZdjdFRGTLJS7oF1V3R0QSLJFBXxdxRSSpIgV9M7vKzB42syNmdkuHxy83sy+bWc3MrmvZ/iIz+4KZHTaz+83sp/rZ+PUolqu6iCsiibVq0DezNHArcDVwELjRzA627fY4cBPwobbtZeANzrnnA1cB7zGziY02eiNmyxVNzBKRxMpE2OdS4Ihz7lEAM7sNuBZ4wO/gnHssfKzR+kTn3CMtt580s2PAXmB2wy1fB+dc0NNX0BeRhIoS9PcBT7TcPwpcttYXMrNLgRzwrbU+N4rZcoXr/+ALPfdpOEe94ZTTF5HEihL0O41tdGt5ETM7C/gz4I3OuUaHx28GbgY4cODAWg7dlEoZF5w5tup+z3/mbn7k4Jnreg0RkUEXJegfBc5uub8feDLqC5jZLuCTwK855+7utI9z7hBwCGB6enpNPyjeruEs/++nX7Kep4qIJEaU0Tv3ABeY2XlmlgNuAD4e5eDh/h8DPuic+/D6mykiIv2watB3ztWAtwCfBh4EbnfOHTazd5rZNQBmdomZHQWuB95nZofDp78euBy4ycy+Gv550ab8S0REZFXm3LqyKZtmenra3XvvvdvdDBGRgWJm9znnplfbL3EzckVEkkxBX0QkQRT0RUQSREFfRCRBFPRFRBIkdqN3zOxp4DtrfNoe4PgmNGcj4tgmULvWIo5tArVrreLYrs1o0znOub2r7RS7oL8eZnZvlKFKWymObQK1ay3i2CZQu9Yqju3azjYpvSMikiAK+iIiCbJTgv6h7W5AB3FsE6hdaxHHNoHatVZxbNe2tWlH5PRFRCSandLTFxGRCAY66K+2YPsmv/b7zeyYmX2jZdukmd1pZt8M/y6E283M3hu2834ze/EmtelsM7vLzB4MF6P/xZi0a9jMvmRmXwvb9Y5w+3lm9sWwXX8VluLGzIbC+0fCx8/djHa1tC9tZl8xs0/EpV1m9piZfT2sTHtvuG2738cJM/uImT0UfsZeFoM2Paelgu9XzeyUmf3SdrcrfK1fDj/v3zCzvwy/B9v+2cI5N5B/gDTB0ovnEyzD+DXg4Ba+/uXAi4FvtGx7N3BLePsW4H+Ht18HfIpgFbKXAl/cpDadBbw4vD0OPEKwmP12t8uAsfB2Fvhi+Hq3AzeE2/8A+M/h7TcDfxDevgH4q01+L38F+BDwifD+trcLeAzY07Ztu9/HPwV+LrydAya2u01t7UsDTwHnbHe7CJaZ/TYw0vKZuikWn63NfiM28Q1+GfDplvtvBd66xW04l+VB/2HgrPD2WcDD4e33ATd22m+T2/e3wI/EqV1AHvgywTrLx4FM+/tJsHbDy8LbmXA/26T27Ac+A/wQ8IkwGMShXY+xMuhv2/sI7AqDmMWlTR3aeCXwb3FoF0tri0+Gn5VPAK+Nw2drkNM7nRZs37dNbfHOdM59DyD8+4xw+5a3NTw9vJigV73t7QpTKF8FjgF3EpylzbpgkZ721262K3z8JDC1Ge0C3gP8KuDXbp6KSbsc8A9mdp8Fa0jD9r6P5wNPA38SpsL+yMxGt7lN7W4A/jK8va3tcs59F/gd4HHgewSflfuIwWdrkIP+hhds30Jb2lYzGwP+Gvgl59ypXrt22LYp7XLO1Z1zLyLoWV8KPK/Ha29Ju8zsx4Bjzrn7Wjdvd7tCr3DOvRi4GvgvZnZ5j323ol0ZgnTm7zvnLgZKBGmT7WzT0osFufFrgNWWZd2qz1YBuBY4D3gmMErwXnZ77S37/xrkoL+hBds3yffN7CyA8O9j4fYta6uZZQkC/l845z4al3Z5zrlZ4J8J8qkTZpbp8NrNdoWP7wZmNqE5rwCuMbPHgNsIUjzviUG7cM49Gf59jGCd6UvZ3vfxKHDUOffF8P5HCH4E4vLZuhr4snPu++H97W7Xa4BvO+eeds5VgY8CLycGn61BDvrrXrB9E30ceGN4+40EOXW//Q3hyIGXAif9qWc/mZkBfww86Jz73Ri1a6+ZTYS3Rwi+EA8CdwHXdWmXb+91wD+5MNnZT865tzrn9jvnziX4/PyTc+6nt7tdZjZqZuP+NkGu+hts4/vonHsKeMLMnhNu+mHgge1sU5sbWUrt+NffznY9DrzUzPLh99L/f23rZwsY3Au54f/H6whGqHwLeNsWv/ZfEuTqqgS/0j9LkIP7DPDN8O/JcF8Dbg3b+XVgepPa9EqCU8L7ga+Gf14Xg3ZdBHwlbNc3gLeH288HvgQcITgtHwq3D4f3j4SPn78F7+erWRq9s63tCl//a+Gfw/6zHYP38UXAveH7+DdAYbvbFL5WHjgB7G7ZFod2vQN4KPzM/xkwtN2fLeecZuSKiCTJIKd3RERkjRT0RUQSREFfRCRBFPRFRBJEQV9EJEEU9EVEEkRBX0QkQRT0RUQS5P8DSCHf9L9kWgwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(times[1:],acc_callback.testaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = ResnetBuilder.build_resnet_18((1000,1,22), 4)\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "time_callback = TimeHistory()\n",
    "acc_callback = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 50 samples\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - 15s 63ms/step - loss: 2.3887 - acc: 0.2395 - val_loss: 3.7686 - val_acc: 0.3000\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 1.4835 - acc: 0.6681 - val_loss: 3.2511 - val_acc: 0.3000\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.7986 - acc: 0.8950 - val_loss: 3.2865 - val_acc: 0.2200\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.5938 - acc: 0.9496 - val_loss: 3.2910 - val_acc: 0.2600\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.4350 - acc: 0.9832 - val_loss: 3.0832 - val_acc: 0.3000\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3968 - acc: 0.9832 - val_loss: 3.1551 - val_acc: 0.2000\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.3297 - acc: 1.0000 - val_loss: 3.3896 - val_acc: 0.2000\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3104 - acc: 1.0000 - val_loss: 3.5851 - val_acc: 0.2200\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3014 - acc: 1.0000 - val_loss: 3.6782 - val_acc: 0.2400\n",
      "Epoch 10/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3009 - acc: 1.0000 - val_loss: 3.7273 - val_acc: 0.2200\n",
      "Epoch 11/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3052 - acc: 0.9916 - val_loss: 3.7778 - val_acc: 0.2400\n",
      "Epoch 12/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3171 - acc: 0.9916 - val_loss: 3.9586 - val_acc: 0.2600\n",
      "Epoch 13/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3382 - acc: 0.9874 - val_loss: 3.9707 - val_acc: 0.2400\n",
      "Epoch 14/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3331 - acc: 0.9874 - val_loss: 4.3211 - val_acc: 0.2000\n",
      "Epoch 15/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.3460 - acc: 0.9748 - val_loss: 4.1953 - val_acc: 0.3000\n",
      "Epoch 16/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.3607 - acc: 0.9748 - val_loss: 4.3779 - val_acc: 0.3000\n",
      "Epoch 17/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3958 - acc: 0.9496 - val_loss: 4.3983 - val_acc: 0.2800\n",
      "Epoch 18/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.4807 - acc: 0.9202 - val_loss: 4.4223 - val_acc: 0.2600\n",
      "Epoch 19/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.3975 - acc: 0.9580 - val_loss: 4.1401 - val_acc: 0.3000\n",
      "Epoch 20/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3862 - acc: 0.9664 - val_loss: 4.0472 - val_acc: 0.2600\n",
      "Epoch 21/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.4379 - acc: 0.9328 - val_loss: 3.8242 - val_acc: 0.3200\n",
      "Epoch 22/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3879 - acc: 0.9748 - val_loss: 4.7268 - val_acc: 0.3200\n",
      "Epoch 23/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3836 - acc: 0.9706 - val_loss: 5.1156 - val_acc: 0.2800\n",
      "Epoch 24/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.4166 - acc: 0.9538 - val_loss: 5.1133 - val_acc: 0.2800\n",
      "Epoch 25/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3199 - acc: 0.9832 - val_loss: 5.5234 - val_acc: 0.3000\n",
      "Epoch 26/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3058 - acc: 0.9958 - val_loss: 5.6149 - val_acc: 0.3200\n",
      "Epoch 27/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.3022 - acc: 0.9958 - val_loss: 5.3560 - val_acc: 0.3200\n",
      "Epoch 28/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2950 - acc: 0.9958 - val_loss: 5.1544 - val_acc: 0.3200\n",
      "Epoch 29/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.3162 - acc: 0.9832 - val_loss: 5.0830 - val_acc: 0.3000\n",
      "Epoch 30/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2918 - acc: 1.0000 - val_loss: 5.1585 - val_acc: 0.3200\n",
      "Epoch 31/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2940 - acc: 0.9958 - val_loss: 5.2812 - val_acc: 0.2800\n",
      "Epoch 32/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2915 - acc: 0.9958 - val_loss: 5.4901 - val_acc: 0.2000\n",
      "Epoch 33/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2920 - acc: 0.9916 - val_loss: 5.3749 - val_acc: 0.2600\n",
      "Epoch 34/100\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2804 - acc: 1.0000 - val_loss: 5.1766 - val_acc: 0.2800\n",
      "Epoch 35/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2856 - acc: 0.9958 - val_loss: 4.9564 - val_acc: 0.2600\n",
      "Epoch 36/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2766 - acc: 1.0000 - val_loss: 4.7888 - val_acc: 0.3200\n",
      "Epoch 37/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3064 - acc: 0.9874 - val_loss: 4.9876 - val_acc: 0.3000\n",
      "Epoch 38/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3023 - acc: 0.9916 - val_loss: 5.2616 - val_acc: 0.2600\n",
      "Epoch 39/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2990 - acc: 0.9874 - val_loss: 5.2752 - val_acc: 0.3200\n",
      "Epoch 40/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2972 - acc: 0.9874 - val_loss: 5.3834 - val_acc: 0.3000\n",
      "Epoch 41/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.4025 - acc: 0.9748 - val_loss: 5.5810 - val_acc: 0.2200\n",
      "Epoch 42/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.4028 - acc: 0.9706 - val_loss: 5.2704 - val_acc: 0.2000\n",
      "Epoch 43/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3627 - acc: 0.9664 - val_loss: 5.0313 - val_acc: 0.2200\n",
      "Epoch 44/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.4402 - acc: 0.9580 - val_loss: 5.1290 - val_acc: 0.1800\n",
      "Epoch 45/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3598 - acc: 0.9664 - val_loss: 4.7602 - val_acc: 0.2200\n",
      "Epoch 46/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.3468 - acc: 0.9748 - val_loss: 4.8219 - val_acc: 0.2000\n",
      "Epoch 47/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2946 - acc: 0.9958 - val_loss: 5.0358 - val_acc: 0.2000\n",
      "Epoch 48/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2839 - acc: 1.0000 - val_loss: 5.1076 - val_acc: 0.2200\n",
      "Epoch 49/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3044 - acc: 0.9874 - val_loss: 4.8719 - val_acc: 0.2000\n",
      "Epoch 50/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2761 - acc: 0.9958 - val_loss: 4.6717 - val_acc: 0.2200\n",
      "Epoch 51/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2884 - acc: 0.9916 - val_loss: 4.6175 - val_acc: 0.2200\n",
      "Epoch 52/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3198 - acc: 0.9832 - val_loss: 4.9866 - val_acc: 0.1800\n",
      "Epoch 53/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3147 - acc: 0.9790 - val_loss: 5.3843 - val_acc: 0.2200\n",
      "Epoch 54/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2992 - acc: 0.9874 - val_loss: 5.5843 - val_acc: 0.2200\n",
      "Epoch 55/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3530 - acc: 0.9832 - val_loss: 5.2731 - val_acc: 0.2600\n",
      "Epoch 56/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3035 - acc: 0.9832 - val_loss: 4.9936 - val_acc: 0.2800\n",
      "Epoch 57/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2972 - acc: 0.9874 - val_loss: 4.9247 - val_acc: 0.2000\n",
      "Epoch 58/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2774 - acc: 0.9958 - val_loss: 4.8853 - val_acc: 0.2400\n",
      "Epoch 59/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2761 - acc: 0.9916 - val_loss: 4.8148 - val_acc: 0.2000\n",
      "Epoch 60/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2628 - acc: 0.9958 - val_loss: 4.8179 - val_acc: 0.2200\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2778 - acc: 0.9916 - val_loss: 4.7380 - val_acc: 0.2200\n",
      "Epoch 62/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2642 - acc: 1.0000 - val_loss: 4.7422 - val_acc: 0.2400\n",
      "Epoch 63/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2593 - acc: 1.0000 - val_loss: 4.7980 - val_acc: 0.2400\n",
      "Epoch 64/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2574 - acc: 1.0000 - val_loss: 4.8955 - val_acc: 0.2400\n",
      "Epoch 65/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3013 - acc: 0.9874 - val_loss: 4.9485 - val_acc: 0.2200\n",
      "Epoch 66/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3168 - acc: 0.9790 - val_loss: 5.3086 - val_acc: 0.2400\n",
      "Epoch 67/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.4321 - acc: 0.9328 - val_loss: 5.3808 - val_acc: 0.2200\n",
      "Epoch 68/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3178 - acc: 0.9790 - val_loss: 5.7975 - val_acc: 0.1400\n",
      "Epoch 69/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3231 - acc: 0.9664 - val_loss: 5.8013 - val_acc: 0.2000\n",
      "Epoch 70/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.3218 - acc: 0.9832 - val_loss: 5.8070 - val_acc: 0.2400\n",
      "Epoch 71/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3058 - acc: 0.9916 - val_loss: 6.0771 - val_acc: 0.2200\n",
      "Epoch 72/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2606 - acc: 0.9958 - val_loss: 5.6991 - val_acc: 0.2000\n",
      "Epoch 73/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2613 - acc: 0.9958 - val_loss: 5.8393 - val_acc: 0.2200\n",
      "Epoch 74/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3281 - acc: 0.9748 - val_loss: 5.1908 - val_acc: 0.2400\n",
      "Epoch 75/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2726 - acc: 0.9916 - val_loss: 4.8963 - val_acc: 0.2600\n",
      "Epoch 76/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2908 - acc: 0.9832 - val_loss: 4.9302 - val_acc: 0.3000\n",
      "Epoch 77/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2511 - acc: 1.0000 - val_loss: 4.9095 - val_acc: 0.3000\n",
      "Epoch 78/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2508 - acc: 1.0000 - val_loss: 4.8256 - val_acc: 0.2800\n",
      "Epoch 79/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2447 - acc: 1.0000 - val_loss: 4.7510 - val_acc: 0.2400\n",
      "Epoch 80/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2510 - acc: 0.9958 - val_loss: 4.7306 - val_acc: 0.2200\n",
      "Epoch 81/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2466 - acc: 0.9958 - val_loss: 4.7345 - val_acc: 0.2200\n",
      "Epoch 82/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2444 - acc: 1.0000 - val_loss: 4.9272 - val_acc: 0.2200\n",
      "Epoch 83/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2435 - acc: 1.0000 - val_loss: 5.0314 - val_acc: 0.2200\n",
      "Epoch 84/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2535 - acc: 0.9958 - val_loss: 4.9990 - val_acc: 0.2200\n",
      "Epoch 85/100\n",
      "238/238 [==============================] - 9s 37ms/step - loss: 0.2581 - acc: 0.9916 - val_loss: 4.8948 - val_acc: 0.2000\n",
      "Epoch 86/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2379 - acc: 1.0000 - val_loss: 4.7423 - val_acc: 0.2000\n",
      "Epoch 87/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2727 - acc: 0.9790 - val_loss: 4.7725 - val_acc: 0.2400\n",
      "Epoch 88/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2484 - acc: 0.9958 - val_loss: 4.8639 - val_acc: 0.2200\n",
      "Epoch 89/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2405 - acc: 0.9958 - val_loss: 4.7480 - val_acc: 0.2000\n",
      "Epoch 90/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2452 - acc: 0.9916 - val_loss: 4.6093 - val_acc: 0.2000\n",
      "Epoch 91/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.2387 - acc: 1.0000 - val_loss: 4.5930 - val_acc: 0.2000\n",
      "Epoch 92/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2610 - acc: 0.9874 - val_loss: 4.8184 - val_acc: 0.2000\n",
      "Epoch 93/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2354 - acc: 0.9958 - val_loss: 4.9198 - val_acc: 0.2000\n",
      "Epoch 94/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.2304 - acc: 1.0000 - val_loss: 4.8577 - val_acc: 0.2600\n",
      "Epoch 95/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.2571 - acc: 0.9916 - val_loss: 4.8524 - val_acc: 0.2800\n",
      "Epoch 96/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2564 - acc: 0.9958 - val_loss: 4.8163 - val_acc: 0.2400\n",
      "Epoch 97/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2783 - acc: 0.9790 - val_loss: 4.8766 - val_acc: 0.2400\n",
      "Epoch 98/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2699 - acc: 0.9790 - val_loss: 4.6467 - val_acc: 0.2400\n",
      "Epoch 99/100\n",
      "238/238 [==============================] - 8s 35ms/step - loss: 0.2953 - acc: 0.9790 - val_loss: 5.0361 - val_acc: 0.2400\n",
      "Epoch 100/100\n",
      "238/238 [==============================] - 9s 36ms/step - loss: 0.2398 - acc: 0.9916 - val_loss: 5.5848 - val_acc: 0.2400\n",
      "50/50 [==============================] - 0s 5ms/step\n",
      "\n",
      "Testing loss: 6.43531753540039, acc: 0.4000000023841858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2.fit(x2_train_add, y2_train_onehot,\n",
    "              batch_size=32,\n",
    "              epochs=100,shuffle=True,\n",
    "          callbacks=[time_callback,acc_callback],\n",
    "         validation_data=(x2_test_add, y2_test_onehot),verbose=1)\n",
    "times = time_callback.times\n",
    "loss,acc=model.evaluate(x2_test_add, y2_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d226548a20>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(times[1:],acc_callback.testaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 1000, 22, 64)      640       \n",
      "=================================================================\n",
      "Total params: 640\n",
      "Trainable params: 640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subject 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 238 samples, validate on 50 samples\n",
      "Epoch 1/100\n",
      "238/238 [==============================] - 35s 148ms/step - loss: 2.4949 - acc: 0.2941 - val_loss: 3.5059 - val_acc: 0.2400\n",
      "Epoch 2/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 1.4520 - acc: 0.6303 - val_loss: 3.4618 - val_acc: 0.3000\n",
      "Epoch 3/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.8912 - acc: 0.8613 - val_loss: 3.3949 - val_acc: 0.2000\n",
      "Epoch 4/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.5179 - acc: 0.9664 - val_loss: 3.4300 - val_acc: 0.2400\n",
      "Epoch 5/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.4016 - acc: 0.9916 - val_loss: 3.4987 - val_acc: 0.2400\n",
      "Epoch 6/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3460 - acc: 1.0000 - val_loss: 3.6248 - val_acc: 0.2200\n",
      "Epoch 7/100\n",
      "238/238 [==============================] - 10s 43ms/step - loss: 0.3254 - acc: 1.0000 - val_loss: 3.6983 - val_acc: 0.2200\n",
      "Epoch 8/100\n",
      "238/238 [==============================] - 11s 45ms/step - loss: 0.3113 - acc: 1.0000 - val_loss: 3.6117 - val_acc: 0.1800\n",
      "Epoch 9/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.3030 - acc: 1.0000 - val_loss: 3.5245 - val_acc: 0.2400\n",
      "Epoch 10/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2952 - acc: 1.0000 - val_loss: 3.4997 - val_acc: 0.2600\n",
      "Epoch 11/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2931 - acc: 1.0000 - val_loss: 3.5956 - val_acc: 0.2200\n",
      "Epoch 12/100\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.2919 - acc: 1.0000 - val_loss: 3.6307 - val_acc: 0.2000\n",
      "Epoch 13/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2858 - acc: 1.0000 - val_loss: 3.6120 - val_acc: 0.1800\n",
      "Epoch 14/100\n",
      "238/238 [==============================] - 10s 43ms/step - loss: 0.2896 - acc: 0.9958 - val_loss: 3.6556 - val_acc: 0.1800\n",
      "Epoch 15/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2874 - acc: 1.0000 - val_loss: 3.7998 - val_acc: 0.2200\n",
      "Epoch 16/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.3117 - acc: 0.9832 - val_loss: 3.3701 - val_acc: 0.2600\n",
      "Epoch 17/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.3339 - acc: 0.9874 - val_loss: 3.7297 - val_acc: 0.2800\n",
      "Epoch 18/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.3776 - acc: 0.9664 - val_loss: 4.3510 - val_acc: 0.2000\n",
      "Epoch 19/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3532 - acc: 0.9664 - val_loss: 4.8089 - val_acc: 0.2200\n",
      "Epoch 20/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3508 - acc: 0.9706 - val_loss: 4.7710 - val_acc: 0.2400\n",
      "Epoch 21/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.4274 - acc: 0.9622 - val_loss: 4.6552 - val_acc: 0.2400\n",
      "Epoch 22/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.3660 - acc: 0.9832 - val_loss: 5.4644 - val_acc: 0.2000\n",
      "Epoch 23/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3491 - acc: 0.9664 - val_loss: 5.5890 - val_acc: 0.2000\n",
      "Epoch 24/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3695 - acc: 0.9706 - val_loss: 5.5121 - val_acc: 0.2000\n",
      "Epoch 25/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3640 - acc: 0.9706 - val_loss: 5.2708 - val_acc: 0.2400\n",
      "Epoch 26/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3214 - acc: 0.9790 - val_loss: 4.7914 - val_acc: 0.2400\n",
      "Epoch 27/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3941 - acc: 0.9580 - val_loss: 4.6850 - val_acc: 0.2600\n",
      "Epoch 28/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3127 - acc: 0.9916 - val_loss: 4.9474 - val_acc: 0.3000\n",
      "Epoch 29/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3120 - acc: 0.9874 - val_loss: 5.2348 - val_acc: 0.3000\n",
      "Epoch 30/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3078 - acc: 0.9874 - val_loss: 5.5265 - val_acc: 0.2200\n",
      "Epoch 31/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3150 - acc: 0.9790 - val_loss: 5.3667 - val_acc: 0.2400\n",
      "Epoch 32/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3026 - acc: 0.9874 - val_loss: 5.3249 - val_acc: 0.2200\n",
      "Epoch 33/100\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2910 - acc: 0.9958 - val_loss: 5.1843 - val_acc: 0.2200\n",
      "Epoch 34/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2772 - acc: 1.0000 - val_loss: 4.9257 - val_acc: 0.2200\n",
      "Epoch 35/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2820 - acc: 0.9916 - val_loss: 4.8116 - val_acc: 0.2400\n",
      "Epoch 36/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.3129 - acc: 0.9874 - val_loss: 4.9006 - val_acc: 0.2600\n",
      "Epoch 37/100\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.3003 - acc: 0.9874 - val_loss: 4.9313 - val_acc: 0.2600\n",
      "Epoch 38/100\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2979 - acc: 0.9832 - val_loss: 5.4541 - val_acc: 0.2000\n",
      "Epoch 39/100\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.2987 - acc: 0.9832 - val_loss: 5.7649 - val_acc: 0.2200\n",
      "Epoch 40/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.3057 - acc: 0.9916 - val_loss: 5.8940 - val_acc: 0.2000\n",
      "Epoch 41/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3076 - acc: 0.9916 - val_loss: 6.0325 - val_acc: 0.1800\n",
      "Epoch 42/100\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2947 - acc: 0.9958 - val_loss: 5.7475 - val_acc: 0.2000\n",
      "Epoch 43/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2979 - acc: 0.9832 - val_loss: 5.5592 - val_acc: 0.2000\n",
      "Epoch 44/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.3028 - acc: 0.9832 - val_loss: 6.1388 - val_acc: 0.2000\n",
      "Epoch 45/100\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.3652 - acc: 0.9790 - val_loss: 5.6734 - val_acc: 0.2600\n",
      "Epoch 46/100\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.3241 - acc: 0.9748 - val_loss: 5.6210 - val_acc: 0.2400\n",
      "Epoch 47/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.3876 - acc: 0.9580 - val_loss: 5.9213 - val_acc: 0.1800\n",
      "Epoch 48/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.3972 - acc: 0.9664 - val_loss: 5.7367 - val_acc: 0.1800\n",
      "Epoch 49/100\n",
      "238/238 [==============================] - 10s 44ms/step - loss: 0.3770 - acc: 0.9580 - val_loss: 6.0082 - val_acc: 0.2600\n",
      "Epoch 50/100\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.3631 - acc: 0.9706 - val_loss: 6.2833 - val_acc: 0.2800\n",
      "Epoch 51/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3625 - acc: 0.9622 - val_loss: 6.4435 - val_acc: 0.2800\n",
      "Epoch 52/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.3044 - acc: 0.9832 - val_loss: 6.0887 - val_acc: 0.2000\n",
      "Epoch 53/100\n",
      "238/238 [==============================] - 9s 38ms/step - loss: 0.3444 - acc: 0.9706 - val_loss: 5.7618 - val_acc: 0.2000\n",
      "Epoch 54/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.3478 - acc: 0.9664 - val_loss: 5.6548 - val_acc: 0.2400\n",
      "Epoch 55/100\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.2829 - acc: 0.9874 - val_loss: 5.5609 - val_acc: 0.2000\n",
      "Epoch 56/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2860 - acc: 0.9958 - val_loss: 5.4381 - val_acc: 0.2200\n",
      "Epoch 57/100\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.2741 - acc: 0.9958 - val_loss: 5.4028 - val_acc: 0.3000\n",
      "Epoch 58/100\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.2953 - acc: 0.9916 - val_loss: 5.1944 - val_acc: 0.2800\n",
      "Epoch 59/100\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2899 - acc: 0.9874 - val_loss: 5.2698 - val_acc: 0.2800\n",
      "Epoch 60/100\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.3060 - acc: 0.9832 - val_loss: 5.0651 - val_acc: 0.2800\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2624 - acc: 1.0000 - val_loss: 5.0558 - val_acc: 0.3400\n",
      "Epoch 62/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2656 - acc: 0.9916 - val_loss: 4.9494 - val_acc: 0.3400\n",
      "Epoch 63/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2906 - acc: 0.9874 - val_loss: 4.9729 - val_acc: 0.3200\n",
      "Epoch 64/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2631 - acc: 0.9958 - val_loss: 5.0854 - val_acc: 0.2600\n",
      "Epoch 65/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2707 - acc: 0.9958 - val_loss: 5.0494 - val_acc: 0.2600\n",
      "Epoch 66/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2500 - acc: 1.0000 - val_loss: 5.0502 - val_acc: 0.2600\n",
      "Epoch 67/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2662 - acc: 0.9916 - val_loss: 4.9762 - val_acc: 0.2600\n",
      "Epoch 68/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2464 - acc: 1.0000 - val_loss: 4.9158 - val_acc: 0.2400\n",
      "Epoch 69/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2449 - acc: 1.0000 - val_loss: 4.8488 - val_acc: 0.2400\n",
      "Epoch 70/100\n",
      "238/238 [==============================] - 11s 47ms/step - loss: 0.2625 - acc: 0.9958 - val_loss: 4.7768 - val_acc: 0.2400\n",
      "Epoch 71/100\n",
      "238/238 [==============================] - 10s 44ms/step - loss: 0.2655 - acc: 0.9958 - val_loss: 4.7476 - val_acc: 0.2200\n",
      "Epoch 72/100\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2658 - acc: 0.9874 - val_loss: 4.7212 - val_acc: 0.2400\n",
      "Epoch 73/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2811 - acc: 0.9874 - val_loss: 4.8960 - val_acc: 0.2800\n",
      "Epoch 74/100\n",
      "238/238 [==============================] - 11s 44ms/step - loss: 0.2474 - acc: 1.0000 - val_loss: 4.9650 - val_acc: 0.2800\n",
      "Epoch 75/100\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.2881 - acc: 0.9916 - val_loss: 4.9227 - val_acc: 0.2400\n",
      "Epoch 76/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2619 - acc: 0.9916 - val_loss: 4.8110 - val_acc: 0.2400\n",
      "Epoch 77/100\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2433 - acc: 1.0000 - val_loss: 4.8035 - val_acc: 0.2400\n",
      "Epoch 78/100\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.2407 - acc: 0.9958 - val_loss: 4.7662 - val_acc: 0.2400\n",
      "Epoch 79/100\n",
      "238/238 [==============================] - 10s 43ms/step - loss: 0.2423 - acc: 0.9958 - val_loss: 4.6958 - val_acc: 0.2200\n",
      "Epoch 80/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2397 - acc: 0.9958 - val_loss: 4.5364 - val_acc: 0.2400\n",
      "Epoch 81/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2582 - acc: 0.9916 - val_loss: 4.5748 - val_acc: 0.2200\n",
      "Epoch 82/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2437 - acc: 0.9958 - val_loss: 4.5164 - val_acc: 0.2400\n",
      "Epoch 83/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2351 - acc: 1.0000 - val_loss: 4.4775 - val_acc: 0.2400\n",
      "Epoch 84/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2415 - acc: 0.9958 - val_loss: 4.3920 - val_acc: 0.2600\n",
      "Epoch 85/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2329 - acc: 1.0000 - val_loss: 4.3823 - val_acc: 0.2200\n",
      "Epoch 86/100\n",
      "238/238 [==============================] - 10s 44ms/step - loss: 0.2370 - acc: 0.9916 - val_loss: 4.3626 - val_acc: 0.2000\n",
      "Epoch 87/100\n",
      "238/238 [==============================] - 10s 42ms/step - loss: 0.2288 - acc: 1.0000 - val_loss: 4.2724 - val_acc: 0.2000\n",
      "Epoch 88/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2380 - acc: 0.9958 - val_loss: 4.2706 - val_acc: 0.1800\n",
      "Epoch 89/100\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2250 - acc: 1.0000 - val_loss: 4.3271 - val_acc: 0.1800\n",
      "Epoch 90/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2238 - acc: 1.0000 - val_loss: 4.3369 - val_acc: 0.1800\n",
      "Epoch 91/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2227 - acc: 1.0000 - val_loss: 4.3035 - val_acc: 0.1800\n",
      "Epoch 92/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2292 - acc: 0.9958 - val_loss: 4.2887 - val_acc: 0.1800\n",
      "Epoch 93/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2589 - acc: 0.9916 - val_loss: 4.3835 - val_acc: 0.1800\n",
      "Epoch 94/100\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2682 - acc: 0.9874 - val_loss: 4.9712 - val_acc: 0.1600\n",
      "Epoch 95/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.3389 - acc: 0.9706 - val_loss: 5.1606 - val_acc: 0.1200\n",
      "Epoch 96/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2900 - acc: 0.9832 - val_loss: 5.3292 - val_acc: 0.1600\n",
      "Epoch 97/100\n",
      "238/238 [==============================] - 10s 40ms/step - loss: 0.2460 - acc: 0.9958 - val_loss: 5.2887 - val_acc: 0.1800\n",
      "Epoch 98/100\n",
      "238/238 [==============================] - 10s 41ms/step - loss: 0.2878 - acc: 0.9790 - val_loss: 5.3893 - val_acc: 0.1800\n",
      "Epoch 99/100\n",
      "238/238 [==============================] - 9s 39ms/step - loss: 0.2349 - acc: 0.9958 - val_loss: 5.3973 - val_acc: 0.1400\n",
      "Epoch 100/100\n",
      "238/238 [==============================] - 9s 40ms/step - loss: 0.2390 - acc: 0.9916 - val_loss: 5.2130 - val_acc: 0.1200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_44_input to have shape (1000, 22, 1) but got array with shape (1, 22, 1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-01d552460ae3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m          validation_data=(x3_test_add, y3_test_onehot),verbose=1)\n\u001b[0;32m     12\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3_test_add\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my3_test_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nTesting loss: {}, acc: {}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtestaccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1002\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m                                    \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                    steps=steps)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1766\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1769\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `_test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_44_input to have shape (1000, 22, 1) but got array with shape (1, 22, 1000)"
     ]
    }
   ],
   "source": [
    "model4 = ResnetBuilder.build_resnet_18((1000,1,22), 4)\n",
    "model4.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "time_callback = TimeHistory()\n",
    "acc_callback = AccuracyHistory()\n",
    "model4.fit(x3_train_add, y3_train_onehot,\n",
    "              batch_size=32,\n",
    "              epochs=100,shuffle=True,\n",
    "          callbacks=[time_callback,acc_callback],\n",
    "         validation_data=(x3_test_add, y3_test_onehot),verbose=1)\n",
    "times = time_callback.times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 4ms/step\n",
      "\n",
      "Testing loss: 5.212983570098877, acc: 0.12000000014901162\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d593ce6e48>]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss,acc=model4.evaluate(x3_test_add, y3_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "plt.plot(times[1:],acc_callback.testaccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = ResnetBuilder.build_resnet_18((1000,1,22), 4)\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "time_callback = TimeHistory()\n",
    "acc_callback = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2142 samples, validate on 638 samples\n",
      "Epoch 1/100\n",
      "2142/2142 [==============================] - 76s 35ms/step - loss: 1.8656 - acc: 0.3025 - val_loss: 2.4264 - val_acc: 0.3495\n",
      "Epoch 2/100\n",
      "2142/2142 [==============================] - 75s 35ms/step - loss: 1.5135 - acc: 0.4650 - val_loss: 1.6865 - val_acc: 0.4404\n",
      "Epoch 3/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 1.3066 - acc: 0.5747 - val_loss: 1.8232 - val_acc: 0.4451\n",
      "Epoch 4/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 1.0914 - acc: 0.6793 - val_loss: 1.8161 - val_acc: 0.4937\n",
      "Epoch 5/100\n",
      "2142/2142 [==============================] - 81s 38ms/step - loss: 0.9394 - acc: 0.7432 - val_loss: 1.7667 - val_acc: 0.5361\n",
      "Epoch 6/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.7660 - acc: 0.8165 - val_loss: 2.0966 - val_acc: 0.5580\n",
      "Epoch 7/100\n",
      "2142/2142 [==============================] - 81s 38ms/step - loss: 0.6306 - acc: 0.8730 - val_loss: 1.9482 - val_acc: 0.5768\n",
      "Epoch 8/100\n",
      "2142/2142 [==============================] - 82s 38ms/step - loss: 0.5890 - acc: 0.8838 - val_loss: 2.1443 - val_acc: 0.5564\n",
      "Epoch 9/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.5115 - acc: 0.9150 - val_loss: 2.1748 - val_acc: 0.6034\n",
      "Epoch 10/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.4815 - acc: 0.9234 - val_loss: 2.3198 - val_acc: 0.5878\n",
      "Epoch 11/100\n",
      "2142/2142 [==============================] - 76s 36ms/step - loss: 0.4432 - acc: 0.9360 - val_loss: 2.3074 - val_acc: 0.5893\n",
      "Epoch 12/100\n",
      "2142/2142 [==============================] - 76s 36ms/step - loss: 0.4259 - acc: 0.9412 - val_loss: 2.2321 - val_acc: 0.5878\n",
      "Epoch 13/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.4355 - acc: 0.9407 - val_loss: 2.0556 - val_acc: 0.5815\n",
      "Epoch 14/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.3642 - acc: 0.9603 - val_loss: 2.4030 - val_acc: 0.5846\n",
      "Epoch 15/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.3912 - acc: 0.9538 - val_loss: 2.2560 - val_acc: 0.5831\n",
      "Epoch 16/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.3403 - acc: 0.9692 - val_loss: 2.2614 - val_acc: 0.5784\n",
      "Epoch 17/100\n",
      "2142/2142 [==============================] - 76s 35ms/step - loss: 0.3128 - acc: 0.9757 - val_loss: 2.1982 - val_acc: 0.6019\n",
      "Epoch 18/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.3103 - acc: 0.9743 - val_loss: 2.3135 - val_acc: 0.5893\n",
      "Epoch 19/100\n",
      "2142/2142 [==============================] - 81s 38ms/step - loss: 0.3380 - acc: 0.9636 - val_loss: 2.4124 - val_acc: 0.5940\n",
      "Epoch 20/100\n",
      "2142/2142 [==============================] - 76s 36ms/step - loss: 0.3444 - acc: 0.9608 - val_loss: 2.3056 - val_acc: 0.6097\n",
      "Epoch 21/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.3352 - acc: 0.9659 - val_loss: 2.2429 - val_acc: 0.6003\n",
      "Epoch 22/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2931 - acc: 0.9790 - val_loss: 2.1750 - val_acc: 0.6019\n",
      "Epoch 23/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.2623 - acc: 0.9827 - val_loss: 2.2852 - val_acc: 0.6034\n",
      "Epoch 24/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2700 - acc: 0.9809 - val_loss: 2.2089 - val_acc: 0.6176\n",
      "Epoch 25/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.3019 - acc: 0.9692 - val_loss: 2.2637 - val_acc: 0.6176\n",
      "Epoch 26/100\n",
      "2142/2142 [==============================] - 81s 38ms/step - loss: 0.3060 - acc: 0.9697 - val_loss: 2.5157 - val_acc: 0.6003\n",
      "Epoch 27/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.2963 - acc: 0.9701 - val_loss: 2.4142 - val_acc: 0.6050\n",
      "Epoch 28/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.2797 - acc: 0.9715 - val_loss: 2.4062 - val_acc: 0.6003\n",
      "Epoch 29/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.3015 - acc: 0.9692 - val_loss: 2.3514 - val_acc: 0.5956\n",
      "Epoch 30/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.2572 - acc: 0.9823 - val_loss: 2.2183 - val_acc: 0.5987\n",
      "Epoch 31/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2263 - acc: 0.9893 - val_loss: 2.3570 - val_acc: 0.6050\n",
      "Epoch 32/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2331 - acc: 0.9860 - val_loss: 2.3440 - val_acc: 0.5987\n",
      "Epoch 33/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.2577 - acc: 0.9767 - val_loss: 2.3556 - val_acc: 0.6082\n",
      "Epoch 34/100\n",
      "2142/2142 [==============================] - 80s 38ms/step - loss: 0.3111 - acc: 0.9580 - val_loss: 2.5288 - val_acc: 0.5940\n",
      "Epoch 35/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.2673 - acc: 0.9753 - val_loss: 2.1735 - val_acc: 0.6207\n",
      "Epoch 36/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.2486 - acc: 0.9809 - val_loss: 2.2802 - val_acc: 0.6050\n",
      "Epoch 37/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.2295 - acc: 0.9855 - val_loss: 2.2128 - val_acc: 0.6097\n",
      "Epoch 38/100\n",
      "2142/2142 [==============================] - 81s 38ms/step - loss: 0.2110 - acc: 0.9911 - val_loss: 2.4488 - val_acc: 0.6050\n",
      "Epoch 39/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2051 - acc: 0.9902 - val_loss: 2.3934 - val_acc: 0.6144\n",
      "Epoch 40/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.2225 - acc: 0.9832 - val_loss: 2.5139 - val_acc: 0.6066\n",
      "Epoch 41/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2508 - acc: 0.9757 - val_loss: 2.6074 - val_acc: 0.6019\n",
      "Epoch 42/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.2480 - acc: 0.9734 - val_loss: 2.3067 - val_acc: 0.5972\n",
      "Epoch 43/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.2620 - acc: 0.9701 - val_loss: 2.3031 - val_acc: 0.6176\n",
      "Epoch 44/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2302 - acc: 0.9799 - val_loss: 2.2908 - val_acc: 0.6144\n",
      "Epoch 45/100\n",
      "2142/2142 [==============================] - 81s 38ms/step - loss: 0.2225 - acc: 0.9823 - val_loss: 2.4009 - val_acc: 0.5862\n",
      "Epoch 46/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2218 - acc: 0.9855 - val_loss: 2.2741 - val_acc: 0.6003\n",
      "Epoch 47/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.2113 - acc: 0.9818 - val_loss: 2.3739 - val_acc: 0.6019\n",
      "Epoch 48/100\n",
      "2142/2142 [==============================] - 78s 37ms/step - loss: 0.1989 - acc: 0.9907 - val_loss: 2.3175 - val_acc: 0.5925\n",
      "Epoch 49/100\n",
      "2142/2142 [==============================] - 82s 38ms/step - loss: 0.2102 - acc: 0.9823 - val_loss: 2.4243 - val_acc: 0.5972\n",
      "Epoch 50/100\n",
      "2142/2142 [==============================] - 78s 37ms/step - loss: 0.2097 - acc: 0.9823 - val_loss: 2.4429 - val_acc: 0.5956\n",
      "Epoch 51/100\n",
      "2142/2142 [==============================] - 82s 38ms/step - loss: 0.1891 - acc: 0.9893 - val_loss: 2.4236 - val_acc: 0.6113\n",
      "Epoch 52/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.2075 - acc: 0.9841 - val_loss: 2.5535 - val_acc: 0.5956\n",
      "Epoch 53/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2627 - acc: 0.9659 - val_loss: 2.6052 - val_acc: 0.5893\n",
      "Epoch 54/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2546 - acc: 0.9715 - val_loss: 2.4950 - val_acc: 0.5972\n",
      "Epoch 55/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.2132 - acc: 0.9855 - val_loss: 2.1675 - val_acc: 0.6050\n",
      "Epoch 56/100\n",
      "2142/2142 [==============================] - 78s 37ms/step - loss: 0.1970 - acc: 0.9883 - val_loss: 2.2269 - val_acc: 0.6113\n",
      "Epoch 57/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.2047 - acc: 0.9846 - val_loss: 2.2914 - val_acc: 0.6003\n",
      "Epoch 58/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2304 - acc: 0.9790 - val_loss: 2.3777 - val_acc: 0.6113\n",
      "Epoch 59/100\n",
      "2142/2142 [==============================] - 78s 37ms/step - loss: 0.2146 - acc: 0.9855 - val_loss: 2.1476 - val_acc: 0.6191\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2142/2142 [==============================] - 78s 37ms/step - loss: 0.1964 - acc: 0.9916 - val_loss: 2.0822 - val_acc: 0.6223\n",
      "Epoch 61/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.1785 - acc: 0.9935 - val_loss: 2.0840 - val_acc: 0.6332\n",
      "Epoch 62/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.1808 - acc: 0.9930 - val_loss: 2.1101 - val_acc: 0.6191\n",
      "Epoch 63/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.2115 - acc: 0.9827 - val_loss: 2.3740 - val_acc: 0.6160\n",
      "Epoch 64/100\n",
      "2142/2142 [==============================] - 76s 36ms/step - loss: 0.2218 - acc: 0.9762 - val_loss: 2.4305 - val_acc: 0.6254\n",
      "Epoch 65/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.2155 - acc: 0.9841 - val_loss: 2.1581 - val_acc: 0.6254\n",
      "Epoch 66/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.1994 - acc: 0.9874 - val_loss: 1.9471 - val_acc: 0.6270\n",
      "Epoch 67/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.1842 - acc: 0.9916 - val_loss: 2.1131 - val_acc: 0.6285\n",
      "Epoch 68/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.1821 - acc: 0.9930 - val_loss: 2.2411 - val_acc: 0.6285\n",
      "Epoch 69/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.1918 - acc: 0.9921 - val_loss: 2.2636 - val_acc: 0.6176\n",
      "Epoch 70/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.1767 - acc: 0.9935 - val_loss: 2.3709 - val_acc: 0.6160\n",
      "Epoch 71/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.1958 - acc: 0.9879 - val_loss: 2.3153 - val_acc: 0.6097\n",
      "Epoch 72/100\n",
      "2142/2142 [==============================] - 84s 39ms/step - loss: 0.2073 - acc: 0.9855 - val_loss: 2.3521 - val_acc: 0.6066\n",
      "Epoch 73/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.2069 - acc: 0.9855 - val_loss: 2.2913 - val_acc: 0.6082\n",
      "Epoch 74/100\n",
      "2142/2142 [==============================] - 81s 38ms/step - loss: 0.2215 - acc: 0.9790 - val_loss: 2.2559 - val_acc: 0.6223\n",
      "Epoch 75/100\n",
      "2142/2142 [==============================] - 81s 38ms/step - loss: 0.1979 - acc: 0.9888 - val_loss: 2.1928 - val_acc: 0.6113\n",
      "Epoch 76/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2162 - acc: 0.9841 - val_loss: 2.3785 - val_acc: 0.6176\n",
      "Epoch 77/100\n",
      "2142/2142 [==============================] - 76s 36ms/step - loss: 0.2116 - acc: 0.9855 - val_loss: 2.2590 - val_acc: 0.6285\n",
      "Epoch 78/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.2282 - acc: 0.9790 - val_loss: 2.2957 - val_acc: 0.6160\n",
      "Epoch 79/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.2274 - acc: 0.9804 - val_loss: 2.1758 - val_acc: 0.6348\n",
      "Epoch 80/100\n",
      "2142/2142 [==============================] - 81s 38ms/step - loss: 0.2295 - acc: 0.9781 - val_loss: 2.1024 - val_acc: 0.6332\n",
      "Epoch 81/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.2193 - acc: 0.9827 - val_loss: 2.0228 - val_acc: 0.6473\n",
      "Epoch 82/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.2026 - acc: 0.9897 - val_loss: 2.0023 - val_acc: 0.6285\n",
      "Epoch 83/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.1941 - acc: 0.9925 - val_loss: 2.2226 - val_acc: 0.6113\n",
      "Epoch 84/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.1934 - acc: 0.9921 - val_loss: 2.1126 - val_acc: 0.6379\n",
      "Epoch 85/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.1965 - acc: 0.9911 - val_loss: 2.2713 - val_acc: 0.6270\n",
      "Epoch 86/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.2250 - acc: 0.9841 - val_loss: 2.2385 - val_acc: 0.6270\n",
      "Epoch 87/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.2414 - acc: 0.9790 - val_loss: 2.2361 - val_acc: 0.6332\n",
      "Epoch 88/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.1949 - acc: 0.9930 - val_loss: 2.1995 - val_acc: 0.6332\n",
      "Epoch 89/100\n",
      "2142/2142 [==============================] - 78s 37ms/step - loss: 0.2159 - acc: 0.9846 - val_loss: 2.1288 - val_acc: 0.6489\n",
      "Epoch 90/100\n",
      "2142/2142 [==============================] - 76s 36ms/step - loss: 0.2002 - acc: 0.9907 - val_loss: 2.0862 - val_acc: 0.6238\n",
      "Epoch 91/100\n",
      "2142/2142 [==============================] - 79s 37ms/step - loss: 0.1900 - acc: 0.9944 - val_loss: 2.0557 - val_acc: 0.6301\n",
      "Epoch 92/100\n",
      "2142/2142 [==============================] - 80s 37ms/step - loss: 0.1774 - acc: 0.9981 - val_loss: 2.0554 - val_acc: 0.6442\n",
      "Epoch 93/100\n",
      "2142/2142 [==============================] - 78s 36ms/step - loss: 0.1730 - acc: 0.9986 - val_loss: 2.1375 - val_acc: 0.6223\n",
      "Epoch 94/100\n",
      "2142/2142 [==============================] - 77s 36ms/step - loss: 0.1852 - acc: 0.9935 - val_loss: 2.2585 - val_acc: 0.6160\n",
      "Epoch 95/100\n",
      "2142/2142 [==============================] - 76s 35ms/step - loss: 0.1937 - acc: 0.9916 - val_loss: 2.3008 - val_acc: 0.6285\n",
      "Epoch 96/100\n",
      "2142/2142 [==============================] - 76s 35ms/step - loss: 0.2499 - acc: 0.9734 - val_loss: 2.5121 - val_acc: 0.6317\n",
      "Epoch 97/100\n",
      "2142/2142 [==============================] - 76s 35ms/step - loss: 0.2588 - acc: 0.9771 - val_loss: 2.4299 - val_acc: 0.6332\n",
      "Epoch 98/100\n",
      "2142/2142 [==============================] - 81s 38ms/step - loss: 0.2208 - acc: 0.9907 - val_loss: 2.1309 - val_acc: 0.6411\n",
      "Epoch 99/100\n",
      "2142/2142 [==============================] - 81s 38ms/step - loss: 0.2089 - acc: 0.9883 - val_loss: 2.0515 - val_acc: 0.6301\n",
      "Epoch 100/100\n",
      "2142/2142 [==============================] - 81s 38ms/step - loss: 0.2235 - acc: 0.9879 - val_loss: 2.0487 - val_acc: 0.6207\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The model needs to be compiled before being used.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-d7adc5a3019e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m          validation_data=(x_test_add, y_test_onehot),verbose=1)\n\u001b[0;32m      6\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_callback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_add\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nTesting loss: {}, acc: {}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\agnitas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m    996\u001b[0m         \"\"\"\n\u001b[0;32m    997\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m             raise RuntimeError('The model needs to be compiled '\n\u001b[0m\u001b[0;32m    999\u001b[0m                                'before being used.')\n\u001b[0;32m   1000\u001b[0m         return self.model.evaluate(x, y,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The model needs to be compiled before being used."
     ]
    }
   ],
   "source": [
    "model3.fit(x_train_add, y_train_onehot,\n",
    "              batch_size=32,\n",
    "              epochs=100,shuffle=True,\n",
    "          callbacks=[time_callback,acc_callback],\n",
    "         validation_data=(x_test_add, y_test_onehot),verbose=1)\n",
    "times = time_callback.times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 2s 2ms/step\n",
      "\n",
      "Testing loss: 2.048684146337001, acc: 0.6206896553125502\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d1f4f386a0>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss,acc=model3.evaluate(x_test_add, y_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "plt.plot(times[1:],acc_callback.testaccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using overall model to predict subject1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 3ms/step\n",
      "\n",
      "Testing loss: 2.4396323204040526, acc: 0.4999999976158142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss,acc=model3.evaluate(x1_test_add, y1_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 5ms/step\n",
      "\n",
      "Testing loss: 3.130914316177368, acc: 0.3800000011920929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss,acc=model3.evaluate(x2_test_add, y2_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 4ms/step\n",
      "\n",
      "Testing loss: 3.464840221405029, acc: 0.3600000047683716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss,acc=model3.evaluate(x3_test_add, y3_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 4ms/step\n",
      "\n",
      "Testing loss: 3.9916942596435545, acc: 0.30000000178813935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss,acc=model3.evaluate(x4_test_add, y4_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 4ms/step\n",
      "\n",
      "Testing loss: 2.310154371261597, acc: 0.44000000119209287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss,acc=model3.evaluate(x5_test_add, y5_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 4ms/step\n",
      "\n",
      "Testing loss: 3.218543071746826, acc: 0.3600000047683716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss,acc=model3.evaluate(x6_test_add, y6_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 4ms/step\n",
      "\n",
      "Testing loss: 3.320403060913086, acc: 0.4600000011920929\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss,acc=model3.evaluate(x7_test_add, y7_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 4ms/step\n",
      "\n",
      "Testing loss: 3.083814792633057, acc: 0.4200000023841858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss,acc=model3.evaluate(x8_test_add, y8_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 4ms/step\n",
      "\n",
      "Testing loss: 3.4238881206512453, acc: 0.34000000476837156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss,acc=model3.evaluate(x9_test_add, y9_test_onehot, batch_size=32)\n",
    "print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
